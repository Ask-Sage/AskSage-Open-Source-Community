{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AskSage API Review: \n",
    "\n",
    "In this notebook, we will go through the AskSage API documentation and review the available endpoints. We will use the Python API client to interact with the API and demonstrate how to use each endpoint. \n",
    "\n",
    "For more information please visit the AskSage Python API Client via the link below:\n",
    "Python API Client: https://pypi.org/project/asksageclient/\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Recommend to run the code cells in order to see the output of the endpoints and understand the examples provided. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> All credential information and API keys are removed from the code cells and declared as environment variables for security purposes. We recommend to do the same when running the code cells if you are sharing the notebook.\n",
    "</div>\n",
    "\n",
    "We will cover all of the following endpoints in this notebook: \n",
    "\n",
    "The order of review is based on a logical flow of first understanding what the API has to offer, then interacting with the API to interact with models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|       Function Name         |                       Description                     |\n",
    "|:---------------------------:|:-----------------------------------------------------:|\n",
    "|       `add_dataset`         |                   Adds a new dataset                  |\n",
    "|     `delete_dataset`        |              Deletes a specified dataset              |\n",
    "|     `assign_dataset`        |                   Assigns a dataset                   |\n",
    "|     `get_user_logs`         |             Retrieves all logs for user               |\n",
    "|    `get_user_logins`        | Retrieves login information for a specific user       |\n",
    "|          `query`            | Interact with the /query endpoint of the Ask Sage API |\n",
    "|    `query_with_file`        |         Executes a query using a file                 |\n",
    "|      `query_plugin`         | Executes a query using a specific plugin              |\n",
    "| `follow_up_questions`       | Interact with the /follow-up-questions endpoint of the Ask Sage API |\n",
    "|        `tokenizer`          | Interact with the /tokenizer endpoint of the Ask Sage API |\n",
    "|      `get_personas`         | Get the available personas from the Ask Sage service  |\n",
    "|      `get_datasets`         | Get the available datasets from the Ask Sage service  |\n",
    "|       `get_plugins`         | Get the available plugins from the Ask Sage service   |\n",
    "|  `count_monthly_tokens`     | Get the count of monthly training tokens spent for this user from the Ask Sage service |\n",
    "|`count_monthly_teach_tokens` | Counts the number of teach tokens used in a month     |\n",
    "|          `train`            | Train the model based on the provided content         |\n",
    "|    `train_with_file`        | Train the dataset based on the provided file          |\n",
    "|          `file`             | Upload a file to the Ask Sage service                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Set Environment Variables \n",
    "\n",
    "Let's start by importing the necessary libraries and setting the environment variables.\n",
    "\n",
    "> There will be more detail within this notebook than what is relevant to the user, but it is important to understand the different endpoints and what they represent. Also, note that the code is not being written in a production-ready manner, but rather to demonstrate the different endpoints and their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # Import the json module to work with JSON data\n",
    "import requests # Import the requests library to send HTTP requests\n",
    "from asksageclient import AskSageClient # Import the AskSageClient class from the asksageclient module\n",
    "import pandas as pd # Import the pandas library to work with dataframes\n",
    "import os # Import the os module to interact with the operating system\n",
    "\n",
    "# Function to load credentials from a JSON file\n",
    "def load_credentials(filename):\n",
    "    try:\n",
    "        with open(filename) as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"The credentials file was not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\"Failed to decode JSON from the credentials file.\")\n",
    "\n",
    "# Load the credentials\n",
    "credentials = load_credentials('../../credentials.json')\n",
    "\n",
    "# Extract the API key, email, and password from the credentials to be used in the API request\n",
    "api_key = credentials['credentials']['api_key']\n",
    "email = credentials['credentials']['Ask_sage_user_info']['username']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with the AskSage Python API Client\n",
    "\n",
    "The AskSage Python API Client provides a simple way to interact with the AskSage API. The client provides methods for each endpoint, making it easy to use the API without having to deal with more time-consuming tasks like making HTTP requests and handling responses.\n",
    "\n",
    "First order is defining the client and setting the credentials for the client, which are the email and API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "class AskSageClient(\n",
    "    email: email, # The email address of the user\n",
    "    api_key: api_key, # The API key for the AskSage API, which can be obtained from the AskSage website\n",
    "    user_base_url: str = 'https://api.asksage.ai/user', # The base URL for the user API\n",
    "    server_base_url: str = 'https://api.asksage.ai/server' # The base URL for the server API\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "ask_sage_client = AskSageClient(email, api_key) # Create an instance of the AskSageClient class with the email and api_key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get User Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint returns the last prompts of the user. By default, it returns the last 5 prompts.\n",
    "\n",
    "There are no parameters required for this endpoint. \n",
    "\n",
    "The output will be the following:\n",
    "- All the prompts that the user has made.\n",
    "- completion_tokens: The completion tokens of the prompt.\n",
    "- date_time: The date and time of the prompt.\n",
    "- id: The ID of the prompt.\n",
    "- ip: The IP address of the prompt.\n",
    "- model: The model used for the prompt.\n",
    "- prompt: The prompt text.\n",
    "- prompt_tokens: The prompt tokens.\n",
    "- response: The response text.\n",
    "- teach: The teach flag (true or false).\n",
    "- total_tokens: The total tokens \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>AskSage - Requested Updated:</b> The endpoint works as expected, however there should be a way to extract all or a specific number of logs.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompts = ask_sage_client.get_user_logs() # Get the user prompts using the get_user_logs method\n",
    "# display(user_prompts) # Uncomment to display the user prompts - this will display a lot of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get User Logins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint returns the last logins of the user. By default, it returns the last 5 logins.\n",
    "\n",
    "The only parameter required for this endpoint is the 'limit' parameter, which specifies the number of logins to return. The default value is 5 and the maximum value is 100.\n",
    "\n",
    "So in return, one will get the following information: \n",
    "- date_time: The date and time of the login.\n",
    "- id: The ID of the login.\n",
    "- ip: The IP address of the login.\n",
    "- status: The status of the login (success or failure).\n",
    "- type: endpoint type (login).\n",
    "- status_code: The status code of the login (200 for success, 400 for failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logins = ask_sage_client.get_user_logins(limit=1) # Get the user logins using the get_user_logins method\n",
    "display(user_logins) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Personas\n",
    "\n",
    "This endpoint returns the available personas from the Ask Sage service - A persona is like having a conversation with individuals who possess different skillsets. It allows the chatbot to tailor its behavior and personality to match specific user requirements. By adjusting the persona, the chatbot can adapt its tone, skillsets, and response formats to better align with the diverse needs and preferences of various scenarios. This customization ensures a more personalized and engaging experience for users, enhancing the effectiveness of the chatbot in addressing their specific queries and concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_personas = ask_sage_client.get_personas() # Get the personas using the get_personas endpoint\n",
    "# output of get_personas is as follows for each persona\n",
    "\"\"\" out put is as follows\n",
    "\n",
    "{'response': [{'datasets': '',\n",
    "   'date_creation': 'Tue, 16 Jan 2024 18:35:32 GMT',\n",
    "   'date_modification': 'Tue, 16 Jan 2024 18:35:32 GMT',\n",
    "   'description': 'Use this persona when you need a general-purpose AI that can handle a wide range of tasks, from translating languages to writing essays and code.',\n",
    "   'id': 1,\n",
    "   'image': None,\n",
    "   'label': 1,\n",
    "   'name': 'Ask Sage',\n",
    "   'prompt': 'Your purpose is help organizations drive outcomes by ingesting knowledge and data, providing analysis and insights with factual answers. \\nYou are able to translate languages, write essays, articles, bids, code and more.',\n",
    "   'public': True,\n",
    "   'user_id': -1}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# extract relevant information from the response 'id', 'name' and 'description'\n",
    "def extract_personas(response):\n",
    "    return [{'id': persona['id'], 'name': persona['name'], 'description': persona['description']} for persona in response['response']]\n",
    "\n",
    "personas = extract_personas(get_personas) # Extract the personas using the extract_personas function\n",
    "\n",
    "# Putting all information into a dataframe\n",
    "personas_df = pd.DataFrame(personas)\n",
    "\n",
    "# set column width to display full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "# display the dataframe\n",
    "display(personas_df.head()) # remove head() to display all personas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Datasets\n",
    "\n",
    "Get the available datasets from the Ask Sage service - These datasets are used to interact with the LLMs models. More information will be provided on how to interact with the datasets in the following endpoints & examples in the repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant information from the response\n",
    "def extract_datasets(response):\n",
    "    return response['response']\n",
    "\n",
    "get_datasets = ask_sage_client.get_datasets() # Get the datasets using the get_datasets endpoint\n",
    "\n",
    "\n",
    "def display_datasets(ask_sage_client):\n",
    "    \"\"\"   \n",
    "    Function to display the datasets in a dataframe\n",
    "\n",
    "    Parameters:\n",
    "    ask_sage_client: AskSageClient - The AskSageClient instance\n",
    "\n",
    "    Returns:\n",
    "    None - Displays the datasets in a dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    get_datasets = ask_sage_client.get_datasets() # Get the datasets using the get_datasets endpoint\n",
    "    datasets = extract_datasets(get_datasets) # Extract the datasets using the extract_datasets function\n",
    "    datasets_df = pd.DataFrame(datasets)\n",
    "    display(datasets_df) # Display the updated datasets dataframe\n",
    "\n",
    "# call the function to display the datasets\n",
    "display_datasets(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Plugins\n",
    "\n",
    "Get the available plugins from the Ask Sage service - Plugins are used to interact with the LLMs models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_plugins = ask_sage_client.get_plugins() # Get the plugins using the get_plugins endpoint\n",
    "\n",
    "# extract relevant information from the response\n",
    "def extract_plugins(response):\n",
    "    return [{'category': plugin['category'], 'description': plugin['description'], 'fields': plugin['fields'], 'title': plugin['title']} for plugin in response['response']]\n",
    "\n",
    "plugins = extract_plugins(get_plugins) # Extract the plugins using the extract_plugins function\n",
    "\n",
    "# Putting all information into a dataframe\n",
    "plugins_df = pd.DataFrame(plugins)\n",
    "\n",
    "# set column width to display full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# set column order title, category, description, fields\n",
    "plugins_df = plugins_df[['title', 'category', 'description', 'fields']]\n",
    "\n",
    "# display the dataframe\n",
    "display(plugins_df.head(2)) # remove head to display all plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Monthly Tokens\n",
    "\n",
    "Get the count of monthly training tokens spent for this user from the Ask Sage service - This endpoint will return the number of tokens used in the current month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_monthly_usage = ask_sage_client.count_monthly_tokens() # Get the count of monthly usage using the get_count_monthly_usage method\n",
    "# extract the count of monthly usage from the response\n",
    "count = count_monthly_usage['response']\n",
    "\n",
    "print(f\"The count of monthly usage is: {count}\") # Print the count of monthly usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Monthly Teach Tokens\n",
    "\n",
    " Get the count of monthly training tokens spent for this user from the Ask Sage service, meaning the number of tokens used for training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_monthly_usage = ask_sage_client.count_monthly_teach_tokens() # Get the count of monthly usage using the get_count_monthly_usage method\n",
    "# extract the count of monthly usage from the response\n",
    "count = count_monthly_usage['response']\n",
    "\n",
    "print(f\"The count of monthly teach usage is: {count}\") # Print the count of monthly usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint is used to create a new dataset that will be available for the user to use in the prompt generation. Additionally, once the dataset is created it will also be available on the AskSage platform for the user to use. \n",
    "\n",
    "Notice how the dataset is now in the list of available datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dataset to be added to the user's datasets\n",
    "add_dataset_data = ask_sage_client.add_dataset('test-test-test') # Replace 'youareawesome' with the name of the dataset you want to add\n",
    "display(add_dataset_data) # Display the response from the API, and check if the dataset was added successfully on the AskSage website\n",
    "display_datasets(ask_sage_client) # Display the datasets after adding a new dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train With File\n",
    "\n",
    "This endpoint is used to train the dataset based on the provided file. The files that can be loaded are listed below: \n",
    "\n",
    "- Format supported: zip, pdf, xlsx, pptx, docx, ppt, csv, cc, sql, cs, hh, c, php, js, py, html, xml, msg, odt, epub, eml, rtf, txt, doc, json, md, jpeg, jpg, png, tsv (50MB)\n",
    "\n",
    "- Audio Format supported: mp3, mp4, mpeg, mpga, m4a, wav, webm (500MB max)\n",
    "\n",
    "The files uploaded will be stored in the AskSafe platform and can be called upon when interacting with the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def train_with_file(self, file_path, dataset):\n",
    "#         \"\"\"\n",
    "#     Train the dataset based on the provided file.\n",
    "\n",
    "#     Parameters:\n",
    "#     file_path (str): The file to upload to the service.\n",
    "#     dataset (str): The dataset to be used. Enter your custom dataset, must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by user ID and DATASET-NAME by the name of your dataset.\n",
    "    \n",
    "#     Returns:\n",
    "#     dict: The response from the service.\n",
    "#         \"\"\"\n",
    "#         with open(file_path, 'rb') as f:\n",
    "#             files = {'file': f}\n",
    "#             return self._request('POST', 'train-with-file', files=files, data={'dataset': dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "file_path = 'data/' \n",
    "\n",
    "# get files in the data path\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "# train the dataset with the files in the data path \n",
    "for file in files:\n",
    "    train_with_file_data = ask_sage_client.train_with_file(file_path + file, 'user_custom_2780_test-test-test_content') # Replace '2780' and 'youareawesome' with your ID and name of the dataset you want to add\n",
    "    # display the field 'response'\n",
    "    display(train_with_file_data['response'] + ' for file ' + file) # Display the response from the API, and check if the dataset was added successfully on the AskSage website\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data upload successfully, will be stored however there is a small lag on availability.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>AskSage - Requested Updated:</b> Uploaded data however noticed that only word documents and pdfs are actually being uploaded and seen on the platform following the upload.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "This endpoint is used to interact with the /query endpoint of the Ask Sage API. It is where the magic happens and users can interact with the various models available on the Ask Sage platform.\n",
    "\n",
    "We will provide examples of how to use this endpoint and various parameters that can be used to interact with the models. Do note that this will only be high-level examples and more detailed examples and explanations on how these models work will be provided in the repository specifically in the examples folder --> ex_2_prompt_generation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query(self, message, persona='default', dataset='all', limit_references=None, temperature=0.0, live=0, model='openai_gpt', system_prompt=None):\n",
    "#         \"\"\"\n",
    "#     Interact with the /query endpoint of the Ask Sage API.\n",
    "\n",
    "#     Parameters:\n",
    "#     message (str): The message to be processed by the service. Message can be a single message or an array of messages following this JSON format: [{ user: \"me\", message: \"Who is Nic Chaillan?\"}, { user: \"gpt\", message: \"Nic Chaillan is...\"}]\n",
    "#     persona (str, optional): The persona to be used. Default is 'default'. Get the list of available personas using get_personas.\n",
    "#     dataset (str, optional): The dataset to be used. Default is 'all'. Other options include 'none' or your custom dataset, must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by user ID and DATASET-NAME by the name of your dataset.\n",
    "#     limit_references (int, optional): The maximum number of references (embeddings) to be used. Default is None, meaning all references will be used. Use 1 to limit to 1 reference or 0 to remove embeddings. You can also set dataset to \"none\"\n",
    "#     temperature (float, optional): The temperature to be used for the generation. Default is 0.0. Higher values (up to 1.0) make the output more random.\n",
    "#     live (int, optional): Whether to use live mode. Default is 0. Live = 1 will pull 10 results from Bing and 2 will also pull the top 2 web pages summaries using our Web crawler.\n",
    "#     model (str, optional): The model to be used. Default is 'openai_gpt'. Other options include cohere, google-bison, gpt4, gpt4-32k, gpt35-16k, claude2, openai_gpt (gpt3.5), davinci, llma2.\n",
    "#     system_prompt (str, optional): Overrides the system prompt from Ask Sage (only use if you know what you are doing).\n",
    "\n",
    "#     Returns:\n",
    "#     dict: The response from the service.\n",
    "#     \"\"\"\n",
    "#         return self._request('POST', 'query', json = {\n",
    "#             'message': message,\n",
    "#             'persona': persona,\n",
    "#             'dataset': dataset,\n",
    "#             'limit_references': limit_references,\n",
    "#             'temperature': temperature,\n",
    "#             'live': live,\n",
    "#             'model': model,\n",
    "#             'system_prompt': system_prompt\n",
    "#         })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Query Parameters: \n",
    "\n",
    "#### 'message'\n",
    "\n",
    "- 'message': The message is your prompt that you want to generate a response for by the model. In other words, the message/question you want to ask the model. But remember, the model will only generate a response based on the data it has been trained on and given this understanding, it is important to ask questions that are relevant to the data the model has been trained on. \n",
    "  \n",
    "If you are using a off-the-shelf model or Out of the Box model, then the model has been trained on a wide range of data and can generate responses to a wide range of questions. However, do not expect the model to generate responses to questions that are not relevant to the data it has been trained on or be an expert in any or all fields. We will discuss more examples on how to direct the model to generate responses to specific questions later. Last but not least, also be aware that each model has its own limitations and capabilities and designed for specific use cases, thus making some more suitable for certain tasks like code generation, text generation, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> Bad Examples of Prompt Generation:\n",
    "* Can you give me references for Dr. Espinoza on his research on under water basket weaving? (He is well known for his research in this field)\n",
    "  * This is a bad example as the model does not have access to personal information or private information, including research papers. Unless the research papers are publicly available and the model has been trained on them. Also, this is a fictional example, but important to show the limitations of the model.\n",
    "* What is the weather for tomorrow in Paris, Texas?\n",
    "  * This is a bad example if the model does not have access to real-time data or weather data.\n",
    "* Who is Mark Espinoza? And can you provide me with his email address?\n",
    "  * This is a bad example as the model does not have access to personal information or private information. \n",
    "* Can you give me the phone number for the nearest pizza place near me? \n",
    "  * Again, this is a bad example as the model does not have access to real-time data or location data.\n",
    "* Can you give me a test plan? \n",
    "  * This is a bad example as the model does not have access to your project or test plan. Also, what kind of test plan are you looking for?\n",
    "* Who will win the next election? \n",
    "  * This is a bad example as the model does not have access to future data or predictions. Also, the model does not have access to real-time data or election data. Also what election is being referred to - student council, presidential, HOA board, etc. \n",
    "\n",
    "  \n",
    "\n",
    ">  Acceptable Examples of Prompt Generation:\n",
    "* How many planets are in the solar system and can you provide the names of the planets in order from the sun? Also, provide the distance of each planet from the sun in kilometers.\n",
    "  * This would be more acceptable as the model has been trained on general knowledge and can provide information on the planets in the solar system - additionally the user is specific on what they want to know, how they want it ordered, and the units of measurement.\n",
    "* Tell me a joke about a giraffe that loves to play basketball, but is not very good at it. (Make sure to make the joke for a audience of 18 years and older)\n",
    "  * This is more of a creative example and the model can generate a joke based on the prompt. The user is also specific on the type of joke they want and the audience it is intended for. The more specific the prompt, the better the response from the model.\n",
    "* Provide me with a series of steps on how to make a API call using python to a REST API endpoint. Also, provide me with a code examples.\n",
    "  * This is a more technical example and the model can generate a response based on the prompt. The user is also specific on what they want to know and the model can generate a response based on the prompt. \n",
    "* Can you provide me with a summary of the book \"The Great Gatsby\" by F. Scott Fitzgerald? Also, provide me with a list of the main characters in the book with a brief description of each character. (Also, what is the main theme of the book?)\n",
    "  * This is more of a literature example based on a well known and book and their exists a lot of information on the book online, thus having a higher chance of the model being trained on the book. The user is also specific on what they want to know and the model can generate a response based on the prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_sage_question(message, persona='default', dataset='all', limit_references=None, temperature=0.0, live=0, model='openai_gpt', system_prompt=None):\n",
    "    \"\"\"\n",
    "    Function to query the AskSage API with a question and return the response message using one of the personas available\n",
    "\n",
    "    Parameters:\n",
    "    question (str): The question to be queried\n",
    "    persona (str): The persona to be used. Default is 'default'. Get the list of available personas using get_personas.\n",
    "    dataset (str): The dataset to be used. Default is 'all'. Other options include 'none' or your custom dataset, must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by user ID and DATASET-NAME by the name of your dataset.\n",
    "    limit_references (int): The maximum number of references (embeddings) to be used. Default is None, meaning all references will be used. Use 1 to limit to 1 reference or 0 to remove embeddings. You can also set dataset to \"none\"\n",
    "    temperature (float): The temperature to be used for the generation. Default is 0.0. Higher values (up to 1.0) make the output more random.\n",
    "    live (int): Whether to use live mode. Default is 0. Live = 1 will pull 10 results from Bing and 2 will also pull the top 2 web pages summaries using our Web crawler.\n",
    "    model (str): The model to be used. Default is 'openai_gpt'. Other options include cohere, google-bison, gpt4, gpt4-32k, gpt35-16k, claude2, openai_gpt (gpt3.5), davinci, llma2.\n",
    "    system_prompt (str): Overrides the system prompt from Ask Sage (only use if you know what you are doing).\n",
    "\n",
    "    Returns:\n",
    "    str: The response message from the AskSage API\n",
    "    \"\"\"\n",
    "    response = ask_sage_client.query(message, persona, dataset, limit_references, temperature, live, model, system_prompt) # Query the AskSage API with the question\n",
    "    message = response['message'] # Extract the message from the response\n",
    "    return message # Return the message\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's review all of the bad examples\n",
    "\n",
    "bad_examples = [ \n",
    "    'Can you give me references for Dr. Espinoza on his research on under water basket weaving? (He is well known for his research in this field)', \n",
    "    'What is the weather for tomorrow in Paris, Texas?', \n",
    "    'Who is Mark Espinoza? And can you provide me with his email address?', \n",
    "    'Can you give me the phone number for the nearest pizza place near me?',\n",
    "    'Can you give me a test plan?', \n",
    "    'Who will win the next election?'\n",
    "]\n",
    "\n",
    "accetable_examples = ['How many planets are in the solar system and can you provide the names of the planets in order from the sun? Also, provide the distance of each planet from the sun in kilometers.', \n",
    "                      'Tell me a joke about a giraffe that loves to play basketball, but is not very good at it. (Make sure to make the joke for a audience of 18 years and older)',\n",
    "                      'Provide me with a series of steps on how to make a API call using python to a REST API endpoint. Also, provide me with a code examples.', \n",
    "                      'Can you provide me with a summary of the book \"The Great Gatsby\" by F. Scott Fitzgerald? Also, provide me with a list of the main characters in the book with a brief description of each character. (Also, what is the main theme of the book?).',\n",
    "                      ]\n",
    "\n",
    "print(\"Bad Examples\")\n",
    "# loop through all bad examples and get the response from AskSage\n",
    "for example in bad_examples:\n",
    "    response = ask_sage_question(example)\n",
    "    print(f\"Question: {example}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n ----------------- \\n\")\n",
    "print(\"Acceptable Examples\")\n",
    "\n",
    "# loop through all acceptable examples and get the response from AskSage\n",
    "for example in accetable_examples:\n",
    "    response = ask_sage_question(example)\n",
    "    print(f\"Question: {example}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'persona'\n",
    "\n",
    "A persona is set for a model to interact with the user. The persona is like having a conversation with individuals who possess different skillsets. It allows the chatbot to tailor its behavior and personality to match specific user requirements. By adjusting the persona, the chatbot can adapt its tone, skillsets, and response formats to better align with the diverse needs and preferences of various scenarios. This customization ensures a more personalized and engaging experience for users, enhancing the effectiveness of the chatbot in addressing their specific queries and concerns. The list of available personas can be retrieved using the get_personas endpoint as shown previously.\n",
    "\n",
    "\n",
    "For this section will create three different questions, each which is unique to a specific skillset (persona) and see how the model responds to each question.\n",
    "\n",
    "Note: Responses can still be the same or similar, but the model will respond based on the persona set for the model.\n",
    "\n",
    "\n",
    "- Software Developer\n",
    "\n",
    "Question 1: 'We are developing a MYSQL database for a new project, but need to know how to create a new database, table, and insert data into the table. Can you provide us with the SQL commands to do this? Also, provide us with information on containerization and how it can be used to deploy the database.'\n",
    "\n",
    "- Legal Assistant\n",
    "\n",
    "Question 2: 'I need a legal document for a non-disclosure agreement for a new project related to 'Super Secret Project'. Can you provide me with a template for a non-disclosure agreement that I can use for my project? Also, add in a clause that states that the agreement is valid for 5 years and can be renewed upon mutual agreement.'\n",
    "\n",
    "- Creative Writer\n",
    "\n",
    "Question 3: 'Draft me a story about how a person learns to ride a horse for the first time. Make sure to include the emotions, the setting, and the characters in the story. Also, make sure the story is suitable for children ages 8-12 years old.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(personas_df.head())\n",
    "\n",
    "# define personas to be used\n",
    "personas = ['Software Developer', 'Legal Assistant', 'Creative Writer']\n",
    "\n",
    "# questions to be asked\n",
    "questions = ['We are developing a MYSQL database for a new project, but need to know how to create a new database, table, and insert data into the table. Can you provide us with the SQL commands to do this? Also, provide us with information on containerization and how it can be used to deploy the database.', \n",
    "             \"I need a legal document for a non-disclosure agreement for a new project related to 'Super Secret Project'. Can you provide me with a template for a non-disclosure agreement that I can use for my project? Also, add in a clause that states that the agreement is valid for 5 years and can be renewed upon mutual agreement.\",\n",
    "             'Draft me a story about how a person learns to ride a horse for the first time. Make sure to include the emotions, the setting, and the characters in the story. Also, make sure the story is suitable for children ages 8-12 years old.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all personas and questions to get the response\n",
    "for persona in personas:\n",
    "    print(f\"Persona: {persona}\")\n",
    "    for question in questions:\n",
    "        response = ask_sage_question(question, persona)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Response: {response}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Selecting a persona is optional and if the persona is not available, the default persona will be used instead. But it is important to note that the persona can help the model generate responses that are more tailored to the specific skillset or personality of the persona.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>AskSage - Requested Updated:</b> When selecting a persona, please ensure that the persona is available in the list of personas. If the persona is not available, the default persona will be used instead. \n",
    "There is no spell check or validation for the persona name.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'dataset'\n",
    "\n",
    "The dataset is the dataset that the model will use to generate responses to the prompt. The dataset is used to interact with the LLMs models. The list of available datasets can be retrieved using the get_datasets endpoint as shown previously. In this example we will use the 'test-test-test' dataset and ask about the story of the files it is referencing from. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask the following question \"Tell me about the random stroy and summarize it\"\n",
    "response = ask_sage_question(message=\"Tell me about the random story and summarize it\", dataset='user_content_2780_test-test-test_content')\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'limit_references'\n",
    "\n",
    "This endpoint is used to limit the number of references that the model will use to generate the response. The default value is 5 and the maximum value is 10, but can be set to 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to the above example, but we are setting reference limit to 0 \n",
    "response = ask_sage_question(message=\"Tell me about the random story and summarize it\", limit_references=0, dataset='user_content_2780_test-test-test_content')\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Notice that even though the prompt is pointing to the dataset, since I set references to 0, the model will not use the dataset to generate the response. Also, the model created a hallucination in the response, which is interesting to see - but it's due to the model not having access to the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'temperature'\n",
    "\n",
    "The temperature is used to control the randomness of the response generated by the model. The temperature value ranges from 0 to 1, where 0 is deterministic and 1 is more random. The default value is 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_sage_question(message=\"Tell me what are the coolest shoes? Only list the shoes no other details needed\", limit_references=0, temperature=0)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "response = ask_sage_question(message=\"Tell me what are the coolest shoes? Only list the shoes no other details needed\", limit_references=0, temperature=1)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Notice how the changes are different based on the temperature value. The higher the temperature, the more random the response will be. The lower the temperature, the more deterministic the response will be.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'live'\n",
    "\n",
    "The live parameter works to pull information from the internet in real-time. Specifically, Live = 1 will pull 10 results from Bing and 2 will also pull the top 2 web pages summaries using our Web crawler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_sage_question(message=\"How do you make a pizza? - keep it short\", live=0) # no information from the web\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "response = ask_sage_question(message=\"How do you make a pizza? - keep it short\", live=1) # 10 results from Bing\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "response = ask_sage_question(message=\"How do you make a pizza? - keep it short\", live=2) # 10 results from Bing and 2 summaries from web crawler\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'model'\n",
    "\n",
    "Here users can specify the model they want to use to generate the response. The default model is the 'gpt-3.5-turbo' model, but users can specify the model they want to use. The list of available models can be retrieved using the get_plugins endpoint as shown previously. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models available as of the making of this notebook\n",
    "\n",
    "models = [\"cohere\", \"mpt-7b-chat\", \"claude2\", \"claude-3-opus\", \"claude-3-sonnet\", \"llma3\", \"aws-bedrock-titan\", \"google-bison\", \"google-gemini-pro\", \"mistral-large\", \"openai_gpt\",\n",
    "           \"gpt4\", \"gpt4-32k\", \"gpt4-vision\", \"gpt35-16k\", \"gpt-gov\", \"gpt4-gov\", \"dall-e-2\", \"dall-e-3\", \"davinci\"]\n",
    "\n",
    "response = ask_sage_question(message=\"How do you make a pizza? - keep it short\", live=0, model=\"gpt4\") # no information from the web\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> A model will behave differently - thus understanding that is important when selecting a model. Some models perform better on certain tasks than others.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'system_prompt'\n",
    "\n",
    "In the context of AI language models like GPT-3, the system_prompt refers to a way to provide context, instructions, and guidelines to the model before presenting it with a question or task. By using a system_prompt, you can set the stage for the conversation, specify the AI's role, personality, tone, or any other relevant information that will help it better understand and respond to the user's input.\n",
    "\n",
    "When using GPT-3 or similar models, you can include a system_prompt as part of your input to guide the AI's behavior. For example, if you want the AI to respond as a helpful assistant, you can start your prompt with a system_prompt like \"You are an AI assistant that provides information and answers questions.\" This helps set the context for the AI's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_sage_question(message=\"How do you make a pizza? - keep it short\", live=0, model=\"gpt4\", \n",
    "                             system_prompt=\"Be a angry chief but give the right answers but make sure to sound angry within the answers\") \n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query with file\n",
    "\n",
    "This endpoint is used to interact with a file that is not in the dataset, but still reference the dataset created while performing the query. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "file_path = 'data/query_with_file/'\n",
    "\n",
    "# get files in the data path\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "message='Would Toby get along with Whiskers?'\n",
    "\n",
    "query_with_file_data = ask_sage_client.query_with_file(message='Would Toby get along with Whiskers?', file=file_path + files[0], dataset='user_content_2780_test-test-test_content') # Replace '2780' and 'test-test-test' with your ID and name of the dataset you want to add\n",
    "# display the field 'response'\n",
    "display(message)\n",
    "display(query_with_file_data['message']) # Display the response from the API, and check if the dataset was added successfully on the AskSage website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Up Questions\n",
    "\n",
    "This endpoint is used to interact with the /follow-up-questions endpoint of the Ask Sage API. It is used to generate follow-up questions based on the prompt given to the model. The follow-up questions are generated based on the prompt and the model will generate questions that are relevant to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follwup_question = \"Ask me questions about the random story\"\n",
    "\n",
    "query_with_file_data = ask_sage_client.query_with_file(message=follwup_question) \n",
    "# display the field 'response'\n",
    "display(follwup_question)\n",
    "display(query_with_file_data['message']) # Display the response from the API, and check if the dataset was added successfully on the AskSage website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "This endpoint is used to interact with the /tokenizer endpoint of the Ask Sage API. It is used to tokenize the text provided to the model. The tokenizer is used to split the text into tokens that the model can understand and process. The tokenizer is used to preprocess the text before it is passed to the model for processing. Thus in return the output will be the tokens of the text provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This endpoint is used to interact with the /tokenizer endpoint of the Ask Sage API. It is used to tokenize the text provided to the model. The tokenizer is used to split the text into tokens that the model can understand and process. The tokenizer is used to preprocess the text before it is passed to the model for processing. Thus in return the output will be the tokens of the text provided.\" \n",
    "\n",
    "tokenize_data = ask_sage_client.tokenizer(text) # Tokenize the text using the tokenizer method\n",
    "\n",
    "# display the field 'response'\n",
    "display('The number of tokens in the text is: ' +\n",
    "        tokenize_data['response'] + ' Tokens') # Display the response from the API, and check if the dataset was added successfully on the AskSage website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The train endpoint is used to train the model based on the provided content. The content is the message to be processed by the service. Ensure it is under 500 tokens. The force_dataset is the dataset to be used. Enter your custom dataset, must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by user ID and DATASET-NAME by the name of your dataset. The context is a short context about the content (metadata). Under 20 tokens. The skip_vectordb is whether to skip the VectorDB training. Default is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = 'Arduino is an open-source electronics platform based on easy-to-use hardware and software. It consists of a physical programmable circuit board (often referred to as a microcontroller) and a piece of software, or IDE (Integrated Development Environment), that runs on your computer. You use the IDE to write and upload computer code to the physical board. The platform is designed to enable users of all ages to create interactive electronic objects and projects that can sense and control physical devices. Arduino boards can read inputs - light on a sensor, a finger on a button, or a Twitter message - and turn it into an output - activating a motor, turning on an LED, publishing something online. You can tell your board what to do by sending a set of instructions to the microcontroller on the board. Arduino is widely used in robotics, home automation, scientific experimentation, and artistic projects.'\n",
    "\n",
    "tokenize_data = ask_sage_client.tokenizer(content) # Tokenize the text using the tokenizer method\n",
    "\n",
    "# display the field 'response'\n",
    "display('The number of tokens in the text is: ' +\n",
    "        tokenize_data['response'] + ' Tokens') # Display the response from the API, and check if the dataset was added successfully on the AskSage website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the content into the database\n",
    "train_data = ask_sage_client.train(content, force_dataset='test-test-test', context='testing') # Replace 'test-test-test' with the name of the dataset you want to add\n",
    "# display the field 'response'\n",
    "display(train_data['response']) # Display the response from the API, and check if the dataset was added successfully on the AskSage website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>AskSage - Requested Updated:</b> When selecting a dataset, the instruction mention to use the following format: user_content_USERID_DATASET-NAME_content. However, the dataset is not being recognized when using the format provided. Just used the dataset name and it worked. Also, successful uploading the data but it's not appearing on the webiste. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File\n",
    "\n",
    "This is a function named file in the Ask Sage service. It is used to upload a file to the service. The function takes two parameters: file_path and strategy.\n",
    "\n",
    "file_path is a string that represents the path to the file you want to upload.\n",
    "\n",
    "strategy is also a string, and it determines the type of parser that will be used. By default, it is set to 'auto'. If you want faster parsing but less accuracy, you can set it to 'fast'. If you need OCR recognition, you can set it to 'hi_res', but keep in mind that this will be slower.\n",
    "\n",
    "The function opens the file in binary mode and prepares it for upload. It then makes a POST request to the 'file' endpoint of the service, passing the file and the strategy as data.\n",
    "\n",
    "The function returns a dictionary which is the response from the service, containing the text/plain of the uploaded file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "path = 'data/query_with_file/'\n",
    "\n",
    "# get files in the data path\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "file_endpoint = ask_sage_client.file(file_path = path + files[0], strategy='auto') \n",
    "# display the field 'response'\n",
    "display(file_endpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Plugin\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This plugin example will be updated in the future, and will be incomplete for now. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Dataset\n",
    "\n",
    "This endpoint is used to assign a dataset to a specific user - This will allow another user to use the dataset but only sharing between users is permitted if they are from the same organization.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Not performing this endpoint since we do not officially belong to an organization. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_dataset(self, dataset, email):\n",
    "#     \"\"\"\n",
    "#     Assign a dataset\n",
    "\n",
    "#     Parameters:\n",
    "#     dataset (str): The dataset to be used. Must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by user ID and DATASET-NAME by the name of your dataset.\n",
    "#     email (str): Email of the user to assign the dataset to. Must be in the same organization. Reach out to support if need be.\n",
    "\n",
    "#     Returns:\n",
    "#     dict: The response from the service.\n",
    "#     \"\"\"\n",
    "#     return self._request('POST', 'assign-dataset', json={'dataset': dataset, 'email': email}, base_url=self.user_base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Dataset\n",
    "\n",
    "This endpoint is used to delete a dataset from the user's account. The only parameter required for this endpoint is the 'dataset', which specifies the specific dataset to delete. \n",
    "\n",
    "Notice how the dataset is no longer in the list of available datasets after deletion.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b>Running the cell below will clear the dataset from your account.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_dataset_data = ask_sage_client.delete_dataset('user_custom_2780_test-test-test_content') # Replace 'youareawesome' with the name of the dataset you want to delete\n",
    "# get the response from the API\n",
    "display(delete_dataset_data) # Display the response from the API, and check if the dataset was deleted successfully on the AskSage website\n",
    "\n",
    "display_datasets(ask_sage_client)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
