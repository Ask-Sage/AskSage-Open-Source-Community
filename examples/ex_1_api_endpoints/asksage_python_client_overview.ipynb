{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask Sage Python API Client - API Documentation\n",
    "\n",
    "In this notebook, we will go through the Ask Sage Python Client and review the available endpoints and how to use them.\n",
    "\n",
    "For more information please visit the Ask Sage Python Client via the link below:\n",
    "\n",
    "Python API Client: https://pypi.org/project/asksageclient/\n",
    "\n",
    "Or also reference the Ask Sage Documentation via the this link: https://docs.asksage.ai/\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Recommend to run the code cells in order to see the output of the endpoints and understand the examples provided. However, be aware that some of the results are post processed to make the output more readable.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> All credential information and API keys are removed from the code cells and declared as environment variables for security purposes. We recommend to do the same when running the code cells if you are sharing the notebook. There is an a file in this repository called `credentials.json.example` as an example of how to structure your credentials file. \n",
    "</div>\n",
    "\n",
    "We will cover all of the following endpoints in this notebook: \n",
    "\n",
    "The order of review is based on a logical flow of first understanding what the API has to offer, then interacting with the API to interact with models. \n",
    "\n",
    "Also, refer to the Outline of the notebook to navigate to the specific endpoints you are interested in reviewing, but still recommend to run the code cells in order to see the output of the endpoints and understand the examples provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Sage Python API Client Endpoints\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "|       Function Name         |                       Description                     |\n",
    "|:---------------------------:|:-----------------------------------------------------:|\n",
    "|         `get_models`         | Get the available models from the Ask Sage service    |\n",
    "|       `add_dataset`         |                   Adds a new dataset                  |\n",
    "|     `delete_dataset`        |              Deletes a specified dataset              |\n",
    "|     `assign_dataset`        |                   Assigns a dataset                   |\n",
    "|     `get_user_logs`         |             Retrieves all logs for user               |\n",
    "|    `get_user_logins`        | Retrieves login information for a specific user       |\n",
    "|          `query`            | Interact with the /query endpoint of the Ask Sage API |\n",
    "|    `query_with_file`        |         Executes a query using a file                 |\n",
    "|      `query_plugin`         | Executes a query using a specific plugin              |\n",
    "|    `execute_plugin`         | Executes a plugin with the provided content           |\n",
    "| `follow_up_questions`       | Interact with the /follow-up-questions endpoint of the Ask Sage API |\n",
    "|        `tokenizer`          | Interact with the /tokenizer endpoint of the Ask Sage API |\n",
    "|      `get_personas`         | Get the available personas from the Ask Sage service  |\n",
    "|      `get_datasets`         | Get the available datasets from the Ask Sage service  |\n",
    "|       `get_plugins`         | Get the available plugins from the Ask Sage service   |\n",
    "|  `count_monthly_tokens`     | Get the count of monthly training tokens spent for this user from the Ask Sage service |\n",
    "|`count_monthly_teach_tokens` | Counts the number of teach tokens used in a month     |\n",
    "|          `train`            | Train the model based on the provided content         |\n",
    "|    `train_with_file`        | Train the dataset based on the provided file          |\n",
    "|          `file`             | Upload a file to the Ask Sage service                 |\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "There are 20 endpoints available in the Ask Sage Python API Client. We will go through each of them in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A. Import Libraries and Set Environment Variables \n",
    "\n",
    "Let's start by importing the necessary libraries and setting the environment variables.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> There will be more detail within this notebook than what is relevant to most users, but it is important to understand the different endpoints and what they represent. Also, note that the code is not being written in a production-ready manner, but rather to demonstrate the different endpoints and their outputs. For production, you would want to write more robust code with error handling, security, and much more. \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.7.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'plotly': 'https://cdn.plot.ly/plotly-3.0.1.min'}, 'shim': {}});\n      require([\"plotly\"], function(Plotly) {\n        window.Plotly = Plotly\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 1;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Plotly !== undefined) && (!(window.Plotly instanceof HTMLElement))) || window.requirejs) {\n      var urls = [];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.6.3/dist/bundled/plotlyplot/plotly-3.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.holoviz.org/panel/1.6.3/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.6.3/dist/bundled/plotlyplot/maplibre-gl@4.4.1/dist/maplibre-gl.css?v=1.6.3\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='6618d45f-f426-443a-8725-95ca2c112443'>\n",
       "  <div id=\"bf92d1b2-d2cd-4a04-bd43-f7f2b5b5278f\" data-root-id=\"6618d45f-f426-443a-8725-95ca2c112443\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"fe8f6cf5-ba23-4c03-a846-b18b1705c03a\":{\"version\":\"3.7.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"6618d45f-f426-443a-8725-95ca2c112443\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"1085fc6c-27e9-472c-aa89-cd6cead7915d\",\"attributes\":{\"plot_id\":\"6618d45f-f426-443a-8725-95ca2c112443\",\"comm_id\":\"1526cb032ed44ef59d11352ee18048cd\",\"client_comm_id\":\"94f3940b1a5042fa9ffe990d9c778c81\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"fe8f6cf5-ba23-4c03-a846-b18b1705c03a\",\"roots\":{\"6618d45f-f426-443a-8725-95ca2c112443\":\"bf92d1b2-d2cd-4a04-bd43-f7f2b5b5278f\"},\"root_ids\":[\"6618d45f-f426-443a-8725-95ca2c112443\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Plotly !== undefined) && ( root.Plotly !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "6618d45f-f426-443a-8725-95ca2c112443"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Core Python Modules ===\n",
    "import os         # Interact with the operating system (file management, paths)\n",
    "import re         # Work with regular expressions\n",
    "import time       # Time-related functions\n",
    "import random     # Generate random numbers\n",
    "import json       # Work with JSON data\n",
    "import pprint     # Pretty-print complex data structures\n",
    "from datetime import datetime, timedelta  # Date and time utilities\n",
    "\n",
    "# === Type Hints ===\n",
    "from typing import List, Tuple, Optional, Dict, Union  # Added Dict and Union for broader type hinting\n",
    "\n",
    "# === External Libraries ===\n",
    "import requests        # Send HTTP requests\n",
    "import pandas as pd     # Data manipulation and analysis\n",
    "import panel as pn      # Build interactive web applications\n",
    "import plotly.express as px   # Simple Plotly visualizations\n",
    "import plotly.graph_objects as go  # Advanced Plotly visualizations\n",
    "import matplotlib.pyplot as plt   # Static, animated, and interactive visualizations\n",
    "from PIL import Image      # Image processing\n",
    "from faker import Faker    # Generate fake data for testing\n",
    "\n",
    "# === Custom Modules ===\n",
    "from asksageclient import AskSageClient  # Interact with the AskSage API\n",
    "\n",
    "# === Panel Setup ===\n",
    "pn.extension('plotly')  # Initialize Panel with Plotly support\n",
    "\n",
    "# === Future Imports ===\n",
    "from __future__ import annotations  # Ensure compatibility with future Python versions\n",
    "\n",
    "# === Logging Setup ===\n",
    "import logging  # Added logging for better debugging and monitoring\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') \n",
    "\n",
    "# === Path Utilities ===\n",
    "from pathlib import Path  # Manage file paths effectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Environment Variables (Credentials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load credentials from a JSON file\n",
    "def load_credentials(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load credentials from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the credentials file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed credentials data.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "        ValueError: If the file contains invalid JSON.\n",
    "        KeyError: If required keys are missing in the credentials.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            credentials = json.load(file)\n",
    "            # Validate required keys\n",
    "            if 'credentials' not in credentials or 'api_key' not in credentials['credentials']:\n",
    "                raise KeyError(\"Missing required keys in the credentials file.\")\n",
    "            return credentials\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Credentials file not found at: {filepath}\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Invalid JSON format in the credentials file: {filepath}\")\n",
    "\n",
    "# Load the credentials\n",
    "credentials = load_credentials('../../credentials.json')\n",
    "\n",
    "# Extract the API key and email from the credentials\n",
    "api_key = credentials['credentials']['api_key']\n",
    "email = credentials['credentials']['Ask_sage_user_info']['username']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Setup Ask Sage Python API Client\n",
    "\n",
    "The AskSage Python API Client provides a simple way to interact with the AskSage API. The client provides methods for each endpoint, making it easy to use the API.\n",
    "\n",
    "First order is defining the client and setting the credentials for the client, which are the email and API key.\n",
    "\n",
    "Note: Users have the option to generate a token for the API key, but this is not required. The API key is sufficient to access the API. However, they API key does not expire, thus take precautions to keep it secure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> If you are not obtaining your API key from https://chat.asksage.ai/ and are on other tenant/instance of Ask Sage, please update the base URL within the Ask Sage Client package installed. See image below for where to update the base URL in the package.\n",
    "\n",
    "![Ask Sage Client Base URL](/Users/mark.espinozaasksage.ai/Code/AskSage-Open-Source-Community/images/update_base_url.png)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "class AskSageClient(\n",
    "    email: email, # The email address of the user\n",
    "    api_key: api_key, # The API key for the AskSage API, which can be obtained from the AskSage website\n",
    "    user_base_url: str = 'https://api.asksage.ai/user', # The base URL for the user API\n",
    "    server_base_url: str = 'https://api.asksage.ai/server' # The base URL for the server API\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "ask_sage_client = AskSageClient(email, api_key) # Create an instance of the AskSageClient class with the email and api_key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Client Endpoints Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve Available Models\n",
    "The `get_models` function fetches a list of all available models provided by Ask Sage. These models can be utilized with the `query` function to process user queries. Developers should familiarize themselves with each model's capabilities and differences to ensure effective usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models available for the user on the respetive Ask Sage Tenant/Account:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aws-bedrock-titan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws-bedrock-claude-35-sonnet-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llma3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-3-opus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-3-sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude-35-sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude-37-sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cohere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mistral-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt4-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt35-16k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dall-e-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-4.5-preview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>google-gemini-pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>google-gemini-20-flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>google-imagen-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-4o-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4o-mini-gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>groq-70b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>groq-llama33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>groq-llama4-scout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>groq-deepseek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt-o1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt-o3-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gpt-image-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xai-grok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "0                  aws-bedrock-titan\n",
       "1   aws-bedrock-claude-35-sonnet-gov\n",
       "2                              llma3\n",
       "3                            claude2\n",
       "4                      claude-3-opus\n",
       "5                    claude-3-sonnet\n",
       "6                   claude-35-sonnet\n",
       "7                   claude-37-sonnet\n",
       "8                             cohere\n",
       "9                      mistral-large\n",
       "10                           gpt-gov\n",
       "11                          gpt4-gov\n",
       "12                               gpt\n",
       "13                              gpt4\n",
       "14                         gpt35-16k\n",
       "15                            gpt-4o\n",
       "16                       gpt-4o-mini\n",
       "17                          dall-e-3\n",
       "18                   gpt-4.5-preview\n",
       "19                 google-gemini-pro\n",
       "20            google-gemini-20-flash\n",
       "21                   google-imagen-3\n",
       "22                        gpt-4o-gov\n",
       "23                   gpt-4o-mini-gov\n",
       "24                          groq-70b\n",
       "25                      groq-llama33\n",
       "26                 groq-llama4-scout\n",
       "27                     groq-deepseek\n",
       "28                            gpt-o1\n",
       "29                       gpt-o3-mini\n",
       "30                       gpt-image-1\n",
       "31                          xai-grok"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch the list of models available for the user\n",
    "response = ask_sage_client.get_models()\n",
    "\n",
    "# Check if the response contains the expected 'response' key\n",
    "if 'response' in response:\n",
    "    models = response['response']\n",
    "    \n",
    "    # Convert the models list into a DataFrame for better visualization\n",
    "    models_df = pd.DataFrame(models)\n",
    "    print('Models available for the user on the respetive Ask Sage Tenant/Account:')\n",
    "    print('--------------------------------------------------')\n",
    "    display(models_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Models available to users can be limited/restricted if they are part of a enterprise account. Admins/account owners can restrict access to certain models.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> For more information on the models, please refer to the Ask Sage `Help` section in the platform and navigate to the `Models` tab. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> The list of models provided in the output are the names of which users will need to define using other endpoints such as `query`, where model = 'model_name'. (e.g. model = 'gpt-4o-mini-gov', model = 'aws-bedrock-claude-35-sonnet-gov', etc.)\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>WARNING:</b> Models do become deprecated and are removed from the list of available models. If you are using a model that is deprecated, you will need to update your code to use a different model. Especially for models that are not open source.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get User Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint returns the last 100 prompts of the user. \n",
    "\n",
    "There are no parameters required for this endpoint. \n",
    "\n",
    "The output will be the following:\n",
    "- All the prompts that the user has made.\n",
    "- completion_tokens: The completion tokens of the prompt.\n",
    "- date_time: The date and time of the prompt.\n",
    "- id: The ID of the prompt.\n",
    "- ip: The IP address of the prompt.\n",
    "- model: The model used for the prompt.\n",
    "- prompt: The prompt text.\n",
    "- prompt_tokens: The prompt tokens.\n",
    "- response: The response text.\n",
    "- teach: The teach flag (true or false).\n",
    "- total_tokens: The total tokens \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Uncomment the `display` call to see the output of the endpoint in the cell below. It was intentionally commented out to avoid showing the output in the notebook. \n",
    "\n",
    "Also, be aware that this endpoint outputs the last 100 prompts that the user has made, which may contain sensitive information. Therefore, it is recommended to use this endpoint with caution and avoid displaying the output in a shared notebook.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>WARNING:</b> The output of this endpoint could contain sensitive information. Please be cautious when displaying the output in a shared notebook. \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total logs retrieved: 100\n"
     ]
    }
   ],
   "source": [
    "# Fetch user logs using the AskSage client\n",
    "user_logs = ask_sage_client.get_user_logs()\n",
    "\n",
    "# print(user_logs)  # Uncomment this line to see the raw user logs. \n",
    "\n",
    "# Check if logs are available and display them\n",
    "if user_logs and 'response' in user_logs:\n",
    "    print(f\"Total logs retrieved: {len(user_logs['response'])}\")\n",
    "    # display(pd.DataFrame(user_logs['response']).head(10))  # Display the first 10 logs in a DataFrame - Uncomment this line to see the logs\n",
    "else:\n",
    "    print(\"No user logs found or response key missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get User Logins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint returns the last logins of the user. By default, it returns the last 5 logins.\n",
    "\n",
    "The only parameter required for this endpoint is the 'limit' parameter, which specifies the number of logins to return. The default value is 5 and the maximum value is 100.\n",
    "\n",
    "So in return, one will get the following information: \n",
    "- date_time: The date and time of the login.\n",
    "- id: The ID of the login.\n",
    "- ip: The IP address of the login.\n",
    "- status: The status of the login (success or failure).\n",
    "- type: endpoint type (login).\n",
    "- status_code: The status code of the login (200 for success, 400 for failure).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Data is intentionally replaced with dummy data for security purposes and to avoid showing sensitive information (e.g. IP address, status code, ID, etc.).\n",
    "</div>\n",
    "\n",
    "The example provided is modified to show the output of the endpoint in a clean dataframe format - note we intentionally replaced the actual output with a dummy output for security purposes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu, 08 May 2025 21:42:04 GMT</td>\n",
       "      <td>56.171.16.40</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu, 08 May 2025 21:34:15 GMT</td>\n",
       "      <td>115.89.15.69</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu, 08 May 2025 21:26:33 GMT</td>\n",
       "      <td>116.157.217.231</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu, 08 May 2025 18:30:50 GMT</td>\n",
       "      <td>121.150.99.242</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu, 08 May 2025 16:48:53 GMT</td>\n",
       "      <td>57.120.247.18</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu, 08 May 2025 15:44:32 GMT</td>\n",
       "      <td>110.194.177.232</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thu, 08 May 2025 15:43:08 GMT</td>\n",
       "      <td>130.134.193.133</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thu, 08 May 2025 15:42:33 GMT</td>\n",
       "      <td>208.207.236.203</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thu, 08 May 2025 15:26:25 GMT</td>\n",
       "      <td>30.80.30.128</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thu, 08 May 2025 15:08:03 GMT</td>\n",
       "      <td>228.250.203.82</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thu, 08 May 2025 14:12:41 GMT</td>\n",
       "      <td>198.193.19.254</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thu, 08 May 2025 14:01:04 GMT</td>\n",
       "      <td>146.231.244.114</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wed, 07 May 2025 21:31:41 GMT</td>\n",
       "      <td>119.14.151.206</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wed, 07 May 2025 19:32:51 GMT</td>\n",
       "      <td>44.123.31.170</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wed, 07 May 2025 19:32:43 GMT</td>\n",
       "      <td>184.169.57.49</td>\n",
       "      <td>111111</td>\n",
       "      <td>Failure</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wed, 07 May 2025 19:32:27 GMT</td>\n",
       "      <td>106.238.7.4</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wed, 07 May 2025 19:28:16 GMT</td>\n",
       "      <td>106.116.106.18</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wed, 07 May 2025 18:55:13 GMT</td>\n",
       "      <td>146.19.166.186</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tue, 06 May 2025 21:43:16 GMT</td>\n",
       "      <td>124.123.169.14</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tue, 06 May 2025 21:39:08 GMT</td>\n",
       "      <td>11.73.76.59</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tue, 06 May 2025 18:20:23 GMT</td>\n",
       "      <td>96.69.12.216</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tue, 06 May 2025 16:06:11 GMT</td>\n",
       "      <td>87.175.24.77</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tue, 06 May 2025 14:33:25 GMT</td>\n",
       "      <td>223.83.18.140</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tue, 06 May 2025 14:33:14 GMT</td>\n",
       "      <td>196.191.205.22</td>\n",
       "      <td>111111</td>\n",
       "      <td>Failure</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tue, 06 May 2025 14:32:22 GMT</td>\n",
       "      <td>184.168.165.195</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tue, 06 May 2025 13:37:09 GMT</td>\n",
       "      <td>5.113.129.83</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mon, 05 May 2025 21:56:52 GMT</td>\n",
       "      <td>237.52.38.207</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mon, 05 May 2025 15:50:45 GMT</td>\n",
       "      <td>241.231.229.208</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mon, 05 May 2025 15:11:17 GMT</td>\n",
       "      <td>243.43.151.134</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mon, 05 May 2025 14:34:14 GMT</td>\n",
       "      <td>46.41.77.164</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mon, 05 May 2025 14:33:57 GMT</td>\n",
       "      <td>130.28.110.181</td>\n",
       "      <td>111111</td>\n",
       "      <td>Failure</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mon, 05 May 2025 14:33:40 GMT</td>\n",
       "      <td>154.22.184.92</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fri, 02 May 2025 21:51:56 GMT</td>\n",
       "      <td>45.195.81.206</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Fri, 02 May 2025 21:41:33 GMT</td>\n",
       "      <td>80.107.209.15</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, 02 May 2025 20:31:41 GMT</td>\n",
       "      <td>188.153.15.137</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fri, 02 May 2025 14:11:37 GMT</td>\n",
       "      <td>58.223.83.99</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Fri, 02 May 2025 14:10:45 GMT</td>\n",
       "      <td>241.155.114.67</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Thu, 01 May 2025 13:16:59 GMT</td>\n",
       "      <td>165.110.135.114</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Thu, 01 May 2025 12:55:26 GMT</td>\n",
       "      <td>7.239.154.107</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Thu, 01 May 2025 12:55:19 GMT</td>\n",
       "      <td>142.123.253.70</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Thu, 01 May 2025 12:55:13 GMT</td>\n",
       "      <td>130.114.156.226</td>\n",
       "      <td>111111</td>\n",
       "      <td>Failure</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Thu, 01 May 2025 12:55:07 GMT</td>\n",
       "      <td>67.48.6.155</td>\n",
       "      <td>111111</td>\n",
       "      <td>Failure</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Thu, 01 May 2025 12:54:44 GMT</td>\n",
       "      <td>240.28.97.223</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Thu, 01 May 2025 12:40:27 GMT</td>\n",
       "      <td>117.5.194.103</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Thu, 01 May 2025 12:39:27 GMT</td>\n",
       "      <td>73.241.112.137</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>login_with_mfa_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Wed, 30 Apr 2025 21:15:20 GMT</td>\n",
       "      <td>198.199.114.182</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Wed, 30 Apr 2025 20:31:37 GMT</td>\n",
       "      <td>201.150.138.29</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wed, 30 Apr 2025 19:34:40 GMT</td>\n",
       "      <td>92.25.69.46</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wed, 30 Apr 2025 18:49:15 GMT</td>\n",
       "      <td>59.127.249.117</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wed, 30 Apr 2025 18:13:36 GMT</td>\n",
       "      <td>161.176.21.145</td>\n",
       "      <td>111111</td>\n",
       "      <td>Success</td>\n",
       "      <td>get_token_with_api_key</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date_time       ip_address      id   status  \\\n",
       "0   Thu, 08 May 2025 21:42:04 GMT     56.171.16.40  111111  Success   \n",
       "1   Thu, 08 May 2025 21:34:15 GMT     115.89.15.69  111111  Success   \n",
       "2   Thu, 08 May 2025 21:26:33 GMT  116.157.217.231  111111  Success   \n",
       "3   Thu, 08 May 2025 18:30:50 GMT   121.150.99.242  111111  Success   \n",
       "4   Thu, 08 May 2025 16:48:53 GMT    57.120.247.18  111111  Success   \n",
       "5   Thu, 08 May 2025 15:44:32 GMT  110.194.177.232  111111  Success   \n",
       "6   Thu, 08 May 2025 15:43:08 GMT  130.134.193.133  111111  Success   \n",
       "7   Thu, 08 May 2025 15:42:33 GMT  208.207.236.203  111111  Success   \n",
       "8   Thu, 08 May 2025 15:26:25 GMT     30.80.30.128  111111  Success   \n",
       "9   Thu, 08 May 2025 15:08:03 GMT   228.250.203.82  111111  Success   \n",
       "10  Thu, 08 May 2025 14:12:41 GMT   198.193.19.254  111111  Success   \n",
       "11  Thu, 08 May 2025 14:01:04 GMT  146.231.244.114  111111  Success   \n",
       "12  Wed, 07 May 2025 21:31:41 GMT   119.14.151.206  111111  Success   \n",
       "13  Wed, 07 May 2025 19:32:51 GMT    44.123.31.170  111111  Success   \n",
       "14  Wed, 07 May 2025 19:32:43 GMT    184.169.57.49  111111  Failure   \n",
       "15  Wed, 07 May 2025 19:32:27 GMT      106.238.7.4  111111  Success   \n",
       "16  Wed, 07 May 2025 19:28:16 GMT   106.116.106.18  111111  Success   \n",
       "17  Wed, 07 May 2025 18:55:13 GMT   146.19.166.186  111111  Success   \n",
       "18  Tue, 06 May 2025 21:43:16 GMT   124.123.169.14  111111  Success   \n",
       "19  Tue, 06 May 2025 21:39:08 GMT      11.73.76.59  111111  Success   \n",
       "20  Tue, 06 May 2025 18:20:23 GMT     96.69.12.216  111111  Success   \n",
       "21  Tue, 06 May 2025 16:06:11 GMT     87.175.24.77  111111  Success   \n",
       "22  Tue, 06 May 2025 14:33:25 GMT    223.83.18.140  111111  Success   \n",
       "23  Tue, 06 May 2025 14:33:14 GMT   196.191.205.22  111111  Failure   \n",
       "24  Tue, 06 May 2025 14:32:22 GMT  184.168.165.195  111111  Success   \n",
       "25  Tue, 06 May 2025 13:37:09 GMT     5.113.129.83  111111  Success   \n",
       "26  Mon, 05 May 2025 21:56:52 GMT    237.52.38.207  111111  Success   \n",
       "27  Mon, 05 May 2025 15:50:45 GMT  241.231.229.208  111111  Success   \n",
       "28  Mon, 05 May 2025 15:11:17 GMT   243.43.151.134  111111  Success   \n",
       "29  Mon, 05 May 2025 14:34:14 GMT     46.41.77.164  111111  Success   \n",
       "30  Mon, 05 May 2025 14:33:57 GMT   130.28.110.181  111111  Failure   \n",
       "31  Mon, 05 May 2025 14:33:40 GMT    154.22.184.92  111111  Success   \n",
       "32  Fri, 02 May 2025 21:51:56 GMT    45.195.81.206  111111  Success   \n",
       "33  Fri, 02 May 2025 21:41:33 GMT    80.107.209.15  111111  Success   \n",
       "34  Fri, 02 May 2025 20:31:41 GMT   188.153.15.137  111111  Success   \n",
       "35  Fri, 02 May 2025 14:11:37 GMT     58.223.83.99  111111  Success   \n",
       "36  Fri, 02 May 2025 14:10:45 GMT   241.155.114.67  111111  Success   \n",
       "37  Thu, 01 May 2025 13:16:59 GMT  165.110.135.114  111111  Success   \n",
       "38  Thu, 01 May 2025 12:55:26 GMT    7.239.154.107  111111  Success   \n",
       "39  Thu, 01 May 2025 12:55:19 GMT   142.123.253.70  111111  Success   \n",
       "40  Thu, 01 May 2025 12:55:13 GMT  130.114.156.226  111111  Failure   \n",
       "41  Thu, 01 May 2025 12:55:07 GMT      67.48.6.155  111111  Failure   \n",
       "42  Thu, 01 May 2025 12:54:44 GMT    240.28.97.223  111111  Success   \n",
       "43  Thu, 01 May 2025 12:40:27 GMT    117.5.194.103  111111  Success   \n",
       "44  Thu, 01 May 2025 12:39:27 GMT   73.241.112.137  111111  Success   \n",
       "45  Wed, 30 Apr 2025 21:15:20 GMT  198.199.114.182  111111  Success   \n",
       "46  Wed, 30 Apr 2025 20:31:37 GMT   201.150.138.29  111111  Success   \n",
       "47  Wed, 30 Apr 2025 19:34:40 GMT      92.25.69.46  111111  Success   \n",
       "48  Wed, 30 Apr 2025 18:49:15 GMT   59.127.249.117  111111  Success   \n",
       "49  Wed, 30 Apr 2025 18:13:36 GMT   161.176.21.145  111111  Success   \n",
       "\n",
       "                      type  \n",
       "0   get_token_with_api_key  \n",
       "1   get_token_with_api_key  \n",
       "2   get_token_with_api_key  \n",
       "3   get_token_with_api_key  \n",
       "4   get_token_with_api_key  \n",
       "5   get_token_with_api_key  \n",
       "6         login_with_mfa_2  \n",
       "7         login_with_mfa_1  \n",
       "8   get_token_with_api_key  \n",
       "9   get_token_with_api_key  \n",
       "10  get_token_with_api_key  \n",
       "11  get_token_with_api_key  \n",
       "12  get_token_with_api_key  \n",
       "13        login_with_mfa_2  \n",
       "14        login_with_mfa_2  \n",
       "15        login_with_mfa_1  \n",
       "16  get_token_with_api_key  \n",
       "17  get_token_with_api_key  \n",
       "18  get_token_with_api_key  \n",
       "19  get_token_with_api_key  \n",
       "20  get_token_with_api_key  \n",
       "21  get_token_with_api_key  \n",
       "22        login_with_mfa_2  \n",
       "23        login_with_mfa_2  \n",
       "24        login_with_mfa_1  \n",
       "25  get_token_with_api_key  \n",
       "26  get_token_with_api_key  \n",
       "27  get_token_with_api_key  \n",
       "28  get_token_with_api_key  \n",
       "29        login_with_mfa_2  \n",
       "30        login_with_mfa_2  \n",
       "31        login_with_mfa_1  \n",
       "32  get_token_with_api_key  \n",
       "33  get_token_with_api_key  \n",
       "34  get_token_with_api_key  \n",
       "35        login_with_mfa_2  \n",
       "36        login_with_mfa_1  \n",
       "37  get_token_with_api_key  \n",
       "38        login_with_mfa_2  \n",
       "39        login_with_mfa_1  \n",
       "40        login_with_mfa_2  \n",
       "41        login_with_mfa_2  \n",
       "42        login_with_mfa_1  \n",
       "43        login_with_mfa_2  \n",
       "44        login_with_mfa_1  \n",
       "45  get_token_with_api_key  \n",
       "46  get_token_with_api_key  \n",
       "47  get_token_with_api_key  \n",
       "48  get_token_with_api_key  \n",
       "49  get_token_with_api_key  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch user login data using the AskSage client\n",
    "user_logins = ask_sage_client.get_user_logins(limit=50)\n",
    "\n",
    "# Check if the response contains login data\n",
    "if user_logins and 'response' in user_logins:\n",
    "    # Extract relevant fields and replace sensitive data with mock values\n",
    "    extracted_data = [\n",
    "        {\n",
    "            'date_time': entry['date_time'],\n",
    "            'ip_address': '.'.join([str(random.randint(0, 255)) for _ in range(4)]),  # Mock IP address for privacy\n",
    "            'id': '111111',  # Mock ID for privacy\n",
    "            'status': entry['status'],\n",
    "            'type': entry['type']\n",
    "        }\n",
    "        for entry in user_logins['response']\n",
    "    ]\n",
    "\n",
    "    # Convert extracted data into a DataFrame for better visualization\n",
    "    user_logins_df = pd.DataFrame(extracted_data)\n",
    "    display(user_logins_df)\n",
    "else:\n",
    "    print(\"No user login data found or response key missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Count Monthly Tokens\n",
    "\n",
    "Get the count of monthly `inference tokens` spent in the current month.\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "### Additional Information on Tokens within Ask Sage\n",
    "\n",
    "<b> Ask Sage Tokens Overview </b>\n",
    "\n",
    "Ask Sage tokens are the primary means of accessing the Ask Sage platform and function as its currency. In the context of Generative Artificial Intelligence (GenAI), a token represents a unit of text that the model processes. Tokens can vary in length, ranging from a single character to an entire word, depending on the language and the model's implementation.\n",
    "\n",
    "<b> Token Allocation </b>\n",
    "\n",
    "For users of Ask Sage, tokens are allocated based on their subscription plan and can be used for various platform features, such as training models and making inferences. There are two main categories of tokens:\n",
    "\n",
    "1. Inference Tokens\n",
    "   - **Purpose**: Used to make predictions or inferences using the models available on the platform.\n",
    "   - **Consumption**: These tokens are consumed when users submit prompts or interact with the models in any way that requires processing text data.\n",
    "\n",
    "2. Training Tokens\n",
    "   - **Purpose**: Used to create training datasets in the Ask Sage platform.\n",
    "   - **Consumption**: These tokens are consumed when users upload data to a dataset for training purposes.\n",
    "\n",
    "\n",
    "Reference the following link for more information on Ask Sage tokens: https://docs.asksage.ai/docs/asksage-platform/%20asksage-tokens.html\n",
    "\n",
    "<b> Token Replenishment <b> \n",
    "\n",
    "Tokens replenish automatically on the first day of each month. Users can also purchase additional tokens if needed.\n",
    "\n",
    "--------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of monthly inference/query tokens used are: 1418083\n"
     ]
    }
   ],
   "source": [
    "def get_monthly_token_usage(client):\n",
    "    \"\"\"\n",
    "    Retrieves and prints the count of monthly inference/query tokens used.\n",
    "\n",
    "    Args:\n",
    "        client: The Ask Sage client instance.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of monthly inference/query tokens used.\n",
    "    \"\"\"\n",
    "    count_monthly_usage = client.count_monthly_tokens()  # Get the count of monthly tokens used\n",
    "    count = count_monthly_usage['response']  # Extract the count from the response\n",
    "    print(f\"The count of monthly inference/query tokens used are: {count}\")\n",
    "    return count\n",
    "\n",
    "count_start = get_monthly_token_usage(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Count Monthly Teach Tokens\n",
    "\n",
    "Get the count of monthly `teach tokens` spent in the current month. `teach tokens` are the same as `training tokens` and are used to create `Ask Sage datasets`.\n",
    "\n",
    "`Ask Sage datasets` are used to perform RAG(Retrieval-Augmented Generation) where the model retrieves information from the dataset to generate responses leveraging sophisticated semantic search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of monthly teach/training tokens used are: 49480\n"
     ]
    }
   ],
   "source": [
    "def get_monthly_teach_token_usage(client):\n",
    "    \"\"\"\n",
    "    Retrieves and prints the count of monthly teach/training tokens used.\n",
    "\n",
    "    Args:\n",
    "        client: The Ask Sage client instance.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of monthly teach/training tokens used.\n",
    "    \"\"\"\n",
    "    count_monthly_usage = client.count_monthly_teach_tokens()  # Get the count of monthly teach tokens used\n",
    "    count_training_tokens_starting = count_monthly_usage['response']  # Extract the count from the response\n",
    "    print(f\"The count of monthly teach/training tokens used are: {count_training_tokens_starting}\")\n",
    "    return count_training_tokens_starting\n",
    "\n",
    "count_training_tokens_starting = get_monthly_teach_token_usage(ask_sage_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Function - Combination of Monthly Tokens and Teach Tokens Call\n",
    "\n",
    "See below function to get the count of monthly and teach tokens spent - this will be used throughout the notebook to get the monthly tokens and teach tokens spent as one progresses through the notebook: \n",
    "- Comparing the monthly tokens and teach tokens spent at start versus current stage of the notebook.\n",
    "- Comparing the monthly tokens and teach tokens spent at the current stage of the notebook versus the previous stage of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Token Volume Report  (Stage #1)\n",
      "--------------------------------------------------\n",
      "The count of monthly teach/training tokens used are: 49480\n",
      "The count of monthly inference/query tokens used are: 1418083\n",
      " Token volume at the *start* of script recorded.\n",
      "The count of monthly teach/training tokens used are: 49480\n",
      "The count of monthly inference/query tokens used are: 1418083\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " No prior stage available for difference comparison.\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "End (Stage #1)           49480       1418083\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  1)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td> No Change</td>\n",
       "      <td> No Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  1)                 0                 0        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  1)        No Change  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 0, 'query_tokens_used': 0}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 0}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def collect_token_counts(client):\n",
    "    \"\"\"\n",
    "    Returns a dict with the exact structure expected by the reporting\n",
    "    function, using the two existing helpers above.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"teach_tokens\": get_monthly_teach_token_usage(client),\n",
    "        \"query_tokens\": get_monthly_token_usage(client)\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Global state\n",
    "# ------------------------------------------------------------------\n",
    "token_counts_start = None    # first snapshot taken the first time we run\n",
    "token_usage_history = []     # list of {\"start\":, \"end\":} per stage\n",
    "stage_counter = 0\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  Reporting function  now calls collect_token_counts()\n",
    "# ------------------------------------------------------------------\n",
    "def print_token_volume_report(client):\n",
    "    \"\"\"\n",
    "    Prints a multi-stage token-usage report that compares the very first\n",
    "    snapshot, the previous stage, and the current end of script.\n",
    "    \"\"\"\n",
    "    global token_counts_start, token_usage_history, stage_counter\n",
    "\n",
    "    stage_counter += 1\n",
    "    print(f\"\\n Token Volume Report  (Stage #{stage_counter})\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # --- 4-a. First-run initialization ---------------------------------\n",
    "    if token_counts_start is None:\n",
    "        token_counts_start = collect_token_counts(client)\n",
    "        print(\" Token volume at the *start* of script recorded.\")\n",
    "    else:\n",
    "        print(\" Reusing token volume from script start.\")\n",
    "\n",
    "    # --- 4-b. Current end-of-stage snapshot ----------------------------\n",
    "    token_counts_end = collect_token_counts(client)\n",
    "    print(\" Token volume recorded *after current script execution*.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # --- 4-c. Store history --------------------------------------------\n",
    "    token_usage_history.append({\n",
    "        \"start\": token_counts_start,\n",
    "        \"end\"  : token_counts_end\n",
    "    })\n",
    "\n",
    "    # --- 4-d. Differences vs prior end ---------------------------------\n",
    "    if len(token_usage_history) > 1:\n",
    "        prior_end   = token_usage_history[-2][\"end\"]\n",
    "        prior_stage = stage_counter - 1\n",
    "        print(f\" Change from Prior End (Stage #{prior_stage})  \"\n",
    "              f\"Current End (Stage #{stage_counter}):\")\n",
    "        print({\n",
    "            \"teach_tokens_diff\": token_counts_end[\"teach_tokens\"]\n",
    "                                 - prior_end[\"teach_tokens\"],\n",
    "            \"query_tokens_diff\": token_counts_end[\"query_tokens\"]\n",
    "                                 - prior_end[\"query_tokens\"],\n",
    "        })\n",
    "    else:\n",
    "        print(\" No prior stage available for difference comparison.\")\n",
    "\n",
    "    # --- 4-e. Pretty tables --------------------------------------------\n",
    "    start_df = pd.DataFrame([token_counts_start],\n",
    "                            index=[f\"Start (Stage #1)\"])\n",
    "    end_df   = pd.DataFrame([token_counts_end],\n",
    "                            index=[f\"End (Stage #{stage_counter})\"])\n",
    "    frames   = [start_df]\n",
    "    if len(token_usage_history) > 1:\n",
    "        prior_df = pd.DataFrame([prior_end],\n",
    "                                index=[f\"Prior (Stage #{prior_stage})\"])\n",
    "        frames.append(prior_df)\n",
    "    frames.append(end_df)\n",
    "\n",
    "    print(\" Token Usage Table:\")\n",
    "    print(pd.concat(frames))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # --- 4-f. Comparison flags -----------------------------------------\n",
    "    def diff_flags(a, b):\n",
    "        return {\n",
    "            \"teach_tokens_diff\": a[\"teach_tokens\"] - b[\"teach_tokens\"],\n",
    "            \"query_tokens_diff\": a[\"query_tokens\"] - b[\"query_tokens\"],\n",
    "            \"teach_tokens_flag\": \" Changed\" if a[\"teach_tokens\"] != b[\"teach_tokens\"]\n",
    "                                 else \" No Change\",\n",
    "            \"query_tokens_flag\": \" Changed\" if a[\"query_tokens\"] != b[\"query_tokens\"]\n",
    "                                 else \" No Change\"\n",
    "        }\n",
    "\n",
    "    if len(token_usage_history) > 1:\n",
    "        comparison_df = pd.DataFrame({\n",
    "            f\"Start vs End (1  {stage_counter})\":\n",
    "                diff_flags(token_counts_end, token_counts_start),\n",
    "            f\"Prior vs End ({prior_stage}  {stage_counter})\":\n",
    "                diff_flags(token_counts_end, prior_end)\n",
    "        }).T\n",
    "    else:\n",
    "        comparison_df = pd.DataFrame({\n",
    "            f\"Start vs End (1  {stage_counter})\":\n",
    "                diff_flags(token_counts_end, token_counts_start)\n",
    "        }).T\n",
    "\n",
    "    print(\" Token Volume Comparison Flags:\")\n",
    "    display(comparison_df)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # --- 4-g. Volume used during this stage (relative to start) -------\n",
    "    stage_usage = {\n",
    "        \"teach_tokens_used\": token_counts_end[\"teach_tokens\"] - token_counts_start[\"teach_tokens\"],\n",
    "        \"query_tokens_used\": token_counts_end[\"query_tokens\"] - token_counts_start[\"query_tokens\"]\n",
    "    }\n",
    "\n",
    "    print(\" Total Token Volume Used Since Script Start:\")\n",
    "    print(stage_usage)\n",
    "    print(\"==================================================\")\n",
    "\n",
    "    # --- 4-h. Volume used in this specific stage only -------------------\n",
    "    if len(token_usage_history) > 1:\n",
    "        current_stage_start = token_usage_history[-2][\"end\"]\n",
    "    else:\n",
    "        current_stage_start = token_counts_start  # Fall back to start if this is stage 1\n",
    "\n",
    "    current_stage_usage = {\n",
    "        \"teach_tokens_used_this_stage\": token_counts_end[\"teach_tokens\"] - current_stage_start[\"teach_tokens\"],\n",
    "        \"query_tokens_used_this_stage\": token_counts_end[\"query_tokens\"] - current_stage_start[\"query_tokens\"]\n",
    "    }\n",
    "\n",
    "    print(\" Token Volume Used in This Stage Only:\")\n",
    "    print(current_stage_usage)\n",
    "    print(\"==================================================\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Get Personas\n",
    "\n",
    "This endpoint returns the available personas from the Ask Sage service. Users will have access to all the standard personas that are available in the Ask Sage service for all paid users, and any custom personas that have been created in the platform. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Custom personas can only be created by users within the Ask Sage platform and not through the API.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Recommend saving any system prompts as personas in the platform for future use. This will allow users to easily access the system prompts and use them in the platform. However, when using the API, we recommend using the `system_prompt` parameter instead of the `persona` parameter to have more control over the system prompt being used.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> The 'id' provided in the output of the endpoint for each persona is unique. When defining a persona in the `query` endpoint or any other endpoint that has the option, the user will need to use the 'id' of the persona not the name of the persona or else it will automatically default to the default persona. Example: persona = '1' or persona = '2' etc. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>Ask Sage</td>\n",
       "      <td>Use this persona when you need a general-purpose AI that can handle a wide range of tasks, from translating languages to writing essays and code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2</td>\n",
       "      <td>Legal Assistant</td>\n",
       "      <td>Use this persona when you need legal advice or information. This persona can provide accurate and helpful advice on a wide range of legal topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>3</td>\n",
       "      <td>Contracting Officer</td>\n",
       "      <td>Use this persona when you have questions or need advice about government contracts, Federal Acquisition Regulation (FAR) regulations, the Defense Federal Acquisition Regulation Supplement (DFARS) regulations and acquisition related questions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>4</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Use this persona when you need to write, review, or debug code. This persona can also provide advice on software development best practices and security standards.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>5</td>\n",
       "      <td>ISSO (Cyber)</td>\n",
       "      <td>Use this persona when you need advice or information about cybersecurity requirements and issues. This persona can provide accurate and helpful advice on a wide range of cybersecurity topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>6</td>\n",
       "      <td>System Administrator</td>\n",
       "      <td>Use this persona when you need advice or information about system designs, security, and issues. This persona can provide accurate and helpful advice on a wide range of system administration topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>7</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td>Use this persona when you need advice or information about structural engineering. This persona can provide accurate and helpful advice on a wide range of structural engineering topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>8</td>\n",
       "      <td>Electrical Engineer</td>\n",
       "      <td>Use this persona when you need advice or information about electrical engineering. This persona can provide accurate and helpful advice on a wide range of electrical engineering topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>9</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Use this persona when you need advice or information about financial matters. This persona can provide accurate and helpful advice on a wide range of accounting and financial topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>10</td>\n",
       "      <td>DevSecOps Engineer</td>\n",
       "      <td>Use this persona when you need advice or information about DevSecOps and software operations. This persona can provide accurate and helpful advice on a wide range of DevSecOps topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>11</td>\n",
       "      <td>Space Ops. Eng.</td>\n",
       "      <td>Use this persona when you need advice or information about space operations. This persona can provide accurate and helpful advice on a wide range of space operations topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>12</td>\n",
       "      <td>Ground Ops. Eng.</td>\n",
       "      <td>Use this persona when you need advice or information about ground operations. This persona can provide accurate and helpful advice on a wide range of ground operations topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>13</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Use this persona when you need advice or information about marketing and communication. This persona can provide accurate and helpful advice on a wide range of marketing and communication topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>14</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>Use this persona when you need advice or information about scientific research. This persona can provide accurate and helpful advice on a wide range of scientific topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>15</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>Use this persona when you need advice or information about project management. This persona can provide accurate and helpful advice on a wide range of project management topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>16</td>\n",
       "      <td>COR</td>\n",
       "      <td>Use this persona when you need advice or information about acquisition challenges and questions. This persona can provide accurate and helpful advice on a wide range of acquisition topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>17</td>\n",
       "      <td>Systems Engineer</td>\n",
       "      <td>Use this persona when you need advice or information about systems engineering. This persona can provide accurate and helpful advice on a wide range of systems engineering topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>18</td>\n",
       "      <td>MBSE</td>\n",
       "      <td>Use this persona when you need advice or information about modeling and simulation. This persona can provide accurate and helpful advice on a wide range of modeling and simulation topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>19</td>\n",
       "      <td>Medical Assistant</td>\n",
       "      <td>Use this persona when you need medical advice or information. This persona can provide accurate and helpful advice on a wide range of medical topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>20</td>\n",
       "      <td>Inspector General</td>\n",
       "      <td>Use this persona when you need advice or information about government operations, policies, procedures, and regulations. This persona can provide accurate and helpful advice on a wide range of government topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>21</td>\n",
       "      <td>Prompt Engineer</td>\n",
       "      <td>Use this persona when you need help crafting the best possible prompt for your needs. This persona can provide accurate and helpful advice on a wide range of prompt crafting topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>22</td>\n",
       "      <td>Ghostwriter</td>\n",
       "      <td>Use this persona when you need help with creative writing. This persona can provide accurate and helpful advice on a wide range of creative writing topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>23</td>\n",
       "      <td>OSCAL Eng.</td>\n",
       "      <td>Use this persona when you need advice or information about OSCAL controls, formats, and templates. This persona can provide accurate and helpful advice on a wide range of OSCAL topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>24</td>\n",
       "      <td>First Responder</td>\n",
       "      <td>Use this persona when you need advice or information about First Responder information, FEMA recommendations and actions that must be taken in case of a disaster or emergency.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>25</td>\n",
       "      <td>OPR/EPR Writer</td>\n",
       "      <td>Use this persona when you need help writing Officer Performance Reports (OPRs) and Enlisted Performance Reports (EPRs). This persona can provide accurate and helpful advice on a wide range of OPR and EPR writing topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>26</td>\n",
       "      <td>Decoration Writer</td>\n",
       "      <td>Use this persona when you need help writing decorations for government employees or military personnel. This persona can provide accurate and helpful advice on a wide range of decoration writing topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>27</td>\n",
       "      <td>Ask Sage French</td>\n",
       "      <td>Use this persona when you need a general-purpose AI that can handle a wide range of tasks in French, from translating languages to writing essays and code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>28</td>\n",
       "      <td>Negotiator</td>\n",
       "      <td>Use this persona when you need advice or information about negotiation skills. This persona can provide accurate and helpful advice on a wide range of negotiation topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>29</td>\n",
       "      <td>Creative Writer</td>\n",
       "      <td>Use this persona when you need advice or information about creative writing. This persona can provide accurate and helpful advice on a wide range of creative writing topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>30</td>\n",
       "      <td>Military Advisor</td>\n",
       "      <td>Use this persona when you need advice or information about military strategy and operations. This persona can provide accurate and helpful advice on a wide range of military topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>31</td>\n",
       "      <td>SEO Specialist</td>\n",
       "      <td>Use this persona when you need advice or information about SEO. This persona can provide accurate and helpful advice on a wide range of SEO topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>32</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Use this persona when you need advice or information about human resources. This persona can provide accurate and helpful advice on a wide range of human resources topics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>43</td>\n",
       "      <td>Solutions Architect</td>\n",
       "      <td>Use this persona when you need advice or information about solution architecture. This persona can provide accurate and helpful advice on a wide range of topics related to solution architecture, including cloud migration, advanced technology integration, and legacy system modernization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>116</td>\n",
       "      <td>Documentation Writer</td>\n",
       "      <td>Documentation expert with decades of experience in the field, responsible for ensuring that all documentation is factual, truthful and up to date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>109</td>\n",
       "      <td>AF EPB/OPBs</td>\n",
       "      <td>Write your Enlisted Performance Briefs (EPBs) and Officer Performance Briefs (OPB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>117</td>\n",
       "      <td>Compliance Expert</td>\n",
       "      <td>Cybersecurity compliance and documentation expert with decades of experience in the field for CMMC, ATOs, NIST, GDPR etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>176</td>\n",
       "      <td>USAF Acquisition Logistics</td>\n",
       "      <td>Use this persona if you need advice on USAF logistics support with the Department of Defense acquisition logistics framework.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        name  \\\n",
       "    1                    Ask Sage   \n",
       "    2             Legal Assistant   \n",
       "    3         Contracting Officer   \n",
       "    4          Software Developer   \n",
       "    5                ISSO (Cyber)   \n",
       "    6        System Administrator   \n",
       "    7         Structural Engineer   \n",
       "    8         Electrical Engineer   \n",
       "    9                  Accountant   \n",
       "   10          DevSecOps Engineer   \n",
       "   11             Space Ops. Eng.   \n",
       "   12            Ground Ops. Eng.   \n",
       "   13                   Marketing   \n",
       "   14                   Scientist   \n",
       "   15             Program Manager   \n",
       "   16                         COR   \n",
       "   17            Systems Engineer   \n",
       "   18                        MBSE   \n",
       "   19           Medical Assistant   \n",
       "   20           Inspector General   \n",
       "   21             Prompt Engineer   \n",
       "   22                 Ghostwriter   \n",
       "   23                  OSCAL Eng.   \n",
       "   24             First Responder   \n",
       "   25              OPR/EPR Writer   \n",
       "   26           Decoration Writer   \n",
       "   27             Ask Sage French   \n",
       "   28                  Negotiator   \n",
       "   29             Creative Writer   \n",
       "   30            Military Advisor   \n",
       "   31              SEO Specialist   \n",
       "   32             Human Resources   \n",
       "   43         Solutions Architect   \n",
       "  116        Documentation Writer   \n",
       "  109                 AF EPB/OPBs   \n",
       "  117           Compliance Expert   \n",
       "  176  USAF Acquisition Logistics   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                      description  \n",
       "                                                                                                                                                Use this persona when you need a general-purpose AI that can handle a wide range of tasks, from translating languages to writing essays and code.  \n",
       "                                                                                                                                                Use this persona when you need legal advice or information. This persona can provide accurate and helpful advice on a wide range of legal topics.  \n",
       "                                               Use this persona when you have questions or need advice about government contracts, Federal Acquisition Regulation (FAR) regulations, the Defense Federal Acquisition Regulation Supplement (DFARS) regulations and acquisition related questions.  \n",
       "                                                                                                                              Use this persona when you need to write, review, or debug code. This persona can also provide advice on software development best practices and security standards.  \n",
       "                                                                                                  Use this persona when you need advice or information about cybersecurity requirements and issues. This persona can provide accurate and helpful advice on a wide range of cybersecurity topics.  \n",
       "                                                                                           Use this persona when you need advice or information about system designs, security, and issues. This persona can provide accurate and helpful advice on a wide range of system administration topics.  \n",
       "                                                                                                        Use this persona when you need advice or information about structural engineering. This persona can provide accurate and helpful advice on a wide range of structural engineering topics.  \n",
       "                                                                                                        Use this persona when you need advice or information about electrical engineering. This persona can provide accurate and helpful advice on a wide range of electrical engineering topics.  \n",
       "                                                                                                           Use this persona when you need advice or information about financial matters. This persona can provide accurate and helpful advice on a wide range of accounting and financial topics.  \n",
       "                                                                                                          Use this persona when you need advice or information about DevSecOps and software operations. This persona can provide accurate and helpful advice on a wide range of DevSecOps topics.  \n",
       "                                                                                                                    Use this persona when you need advice or information about space operations. This persona can provide accurate and helpful advice on a wide range of space operations topics.  \n",
       "                                                                                                                  Use this persona when you need advice or information about ground operations. This persona can provide accurate and helpful advice on a wide range of ground operations topics.  \n",
       "                                                                                              Use this persona when you need advice or information about marketing and communication. This persona can provide accurate and helpful advice on a wide range of marketing and communication topics.  \n",
       "                                                                                                                       Use this persona when you need advice or information about scientific research. This persona can provide accurate and helpful advice on a wide range of scientific topics.  \n",
       "                                                                                                                Use this persona when you need advice or information about project management. This persona can provide accurate and helpful advice on a wide range of project management topics.  \n",
       "                                                                                                     Use this persona when you need advice or information about acquisition challenges and questions. This persona can provide accurate and helpful advice on a wide range of acquisition topics.  \n",
       "                                                                                                              Use this persona when you need advice or information about systems engineering. This persona can provide accurate and helpful advice on a wide range of systems engineering topics.  \n",
       "                                                                                                      Use this persona when you need advice or information about modeling and simulation. This persona can provide accurate and helpful advice on a wide range of modeling and simulation topics.  \n",
       "                                                                                                                                            Use this persona when you need medical advice or information. This persona can provide accurate and helpful advice on a wide range of medical topics.  \n",
       "                                                                              Use this persona when you need advice or information about government operations, policies, procedures, and regulations. This persona can provide accurate and helpful advice on a wide range of government topics.  \n",
       "                                                                                                            Use this persona when you need help crafting the best possible prompt for your needs. This persona can provide accurate and helpful advice on a wide range of prompt crafting topics.  \n",
       "                                                                                                                                      Use this persona when you need help with creative writing. This persona can provide accurate and helpful advice on a wide range of creative writing topics.  \n",
       "                                                                                                         Use this persona when you need advice or information about OSCAL controls, formats, and templates. This persona can provide accurate and helpful advice on a wide range of OSCAL topics.  \n",
       "                                                                                                                  Use this persona when you need advice or information about First Responder information, FEMA recommendations and actions that must be taken in case of a disaster or emergency.  \n",
       "                                                                      Use this persona when you need help writing Officer Performance Reports (OPRs) and Enlisted Performance Reports (EPRs). This persona can provide accurate and helpful advice on a wide range of OPR and EPR writing topics.  \n",
       "                                                                                       Use this persona when you need help writing decorations for government employees or military personnel. This persona can provide accurate and helpful advice on a wide range of decoration writing topics.  \n",
       "                                                                                                                                      Use this persona when you need a general-purpose AI that can handle a wide range of tasks in French, from translating languages to writing essays and code.  \n",
       "                                                                                                                       Use this persona when you need advice or information about negotiation skills. This persona can provide accurate and helpful advice on a wide range of negotiation topics.  \n",
       "                                                                                                                    Use this persona when you need advice or information about creative writing. This persona can provide accurate and helpful advice on a wide range of creative writing topics.  \n",
       "                                                                                                            Use this persona when you need advice or information about military strategy and operations. This persona can provide accurate and helpful advice on a wide range of military topics.  \n",
       "                                                                                                                                              Use this persona when you need advice or information about SEO. This persona can provide accurate and helpful advice on a wide range of SEO topics.  \n",
       "                                                                                                                      Use this persona when you need advice or information about human resources. This persona can provide accurate and helpful advice on a wide range of human resources topics.  \n",
       "  Use this persona when you need advice or information about solution architecture. This persona can provide accurate and helpful advice on a wide range of topics related to solution architecture, including cloud migration, advanced technology integration, and legacy system modernization.  \n",
       "                                                                                                                                               Documentation expert with decades of experience in the field, responsible for ensuring that all documentation is factual, truthful and up to date.  \n",
       "                                                                                                                                                                                                               Write your Enlisted Performance Briefs (EPBs) and Officer Performance Briefs (OPB)  \n",
       "                                                                                                                                                                       Cybersecurity compliance and documentation expert with decades of experience in the field for CMMC, ATOs, NIST, GDPR etc.   \n",
       "                                                                                                                                                                    Use this persona if you need advice on USAF logistics support with the Department of Defense acquisition logistics framework.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the personas using the get_personas endpoint\n",
    "get_personas = ask_sage_client.get_personas()\n",
    "\n",
    "# Extract relevant information from the response\n",
    "def extract_personas(response):\n",
    "    return [\n",
    "        {\n",
    "            'id': persona['id'],\n",
    "            'name': persona['name'],\n",
    "            'description': persona['description']\n",
    "        }\n",
    "        for persona in response['response']\n",
    "    ]\n",
    "\n",
    "# Extract the personas using the extract_personas function\n",
    "personas = extract_personas(get_personas)\n",
    "\n",
    "# Putting all information into a DataFrame\n",
    "personas_df = pd.DataFrame(personas)\n",
    "\n",
    "# Remove the index column for display\n",
    "personas_df.index = personas_df.index.map(lambda _: '')\n",
    "\n",
    "# Set column width to display full content and enable word wrapping\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(personas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tokenizer\n",
    "\n",
    "This endpoint is used to interact with the `/tokenizer` endpoint of the Ask Sage API. It is used to tokenize the text data provided to the model. \n",
    "\n",
    "A token is a unit of text that the model processes. Tokens can vary in length, ranging from a single character to an entire word, depending on the language and the model's implementation. A good rule of thumb is 1 token is equivalent to 3.7 english characters.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> The `tokenizer` endpoint is useful in estimating the number of tokens that will be used for a given text. This can be helpful in managing the number of tokens used when prompting a model. Key is it's an estimate and not an exact number. \n",
    "</div>\n",
    "\n",
    "In the example provided below, we tokenize 3 different texts to see the number of tokens used for each text. Feel free to modify the text to see the number of tokens used for different text inputs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The number of tokens in the text is: 84 Tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The number of tokens in the text is: 13 Tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The number of tokens in the text is: 24 Tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Total number of tokens across all texts: 121 Tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"This endpoint is used to interact with the /tokenizer endpoint of the Ask Sage API. It is used to tokenize the text provided to the model. The tokenizer is used to split the text into tokens that the model can understand and process. The tokenizer is used to preprocess the text before it is passed to the model for processing. Thus in return the output will be the tokens of the text provided.\",\n",
    "    \"Ask Sage is a GenAI Platform.\",\n",
    "    \"{ sdfd < > ? / . , ; : ' \\\" [ ] { } ( ) }\"\n",
    "]\n",
    "\n",
    "total_tokens = 0\n",
    "\n",
    "for text in texts:\n",
    "    tokenize_data = ask_sage_client.tokenizer(text)  # Tokenize the text using the tokenizer method\n",
    "    # Uncomment the next line to display the raw response\n",
    "    # display(tokenize_data)  \n",
    "    tokens_count = tokenize_data['response']  # Assuming 'response' contains the token count\n",
    "    total_tokens += int(tokens_count)  # Accumulate the total number of tokens\n",
    "    display(f'The number of tokens in the text is: {tokens_count} Tokens')\n",
    "\n",
    "display(f'Total number of tokens across all texts: {total_tokens} Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Token Volume Report  (Stage #2)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 49480\n",
      "The count of monthly inference/query tokens used are: 1418083\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #1)  Current End (Stage #2):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 0}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #1)         49480       1418083\n",
      "End (Stage #2)           49480       1418083\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  2)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td> No Change</td>\n",
       "      <td> No Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (1  2)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td> No Change</td>\n",
       "      <td> No Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  2)                 0                 0        No Change   \n",
       "Prior vs End (1  2)                 0                 0        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  2)        No Change  \n",
       "Prior vs End (1  2)        No Change  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 0, 'query_tokens_used': 0}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 0}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. File Endpoint\n",
    "\n",
    "The `file` endpoint is designed for extracting information from files, enabling seamless ingestion into Ask Sage. Below is a detailed overview of its functionality, parameters, and usage.\n",
    "\n",
    "### Parameters:\n",
    "- **`file_path` (str)**:  \n",
    "  Specifies the path to the file you want to upload. This should be a string representing the full file path.\n",
    "\n",
    "- **`strategy` (str, optional)**:  \n",
    "  Defines the parsing strategy to be used. Available options include:  \n",
    "  - `'auto'`: Default strategy that automatically selects the optimal parsing method.  \n",
    "  - `'fast'`: A quicker parsing method that may trade off some accuracy.  \n",
    "  - `'hi_res'`: A slower, high-accuracy method using Optical Character Recognition (OCR), ideal for image-based files.\n",
    "\n",
    "### Returns:\n",
    "The method returns a dictionary containing:\n",
    "- **`status`**: Indicates the success or failure of the operation.\n",
    "- **`data`**: Includes any extracted information from the file.\n",
    "\n",
    "---\n",
    "\n",
    "### Usage:\n",
    "The `file` endpoint is highly versatile for parsing and extracting text from various file types, such as PDFs, images, and documents. The extracted text can then be utilized in other endpoints, such as:\n",
    "- **`query_with_file`**: For querying extracted content.\n",
    "- **`train_with_file`**: For training datasets using the extracted content.\n",
    "\n",
    "This endpoint is particularly useful when working with Ask Sage **Plugins/Agents** to automate workflows involving file ingestion and processing.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Notes:\n",
    "1. **Data Ingestion**:  \n",
    "   The `file` endpoint is integral to ingesting data into Ask Sage. For example, you can parse a file and use the `Train` endpoint to assign its content to a dataset within Ask Sage.\n",
    "\n",
    "\n",
    "2. **Supported File Types**:  \n",
    "   Ask Sage supports a variety of file types. For a complete list, refer to the [Ask Sage Documentation](https://docs.asksage.ai/) or check directly within the Ask Sage platform. If you encounter issues with unsupported file types, contact Ask Sage support for assistance.\n",
    "\n",
    "3. **Image & Audio Files**:  \n",
    "   The `file` endpoint can also handle image and audio files, however when processing these files users will be charged for the inference tokens used to extract context from them. Therefore, image and audio files are more expensive to process than text files since they require inference tokens to extract the context from them.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Workflow:\n",
    "1. Use the `file` endpoint to parse a file and extract its content.\n",
    "2. Train or update embedding Ask Sage datasets with the extracted content via the `Train` endpoint.\n",
    "3. Perform retrieval-augmented generation (RAG) on the Ask Sage dataset with the embedding using the `query` endpoint.\n",
    "\n",
    "1. Parse a file using the `file` endpoint to extract its content.\n",
    "2. Combine the extracted content with a {prompt} and generate a response using the `query` endpoint.\n",
    "\n",
    "By understanding the `file` endpoint, you gain insight into how data ingestion works within Ask Sage, enabling efficient use of its services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'OK',\n",
       " 'ret': '{\"asksage_metadata\": {\"filename\": \"random_photo_2.png\", \"page_number\": \"1\"}}\\nThe image depicts a beautifully arranged charcuterie board placed on a wooden serving tray with black handles. The board is filled with a variety of snacks, cheeses, meats, vegetables, and dips, creating a colorful and appetizing display. Below is a detailed description of the components:\\n\\n### **Top Section:**\\n1. **Cheese and Meat Arrangement:**\\n   - Slices of white cheese are arranged in a semi-circle pattern.\\n   - Thinly folded slices of cured meat (likely salami or prosciutto) are placed next to the cheese, forming a decorative fan-like arrangement.\\n\\n2. **Three-Compartment Bowl:**\\n   - **Top Left Compartment:** Contains a mix of green and black olives.\\n   - **Top Right Compartment:** Contains marinated mozzarella balls sprinkled with herbs and spices.\\n   - **Bottom Compartment:** Contains hummus topped with a dollop of red chili sauce or salsa.\\n\\n### **Middle Section:**\\n1. **Vegetables:**\\n   - Slices of fresh cucumber are arranged in a neat pile.\\n   - Baby carrots are placed nearby, adding vibrant orange color.\\n\\n2. **Meats:**\\n   - Thinly sliced cured meats, including salami and possibly capicola, are layered neatly.\\n\\n3. **Crackers:**\\n   - A long row of round crackers runs diagonally across the board, creating a visual divider.\\n\\n### **Bottom Section:**\\n1. **Cherry Tomatoes:**\\n   - Halved cherry tomatoes are arranged in a cluster, showcasing their bright red color.\\n\\n2. **Sweet and Savory Snacks:**\\n   - Pretzels topped with chocolate and festive sprinkles (red, green, and white) are placed in a small group.\\n   - Chocolate-covered nuts or candies are scattered nearby.\\n\\n3. **Popcorn or Cheese Puffs:**\\n   - A pile of seasoned popcorn or cheese puffs adds a crunchy texture and golden-yellow color.\\n\\n### **Overall Presentation:**\\nThe board is thoughtfully arranged to balance colors, textures, and flavors. The wooden tray provides a rustic and elegant base, while the variety of items ensures a mix of sweet, savory, and fresh options. The marble-like surface beneath the tray complements the aesthetic of the presentation.',\n",
       " 'sent_filename': 'random_photo_2.png',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of chunks in random_photo_2.png is: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'OK',\n",
       " 'ret': '{\"asksage_metadata\": {\"filename\": \"ghi-780.png\", \"page_number\": \"1\"}}\\nThe image depicts a group of construction workers actively engaged in building the wooden framework of a house. The scene is outdoors, surrounded by trees, suggesting the construction site is in a rural or suburban area. The workers are wearing safety gear, including hard hats in various colors such as white, yellow, and green, which may indicate different roles or teams.\\n\\nThe structure being built appears to be a single-story house with a pitched roof. The workers are handling wooden trusses and beams, which form the skeleton of the roof. Some workers are standing on ladders or elevated platforms to position and secure the trusses, while others are on the ground lifting and stabilizing the beams. The teamwork is evident as they coordinate their efforts to align and assemble the framework.\\n\\nThe foundation of the house is visible, made of concrete, and the walls are constructed with wooden studs and sheathing. The workers are dressed in casual work attire, including jeans, t-shirts, and boots, with some wearing camouflage pants, suggesting a mix of civilian and possibly military personnel.\\n\\nThe environment is bright and sunny, with natural light illuminating the construction site. The trees in the background provide a lush green backdrop, adding to the sense of an open and natural setting. The image captures the collaborative effort and physical labor involved in the early stages of building a home.',\n",
       " 'sent_filename': 'ghi-780.png',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of chunks in ghi-780.png is: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'OK',\n",
       " 'ret': '\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 1}}\\n1 2 0 2\\nt c O 6 1\\n] L C . s c [\\n2 v 5 8 6 9 0 . 6 0 1 2 : v i X r a\\nLORA: LOW-RANK ADAPTATION OF LARGE LAN- GUAGE MODELS\\nEdward Hu Yuanzhi Li Microsoft Corporation {edwardhu, yeshe, phwallis, zeyuana, yuanzhil, swang, luw, wzchen}@microsoft.com yuanzhil@andrew.cmu.edu (Version 2)\\nYelong Shen Shean Wang\\nPhillip Wallis\\nZeyuan Allen-Zhu\\nLu Wang\\nWeizhu Chen\\nABSTRACT\\nAn important paradigm of natural language processing consists of large-scale pre- training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full ne-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example  deploying indepen- dent instances of ne-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre- trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable pa- rameters for downstream tasks. Compared to GPT-3 175B ne-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than ne- tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite hav- ing fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deciency in language model adaptation, which sheds light on the efcacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.\\n1\\nINTRODUCTION\\nMany applications in natural language processing rely on adapt- ing one large-scale, pre-trained language model to multiple down- stream applications. Such adaptation is usually done via ne-tuning, which updates all the parameters of the pre-trained model. The ma- jor downside of ne-tuning is that the new model contains as many parameters as in the original model. As larger models are trained every few months, this changes from a mere inconvenience for GPT-2 (Radford et al., b) or RoBERTa large (Liu et al., 2019) to a critical deployment challenge for GPT-3 (Brown et al., 2020) with 175 billion trainable parameters.1\\n\\n=(0,2)\\nh\\nx\\n=0\\nf(x)\\nPretrained Weights\\nx\\nPretrained Weights\\n\\n\\nMany sought to mitigate this by adapting only some parameters or learning external modules for new tasks. This way, we only need to store and load a small number of task-specic parameters in ad- dition to the pre-trained model for each task, greatly boosting the operational efciency when deployed. However, existing techniques\\nFigure 1: Our reparametriza- tion. We only train A and B.\\nEqual contribution. 0Compared to V1, this draft includes better baselines, experiments on GLUE, and more on adapter latency. 1While GPT-3 175B achieves non-trivial performance with few-shot learning, ne-tuning boosts its perfor-\\nmance signicantly as shown in Appendix A.\\n1\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 2}}\\noften introduce inference latency (Houlsby et al., 2019; Rebuf et al., 2017) by extending model depth or reduce the models usable sequence length (Li & Liang, 2021; Lester et al., 2021; Ham- bardzumyan et al., 2020; Liu et al., 2021) (Section 3). More importantly, these method often fail to match the ne-tuning baselines, posing a trade-off between efciency and model quality.\\nWe take inspiration from Li et al. (2018a); Aghajanyan et al. (2020) which show that the learned over-parametrized models in fact reside on a low intrinsic dimension. We hypothesize that the change in weights during model adaptation also has a low intrinsic rank, leading to our proposed Low-Rank Adaptation (LoRA) approach. LoRA allows us to train some dense layers in a neural network indirectly by optimizing rank decomposition matrices of the dense layers change during adaptation instead, while keeping the pre-trained weights frozen, as shown in Figure 1. Using GPT-3 175B as an example, we show that a very low rank (i.e., r in Figure 1 can be one or two) sufces even when the full rank (i.e., d) is as high as 12,288, making LoRA both storage- and compute-efcient.\\nLoRA possesses several key advantages.\\nA pre-trained model can be shared and used to build many small LoRA modules for dif- ferent tasks. We can freeze the shared model and efciently switch tasks by replacing the matrices A and B in Figure 1, reducing the storage requirement and task-switching over- head signicantly.\\nLoRA makes training more efcient and lowers the hardware barrier to entry by up to 3 times when using adaptive optimizers since we do not need to calculate the gradients or maintain the optimizer states for most parameters. Instead, we only optimize the injected, much smaller low-rank matrices.\\nOur simple linear design allows us to merge the trainable matrices with the frozen weights when deployed, introducing no inference latency compared to a fully ne-tuned model, by construction.\\nLoRA is orthogonal to many prior methods and can be combined with many of them, such as prex-tuning. We provide an example in Appendix E.\\nTerminologies and Conventions We make frequent references to the Transformer architecture and use the conventional terminologies for its dimensions. We call the input and output di- mension size of a Transformer layer dmodel. We use Wq, Wk, Wv, and Wo to refer to the query/key/value/output projection matrices in the self-attention module. W or W0 refers to a pre- trained weight matrix and W its accumulated gradient update during adaptation. We use r to denote the rank of a LoRA module. We follow the conventions set out by (Vaswani et al., 2017; Brown et al., 2020) and use Adam (Loshchilov & Hutter, 2019; Kingma & Ba, 2017) for model optimization and use a Transformer MLP feedforward dimension dffn = 4  dmodel.\\n2 PROBLEM STATEMENT\\nWhile our proposal is agnostic to training objective, we focus on language modeling as our motivat- ing use case. Below is a brief description of the language modeling problem and, in particular, the maximization of conditional probabilities given a task-specic prompt.\\nSuppose we are given a pre-trained autoregressive language model P(y|x) parametrized by . For instance, P(y|x) can be a generic multi-task learner such as GPT (Radford et al., b; Brown et al., 2020) based on the Transformer architecture (Vaswani et al., 2017). Consider adapting this pre-trained model to downstream conditional text generation tasks, such as summarization, machine reading comprehension (MRC), and natural language to SQL (NL2SQL). Each downstream task is represented by a training dataset of context-target pairs: Z = {(xi,yi)}i=1,..,N, where both xi and yi are sequences of tokens. For example, in NL2SQL, xi is a natural language query and yi its corresponding SQL command; for summarization, xi is the content of an article and yi its summary.\\n2\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 3}}\\nDuring full ne-tuning, the model is initialized to pre-trained weights 0 and updated to 0 +  by repeatedly following the gradient to maximize the conditional language modeling objective:\\nmax \\n(cid:88)\\n(x,y)Z\\n|y| (cid:88)\\nt=1\\nlog(P(yt|x,y<t))\\nOne of the main drawbacks for full ne-tuning is that for each downstream task, we learn a different set of parameters  whose dimension || equals |0|. Thus, if the pre-trained model is large (such as GPT-3 with |0|  175 Billion), storing and deploying many independent instances of ne-tuned models can be challenging, if at all feasible.\\nIn this paper, we adopt a more parameter-efcient approach, where the task-specic parameter increment  = () is further encoded by a much smaller-sized set of parameters  with || (cid:28) |0|. The task of nding  thus becomes optimizing over :\\nmax \\n(cid:88)\\n(x,y)Z\\n|y| (cid:88)\\nt=1\\nlog(cid:0)p0+()(yt|x,y<t)(cid:1)\\nIn the subsequent sections, we propose to use a low-rank representation to encode  that is both compute- and memory-efcient. When the pre-trained model is GPT-3 175B, the number of train- able parameters || can be as small as 0.01% of |0|.\\n3 ARENT EXISTING SOLUTIONS GOOD ENOUGH?\\nThe problem we set out to tackle is by no means new. Since the inception of transfer learning, dozens of works have sought to make model adaptation more parameter- and compute-efcient. See Sec- tion 6 for a survey of some of the well-known works. Using language modeling as an example, there are two prominent strategies when it comes to efcient adaptations: adding adapter layers (Houlsby et al., 2019; Rebuf et al., 2017; Pfeiffer et al., 2021; Ruckle et al., 2020) or optimizing some forms of the input layer activations (Li & Liang, 2021; Lester et al., 2021; Hambardzumyan et al., 2020; Liu et al., 2021). However, both strategies have their limitations, especially in a large-scale and latency-sensitive production scenario.\\nAdapter Layers Introduce Inference Latency There are many variants of adapters. We focus on the original design by Houlsby et al. (2019) which has two adapter layers per Transformer block and a more recent one by Lin et al. (2020) which has only one per block but with an additional LayerNorm (Ba et al., 2016). While one can reduce the overall latency by pruning layers or exploit- ing multi-task settings (Ruckle et al., 2020; Pfeiffer et al., 2021), there is no direct ways to bypass the extra compute in adapter layers. This seems like a non-issue since adapter layers are designed to have few parameters (sometimes <1% of the original model) by having a small bottleneck di- mension, which limits the FLOPs they can add. However, large neural networks rely on hardware parallelism to keep the latency low, and adapter layers have to be processed sequentially. This makes a difference in the online inference setting where the batch size is typically as small as one. In a generic scenario without model parallelism, such as running inference on GPT-2 (Radford et al., b) medium on a single GPU, we see a noticeable increase in latency when using adapters, even with a very small bottleneck dimension (Table 1).\\nThis problem gets worse when we need to shard the model as done in Shoeybi et al. (2020); Lep- ikhin et al. (2020), because the additional depth requires more synchronous GPU operations such as AllReduce and Broadcast, unless we store the adapter parameters redundantly many times.\\nDirectly Optimizing the Prompt is Hard The other direction, as exemplied by prex tuning (Li & Liang, 2021), faces a different challenge. We observe that prex tuning is difcult to optimize and that its performance changes non-monotonically in trainable parameters, conrming similar observations in the original paper. More fundamentally, reserving a part of the sequence length for adaptation necessarily reduces the sequence length available to process a downstream task, which we suspect makes tuning the prompt less performant compared to other methods. We defer the study on task performance to Section 5.\\n3\\n(1)\\n(2)\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 4}}\\nBatch Size Sequence Length ||\\n32 512 0.5M\\n16 256 11M\\n1 128 11M\\nFine-Tune/LoRA AdapterL AdapterH\\n1449.40.8\\n1482.01.0 (+2.2%) 1492.21.0 (+3.0%)\\n338.00.6\\n354.80.5 (+5.0%) 366.30.5 (+8.4%)\\n19.82.7\\n23.92.1 (+20.7%) 25.82.2 (+30.3%)\\nTable 1: Infernece latency of a single forward pass in GPT-2 medium measured in milliseconds, av- eraged over 100 trials. We use an NVIDIA Quadro RTX8000. || denotes the number of trainable parameters in adapter layers. AdapterL and AdapterH are two variants of adapter tuning, which we describe in Section 5.1. The inference latency introduced by adapter layers can be signicant in an online, short-sequence-length scenario. See the full study in Appendix B.\\n4 OUR METHOD\\nWe describe the simple design of LoRA and its practical benets. The principles outlined here apply to any dense layers in deep learning models, though we only focus on certain weights in Transformer language models in our experiments as the motivating use case.\\n4.1 LOW-RANK-PARAMETRIZED UPDATE MATRICES\\nA neural network contains many dense layers which perform matrix multiplication. The weight matrices in these layers typically have full-rank. When adapting to a specic task, Aghajanyan et al. (2020) shows that the pre-trained language models have a low instrisic dimension and can still learn efciently despite a random projection to a smaller subspace. Inspired by this, we hypothe- size the updates to the weights also have a low intrinsic rank during adaptation. For a pre-trained weight matrix W0  Rdk, we constrain its update by representing the latter with a low-rank de- composition W0 + W = W0 + BA, where B  Rdr,A  Rrk, and the rank r (cid:28) min(d,k). During training, W0 is frozen and does not receive gradient updates, while A and B contain trainable parameters. Note both W0 and W = BA are multiplied with the same input, and their respective output vectors are summed coordinate-wise. For h = W0x, our modied forward pass yields:\\nh = W0x + Wx = W0x + BAx\\nWe illustrate our reparametrization in Figure 1. We use a random Gaussian initialization for A and zero for B, so W = BA is zero at the beginning of training. We then scale Wx by  r , where  is a constant in r. When optimizing with Adam, tuning  is roughly the same as tuning the learning rate if we scale the initialization appropriately. As a result, we simply set  to the rst r we try and do not tune it. This scaling helps to reduce the need to retune hyperparameters when we vary r (Yang & Hu, 2021).\\nA Generalization of Full Fine-tuning. A more general form of ne-tuning allows the training of a subset of the pre-trained parameters. LoRA takes a step further and does not require the accumu- lated gradient update to weight matrices to have full-rank during adaptation. This means that when applying LoRA to all weight matrices and training all biases2, we roughly recover the expressive- ness of full ne-tuning by setting the LoRA rank r to the rank of the pre-trained weight matrices. In other words, as we increase the number of trainable parameters 3, training LoRA roughly converges to training the original model, while adapter-based methods converges to an MLP and prex-based methods to a model that cannot take long input sequences.\\nNo Additional Inference Latency. When deployed in production, we can explicitly compute and store W = W0 + BA and perform inference as usual. Note that both W0 and BA are in Rdk. When we need to switch to another downstream task, we can recover W0 by subtracting BA and then adding a different B(cid:48)A(cid:48), a quick operation with very little memory overhead. Critically, this\\n2They represent a negligible number of parameters compared to weights. 3An inevitability when adapting to hard tasks.\\n4\\n(3)\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 5}}\\nguarantees that we do not introduce any additional latency during inference compared to a ne-tuned model by construction.\\n4.2 APPLYING LORA TO TRANSFORMER\\nIn principle, we can apply LoRA to any subset of weight matrices in a neural network to reduce the number of trainable parameters. In the Transformer architecture, there are four weight matrices in the self-attention module (Wq,Wk,Wv,Wo) and two in the MLP module. We treat Wq (or Wk, Wv) as a single matrix of dimension dmodel dmodel, even though the output dimension is usually sliced into attention heads. We limit our study to only adapting the attention weights for downstream tasks and freeze the MLP modules (so they are not trained in downstream tasks) both for simplicity and parameter-efciency.We further study the effect on adapting different types of attention weight matrices in a Transformer in Section 7.1. We leave the empirical investigation of adapting the MLP layers, LayerNorm layers, and biases to a future work.\\nPractical Benets and Limitations. The most signicant benet comes from the reduction in memory and storage usage. For a large Transformer trained with Adam, we reduce that VRAM usage by up to 2/3 if r (cid:28) dmodel as we do not need to store the optimizer states for the frozen parameters. On GPT-3 175B, we reduce the VRAM consumption during training from 1.2TB to 350GB. With r = 4 and only the query and value projection matrices being adapted, the checkpoint size is reduced by roughly 10,000 (from 350GB to 35MB)4. This allows us to train with signi- cantly fewer GPUs and avoid I/O bottlenecks. Another benet is that we can switch between tasks while deployed at a much lower cost by only swapping the LoRA weights as opposed to all the parameters. This allows for the creation of many customized models that can be swapped in and out on the y on machines that store the pre-trained weights in VRAM. We also observe a 25% speedup during training on GPT-3 175B compared to full ne-tuning5 as we do not need to calculate the gradient for the vast majority of the parameters.\\nLoRA also has its limitations. For example, it is not straightforward to batch inputs to different tasks with different A and B in a single forward pass, if one chooses to absorb A and B into W to eliminate additional inference latency. Though it is possible to not merge the weights and dynamically choose the LoRA modules to use for samples in a batch for scenarios where latency is not critical.\\n5 EMPIRICAL EXPERIMENTS\\nWe evaluate the downstream task performance of LoRA on RoBERTa (Liu et al., 2019), De- BERTa (He et al., 2021), and GPT-2 (Radford et al., b), before scaling up to GPT-3 175B (Brown et al., 2020). Our experiments cover a wide range of tasks, from natural language understanding (NLU) to generation (NLG). Specically, we evaluate on the GLUE (Wang et al., 2019) benchmark for RoBERTa and DeBERTa. We follow the setup of Li & Liang (2021) on GPT-2 for a direct com- parison and add WikiSQL (Zhong et al., 2017) (NL to SQL queries) and SAMSum (Gliwa et al., 2019) (conversation summarization) for large-scale experiments on GPT-3. See Appendix C for more details on the datasets we use. We use NVIDIA Tesla V100 for all experiments.\\n5.1 BASELINES\\nTo compare with other baselines broadly, we replicate the setups used by prior work and reuse their reported numbers whenever possible. This, however, means that some baselines might only appear in certain experiments.\\nFine-Tuning (FT) is a common approach for adaptation. During ne-tuning, the model is initialized to the pre-trained weights and biases, and all model parameters undergo gradient updates.A simple variant is to update only some layers while freezing others. We include one such baseline reported in prior work (Li & Liang, 2021) on GPT-2, which adapts just the last two layers (FTTop2).\\n4We still need the 350GB model during deployment; however, storing 100 adapted models only requires\\n350GB + 35MB * 100  354GB as opposed to 100 * 350GB  35TB.\\n5For GPT-3 175B, the training throughput for full ne-tuning is 32.5 tokens/s per V100 GPU; with the same\\nnumber of weight shards for model parallelism, the throughput is 43.1 tokens/s per V100 GPU for LoRA.\\n5\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 6}}\\nModel & Method # Trainable\\nParameters MNLI SST-2 MRPC CoLA QNLI QQP\\nRTE\\nSTS-B Avg.\\nRoBbase (FT)* RoBbase (BitFit)* RoBbase (AdptD)* RoBbase (AdptD)* RoBbase (LoRA)\\n125.0M 87.6 86.4 0.1M 84.7 85.2 0.3M 87.1.0 94.2.1 88.51.1 60.8.4 93.1.1 90.2.0 71.52.7 89.7.3 84.4 0.9M 87.3.1 94.7.3 88.4.1 62.6.9 93.0.2 90.6.0 75.92.2 90.3.1 85.4 0.3M 87.5.3 95.1.2 89.7.7 63.41.2 93.3.3 90.8.1 86.6.7 91.5.2 87.2\\n94.8 93.7\\n90.2 92.7\\n63.6 62.0\\n92.8 91.8\\n91.9 84.0\\n78.7 81.5\\n91.2 90.8\\nRoBlarge (FT)* RoBlarge (LoRA) RoBlarge (AdptP) RoBlarge (AdptP) RoBlarge (AdptH) RoBlarge (AdptH) RoBlarge (LoRA)\\n355.0M 90.2\\n88.9 0.8M 90.6.2 96.2.5 90.91.2 68.21.9 94.9.3 91.6.1 87.42.5 92.6.2 89.0\\n96.4\\n90.9\\n68.0\\n94.7\\n92.2\\n86.6\\n92.4\\n3.0M 90.2.3 96.1.3 90.2.7 68.31.0 94.8.2 91.9.1 83.82.9 92.1.7 88.4 0.8M 90.5.3 96.6.2 89.71.2 67.82.5 94.8.3 91.7.2 80.12.9 91.9.4 87.9 6.0M 89.9.5 96.2.3 88.72.9 66.54.4 94.7.2 92.1.1 83.41.1 91.01.7 87.8 0.8M 90.3.3 96.3.5 87.71.7 66.32.0 94.7.2 91.5.1 72.92.9 91.5.5 86.4 0.8M 90.6.2 96.2.5 90.21.0 68.21.9 94.8.3 91.6.2 85.21.1 92.3.5 88.6\\nDeBXXL (FT)* DeBXXL (LoRA)\\n1500.0M 91.8\\n91.1 4.7M 91.9.2 96.9.2 92.6.6 72.41.1 96.0.1 92.9.1 94.9.4 93.0.2 91.3\\n97.2\\n92.0\\n72.0\\n96.0\\n92.7\\n93.9\\n92.9\\nTable 2: RoBERTabase, RoBERTalarge, and DeBERTaXXL with different adaptation methods on the GLUE benchmark. We report the overall (matched and mismatched) accuracy for MNLI, Matthews correlation for CoLA, Pearson correlation for STS-B, and accuracy for other tasks. Higher is better for all metrics. * indicates numbers published in prior works.  indicates runs congured in a setup similar to Houlsby et al. (2019) for a fair comparison.\\nBias-only or BitFit is a baseline where we only train the bias vectors while freezing everything else. Contemporarily, this baseline has also been studied by BitFit (Zaken et al., 2021).\\nPrex-embedding tuning (PreEmbed) inserts special tokens among the input tokens. These spe- cial tokens have trainable word embeddings and are generally not in the models vocabulary. Where to place such tokens can have an impact on performance. We focus on prexing, which prepends such tokens to the prompt, and inxing, which appends to the prompt; both are discussed in Li & Liang (2021). We use lp (resp. li) denote the number of prex (resp. inx) tokens. The number of trainable parameters is || = dmodel  (lp + li).\\nPrex-layer tuning (PreLayer) is an extension to prex-embedding tuning. Instead of just learning the word embeddings (or equivalently, the activations after the embedding layer) for some special tokens, we learn the activations after every Transformer layer. The activations computed from pre- vious layers are simply replaced by trainable ones. The resulting number of trainable parameters is || = L  dmodel  (lp + li), where L is the number of Transformer layers.\\nAdapter tuning as proposed in Houlsby et al. (2019) inserts adapter layers between the self- attention module (and the MLP module) and the subsequent residual connection. There are two fully connected layers with biases in an adapter layer with a nonlinearity in between. We call this original design AdapterH. Recently, Lin et al. (2020) proposed a more efcient design with the adapter layer applied only after the MLP module and after a LayerNorm. We call it AdapterL. This is very similar to another deign proposed in Pfeiffer et al. (2021), which we call AdapterP. We also include another baseline call AdapterDrop (Ruckle et al., 2020) which drops some adapter layers for greater efciency (AdapterD). We cite numbers from prior works whenever possible to maximize the number of baselines we compare with; they are in rows with an asterisk (*) in the rst column. In all cases, we have || = LAdpt(2dmodelr+r+dmodel)+2 LLN dmodel where LAdpt is the number of adapter layers and LLN the number of trainable LayerNorms (e.g., in AdapterL). LoRA adds trainable pairs of rank decomposition matrices in parallel to existing weight matrices. As mentioned in Section 4.2, we only apply LoRA to Wq and Wv in most experiments for simplicity. The number of trainable parameters is determined by the rank r and the shape of the original weights: || = 2 LLoRA dmodel r, where LLoRA is the number of weight matrices we apply LoRA to.\\n6\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 7}}\\nModel & Method\\n# Trainable Parameters\\nBLEU\\nE2E NLG Challenge\\nNIST\\nMET\\nROUGE-L\\nCIDEr\\nGPT-2 M (FT)* GPT-2 M (AdapterL)* GPT-2 M (AdapterL)* GPT-2 M (AdapterH) GPT-2 M (FTTop2)* GPT-2 M (PreLayer)* GPT-2 M (LoRA)\\nGPT-2 L (FT)* GPT-2 L (AdapterL) GPT-2 L (AdapterL) GPT-2 L (PreLayer)* GPT-2 L (LoRA)\\n354.92M 0.37M 11.09M 11.09M 67.3.6 25.19M 0.35M 0.35M 70.4.1\\n68.2 66.3 68.9\\n68.1 69.7\\n774.03M\\n68.5\\n0.88M 69.1.1 23.00M 68.9.3 0.77M 0.77M 70.4.1\\n70.3\\n8.62 8.41 8.71 8.50.07 8.59 8.81 8.85.02 8.78 8.68.03 8.70.04 8.85 8.89.02\\n46.2 45.0 46.1 46.0.2 46.0 46.1 46.8.2 46.0 46.3.0 46.1.1 46.2 46.8.2\\n71.0 69.8 71.3 70.7.2 70.8 71.4 71.8.1 69.9 71.4.2 71.3.2 71.7 72.0.2\\n2.47 2.40 2.47 2.44.01 2.41 2.49 2.53.02 2.45 2.49.0 2.45.02 2.47 2.47.02\\nTable 3: GPT-2 medium (M) and large (L) with different adaptation methods on the E2E NLG Challenge. For all metrics, higher is better. LoRA outperforms several baselines with comparable or fewer trainable parameters. Condence intervals are shown for experiments we ran. * indicates numbers published in prior works.\\n5.2 ROBERTA BASE/LARGE\\nRoBERTa (Liu et al., 2019) optimized the pre-training recipe originally proposed in BERT (Devlin et al., 2019a) and boosted the latters task performance without introducing many more trainable parameters. While RoBERTa has been overtaken by much larger models on NLP leaderboards such as the GLUE benchmark (Wang et al., 2019) in recent years, it remains a competitive and popular pre-trained model for its size among practitioners. We take the pre-trained RoBERTa base (125M) and RoBERTa large (355M) from the HuggingFace Transformers library (Wolf et al., 2020) and evaluate the performance of different efcient adaptation approaches on tasks from the GLUE benchmark. We also replicate Houlsby et al. (2019) and Pfeiffer et al. (2021) according to their setup. To ensure a fair comparison, we make two crucial changes to how we evaluate LoRA when comparing with adapters. First, we use the same batch size for all tasks and use a sequence length of 128 to match the adapter baselines. Second, we initialize the model to the pre-trained model for MRPC, RTE, and STS-B, not a model already adapted to MNLI like the ne-tuning baseline. Runs following this more restricted setup from Houlsby et al. (2019) are labeled with . The result is presented in Table 2 (Top Three Sections). See Section D.1 for details on the hyperparameters used.\\n5.3 DEBERTA XXL\\nDeBERTa (He et al., 2021) is a more recent variant of BERT that is trained on a much larger scale and performs very competitively on benchmarks such as GLUE (Wang et al., 2019) and Su- perGLUE (Wang et al., 2020). We evaluate if LoRA can still match the performance of a fully ne-tuned DeBERTa XXL (1.5B) on GLUE. The result is presented in Table 2 (Bottom Section). See Section D.2 for details on the hyperparameters used.\\n5.4 GPT-2 MEDIUM/LARGE\\nHaving shown that LoRA can be a competitive alternative to full ne-tuning on NLU, we hope to answer if LoRA still prevails on NLG models, such as GPT-2 medium and large (Radford et al., b). We keep our setup as close as possible to Li & Liang (2021) for a direct comparison. Due to space constraint, we only present our result on E2E NLG Challenge (Table 3) in this section. See Section F.1 for results on WebNLG (Gardent et al., 2017) and DART (Nan et al., 2020). We include a list of the hyperparameters used in Section D.3.\\n7\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 8}}\\nModel&Method\\n# Trainable WikiSQL MNLI-m Parameters Acc. (%) Acc. (%)\\nSAMSum R1/R2/RL\\nGPT-3 (FT) GPT-3 (BitFit) GPT-3 (PreEmbed) GPT-3 (PreLayer) GPT-3 (AdapterH) GPT-3 (AdapterH)\\n175,255.8M 14.2M 3.2M 20.2M 7.1M 40.1M\\n73.8 71.3 63.1 70.1 71.9 73.2\\n89.5 91.0 88.6 89.5 89.8 91.5\\n52.0/28.0/44.5 51.3/27.4/43.5 48.3/24.2/40.5 50.8/27.3/43.5 53.0/28.9/44.8 53.2/29.0/45.1\\nGPT-3 (LoRA) GPT-3 (LoRA)\\n4.7M 37.7M\\n73.4 74.0\\n91.7 91.6\\n53.8/29.8/45.9 53.4/29.2/45.1\\nTable 4: Performance of different adaptation methods on GPT-3 175B. We report the logical form validation accuracy on WikiSQL, validation accuracy on MultiNLI-matched, and Rouge-1/2/L on SAMSum. LoRA performs better than prior approaches, including full ne-tuning. The results on WikiSQL have a uctuation around 0.5%, MNLI-m around 0.1%, and SAMSum around 0.2/0.2/0.1 for the three metrics.\\n5.5 SCALING UP TO GPT-3 175B\\nAs a nal stress test for LoRA, we scale up to GPT-3 with 175 billion parameters. Due to the high training cost, we only report the typical standard deviation for a given task over random seeds, as opposed to providing one for every entry. See Section D.4 for details on the hyperparameters used.\\nAs shown in Table 4, LoRA matches or exceeds the ne-tuning baseline on all three datasets. Note that not all methods benet monotonically from having more trainable parameters, as shown in Fig- ure 2. We observe a signicant performance drop when we use more than 256 special tokens for prex-embedding tuning or more than 32 special tokens for prex-layer tuning. This corroborates similar observations in Li & Liang (2021). While a thorough investigation into this phenomenon is out-of-scope for this work, we suspect that having more special tokens causes the input distri- bution to shift further away from the pre-training data distribution. Separately, we investigate the performance of different adaptation approaches in the low-data regime in Section F.3.\\nMultiNLI-matched\\n0.90\\n0.60\\n10\\n8\\n8\\n7\\nLoRA\\nWikiSQL\\n6\\nPrefixEmbed\\n10\\n0.86\\n0.84\\nMethod\\nPrefixLayer\\n9\\n0.55\\nAdapter(H)\\n0.70\\n0.75Validation Accuracy\\n7\\n9\\n0.88\\n0.92\\nFine-Tune\\n11log10 # Trainable Parameters\\n11log10 # Trainable Parameters\\n6\\n0.65\\nFigure 2: GPT-3 175B validation accuracy vs. number of trainable parameters of several adaptation methods on WikiSQL and MNLI-matched. LoRA exhibits better scalability and task performance. See Section F.2 for more details on the plotted data points.\\n6 RELATED WORKS\\nTransformer Language Models. Transformer (Vaswani et al., 2017) is a sequence-to-sequence architecture that makes heavy use of self-attention. Radford et al. (a) applied it to autoregressive lan- guage modeling by using a stack of Transformer decoders. Since then, Transformer-based language models have dominated NLP, achieving the state-of-the-art in many tasks. A new paradigm emerged with BERT (Devlin et al., 2019b) and GPT-2 (Radford et al., b)  both are large Transformer lan-\\n8\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 9}}\\nguage models trained on a large amount of text  where ne-tuning on task-specic data after pre- training on general domain data provides a signicant performance gain compared to training on task-specic data directly. Training larger Transformers generally results in better performance and remains an active research direction. GPT-3 (Brown et al., 2020) is the largest single Transformer language model trained to-date with 175B parameters.\\nPrompt Engineering and Fine-Tuning. While GPT-3 175B can adapt its behavior with just a few additional training examples, the result depends heavily on the input prompt (Brown et al., 2020). This necessitates an empirical art of composing and formatting the prompt to maximize a models performance on a desired task, which is known as prompt engineering or prompt hacking. Fine-tuning retrains a model pre-trained on general domains to a specic task Devlin et al. (2019b); Radford et al. (a). Variants of it include learning just a subset of the parameters Devlin et al. (2019b); Collobert & Weston (2008), yet practitioners often retrain all of them to maximize the downstream performance. However, the enormity of GPT-3 175B makes it challenging to perform ne-tuning in the usual way due to the large checkpoint it produces and the high hardware barrier to entry since it has the same memory footprint as pre-training.\\nParameter-Efcient Adaptation. Many have proposed inserting adapter layers between existing layers in a neural network (Houlsby et al., 2019; Rebuf et al., 2017; Lin et al., 2020). Our method uses a similar bottleneck structure to impose a low-rank constraint on the weight updates. The key functional difference is that our learned weights can be merged with the main weights during inference, thus not introducing any latency, which is not the case for the adapter layers (Section 3). A comtenporary extension of adapter is COMPACTER (Mahabadi et al., 2021), which essentially parametrizes the adapter layers using Kronecker products with some predetermined weight sharing scheme. Similarly, combining LoRA with other tensor product-based methods could potentially improve its parameter efciency, which we leave to future work. More recently, many proposed optimizing the input word embeddings in lieu of ne-tuning, akin to a continuous and differentiable generalization of prompt engineering (Li & Liang, 2021; Lester et al., 2021; Hambardzumyan et al., 2020; Liu et al., 2021). We include comparisons with Li & Liang (2021) in our experiment section. However, this line of works can only scale up by using more special tokens in the prompt, which take up available sequence length for task tokens when positional embeddings are learned.\\nLow-Rank Structures in Deep Learning. Low-rank structure is very common in machine learn- ing. A lot of machine learning problems have certain intrinsic low-rank structure (Li et al., 2016; Cai et al., 2010; Li et al., 2018b; Grasedyck et al., 2013). Moreover, it is known that for many deep learning tasks, especially those with a heavily over-parametrized neural network, the learned neural network will enjoy low-rank properties after training (Oymak et al., 2019). Some prior works even explicitly impose the low-rank constraint when training the original neural network (Sainath et al., 2013; Povey et al., 2018; Zhang et al., 2014; Jaderberg et al., 2014; Zhao et al., 2016; Kho- dak et al., 2021; Denil et al., 2014); however, to the best of our knowledge, none of these works considers low-rank update to a frozen model for adaptation to downstream tasks. In theory liter- ature, it is known that neural networks outperform other classical learning methods, including the corresponding (nite-width) neural tangent kernels (Allen-Zhu et al., 2019; Li & Liang, 2018) when the underlying concept class has certain low-rank structure (Ghorbani et al., 2020; Allen-Zhu & Li, 2019; Allen-Zhu & Li, 2020a). Another theoretical result in Allen-Zhu & Li (2020b) suggests that low-rank adaptations can be useful for adversarial training. In sum, we believe that our proposed low-rank adaptation update is well-motivated by the literature.\\n7 UNDERSTANDING THE LOW-RANK UPDATES\\nGiven the empirical advantage of LoRA, we hope to further explain the properties of the low-rank adaptation learned from downstream tasks. Note that the low-rank structure not only lowers the hardware barrier to entry which allows us to run multiple experiments in parallel, but also gives better interpretability of how the update weights are correlated with the pre-trained weights. We focus our study on GPT-3 175B, where we achieved the largest reduction of trainable parameters (up to 10,000) without adversely affecting task performances.\\nWe perform a sequence of empirical studies to answer the following questions: 1) Given a parameter budget constraint, which subset of weight matrices in a pre-trained Transformer should we adapt\\n9\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 10}}\\nto maximize downstream performance? 2) Is the optimal adaptation matrix W really rank- decient? If so, what is a good rank to use in practice? 3) What is the connection between W and W? Does W highly correlate with W? How large is W comparing to W?\\nWe believe that our answers to question (2) and (3) shed light on the fundamental principles of using pre-trained language models for downstream tasks, which is a critical topic in NLP.\\n7.1 WHICH WEIGHT MATRICES IN TRANSFORMER SHOULD WE APPLY LORA TO?\\nGiven a limited parameter budget, which types of weights should we adapt with LoRA to obtain the best performance on downstream tasks? As mentioned in Section 4.2, we only consider weight matrices in the self-attention module. We set a parameter budget of 18M (roughly 35MB if stored in FP16) on GPT-3 175B, which corresponds to r = 8 if we adapt one type of attention weights or r = 4 if we adapt two types, for all 96 layers. The result is presented in Table 5.\\n# of Trainable Parameters = 18M\\nWeight Type Rank r\\nWq Wk Wv Wo Wq,Wk Wq,Wv Wq,Wk,Wv,Wo 4 8\\n8\\n8\\n8\\n4\\n2\\nWikiSQL (0.5%) MultiNLI (0.1%)\\n70.4 91.0\\n70.0 90.8\\n73.0 91.0\\n73.2 91.3\\n71.4 91.3\\n73.7 91.3\\n73.7 91.7\\nTable 5: Validation accuracy on WikiSQL and MultiNLI after applying LoRA to different types of attention weights in GPT-3, given the same number of trainable parameters. Adapting both Wq and Wv gives the best performance overall. We nd the standard deviation across random seeds to be consistent for a given dataset, which we report in the rst column.\\nNote that putting all the parameters in Wq or Wk results in signicantly lower performance, while adapting both Wq and Wv yields the best result. This suggests that even a rank of four captures enough information in W such that it is preferable to adapt more weight matrices than adapting a single type of weights with a larger rank.\\n7.2 WHAT IS THE OPTIMAL RANK r FOR LORA?\\nWe turn our attention to the effect of rank r on model performance. We adapt {Wq,Wv}, {Wq,Wk,Wv,Wc}, and just Wq for a comparison.\\nWeight Type\\nr = 1\\nr = 2\\nr = 4\\nr = 8\\nr = 64\\nWikiSQL(0.5%)\\nMultiNLI (0.1%)\\nWq Wq,Wv Wq,Wk,Wv,Wo Wq Wq,Wv Wq,Wk,Wv,Wo\\n68.8 73.4 74.1\\n90.7 91.3 91.2\\n69.6 73.3 73.7\\n90.9 91.4 91.7\\n70.5 73.7 74.0\\n91.1 91.3 91.7\\n70.4 73.8 74.0\\n90.7 91.6 91.5\\n70.0 73.5 73.9\\n90.7 91.4 91.4\\nTable 6: Validation accuracy on WikiSQL and MultiNLI with different rank r. To our surprise, a rank as small as one sufces for adapting both Wq and Wv on these datasets while training Wq alone needs a larger r. We conduct a similar experiment on GPT-2 in Section H.2.\\nTable 6 shows that, surprisingly, LoRA already performs competitively with a very small r (more so for {Wq,Wv} than just Wq). This suggests the update matrix W could have a very small intrinsic rank.6 To further support this nding, we check the overlap of the subspaces learned by different choices of r and by different random seeds. We argue that increasing r does not cover a more meaningful subspace, which suggests that a low-rank adaptation matrix is sufcient.\\n6However, we do not expect a small r to work for every task or dataset. Consider the following thought experiment: if the downstream task were in a different language than the one used for pre-training, retraining the entire model (similar to LoRA with r = dmodel) could certainly outperform LoRA with a small r.\\n10\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 11}}\\nSubspace similarity between different r. Given Ar=8 and Ar=64 which are the learned adapta- tion matrices with rank r = 8 and 64 using the same pre-trained model, we perform singular value decomposition and obtain the right-singular unitary matrices UAr=8 and UAr=64.7 We hope to an- swer: how much of the subspace spanned by the top i singular vectors in UAr=8 (for 1  i  8) is contained in the subspace spanned by top j singular vectors of UAr=64 (for 1  j  64)? We mea- sure this quantity with a normalized subspace similarity based on the Grassmann distance (See Ap- pendix G for a more formal discussion)\\n(Ar=8,Ar=64,i,j) =\\nUj Ar=64 min(i,j)\\n||Ui(cid:62)\\nAr=8\\n||2 F\\n [0,1]\\nwhere Ui\\nAr=8\\nrepresents the columns of UAr=8 corresponding to the top-i singular vectors.\\n() has a range of [0,1], where 1 represents a complete overlap of subspaces and 0 a complete separation. See Figure 3 for how  changes as we vary i and j. We only look at the 48th layer (out of 96) due to space constraint, but the conclusion holds for other layers as well, as shown in Section H.1.\\n0.0\\n0.2\\n0.4\\nWv\\nWv\\nWq\\n16121823293540465258j12345678i\\n12345678j\\n16121823293540465258j\\n0.6\\n1.0\\n0.8\\n12345678j\\n(Ar=64,Ar=8,i,j)\\nWq\\nFigure 3: Subspace similarity between column vectors of Ar=8 and Ar=64 for both Wq and Wv. The third and the fourth gures zoom in on the lower-left triangle in the rst two gures. The top directions in r = 8 are included in r = 64, and vice versa.\\nWe make an important observation from Figure 3.\\nDirections corresponding to the top singular vector overlap signicantly between Ar=8 and Ar=64, while others do not. Specically, Wv (resp. Wq) of Ar=8 and Wv (resp. Wq) of Ar=64 share a subspace of dimension 1 with normalized similarity > 0.5, providing an explanation of why r = 1 performs quite well in our downstream tasks for GPT-3.\\nSince both Ar=8 and Ar=64 are learned using the same pre-trained model, Figure 3 indicates that the top singular-vector directions of Ar=8 and Ar=64 are the most useful, while other directions potentially contain mostly random noises accumulated during training. Hence, the adaptation matrix can indeed have a very low rank.\\nSubspace similarity between different random seeds. We further conrm this by plotting the normalized subspace similarity between two randomly seeded runs with r = 64, shown in Figure 4. Wq appears to have a higher intrinsic rank than Wv, since more common singular value direc- tions are learned by both runs for Wq, which is in line with our empirical observation in Table 6. As a comparison, we also plot two random Gaussian matrices, which do not share any common singular value directions with each other.\\n7.3 HOW DOES THE ADAPTATION MATRIX W COMPARE TO W?\\nWe further investigate the relationship between W and W. In particular, does W highly correlate with W? (Or mathematically, is W mostly contained in the top singular directions of W?) Also,\\n7Note that a similar analysis can be carried out with B and the left-singular unitary matrices  we stick with\\nA for our experiments.\\n11\\n(4)\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 12}}\\n0.0\\n0.1\\n151015202530343944495459j\\n0.4\\n151015202530343944495459j18162432404856i\\n0.3\\n0.2\\n0.5\\nWq\\n(Ar=64,A0r=64,i,j)\\n151015202530343944495459j\\nRandom Gaussian\\nWv\\nFigure 4: Left and Middle: Normalized subspace similarity between the column vectors of Ar=64 from two random seeds, for both Wq and Wv in the 48-th layer. Right: the same heat-map between the column vectors of two random Gaussian matrices. See Section H.1 for other layers.\\nhow large is W comparing to its corresponding directions in W? This can shed light on the underlying mechanism for adapting pre-trained language models.\\nTo answer these questions, we project W onto the r-dimensional subspace of W by comput- ing U(cid:62)WV (cid:62), with U/V being the left/right singular-vector matrix of W. Then, we com- pare the Frobenius norm between (cid:107)U(cid:62)WV (cid:62)(cid:107)F and (cid:107)W(cid:107)F. As a comparison, we also compute (cid:107)U(cid:62)WV (cid:62)(cid:107)F by replacing U,V with the top r singular vectors of W or a random matrix.\\nr = 4\\nr = 64\\nWq Wq\\nRandom Wq Wq\\nRandom\\n||U(cid:62)WqV (cid:62)||F = 0.32 ||Wq||F = 61.95\\n21.67\\n0.02\\n||Wq||F = 6.91\\n1.90\\n37.71\\n0.33\\n||Wq||F = 3.57\\nTable 7: The Frobenius norm of U(cid:62)WqV (cid:62) where U and V are the left/right top r singular vector directions of either (1) Wq, (2) Wq, or (3) a random matrix. The weight matrices are taken from the 48th layer of GPT-3.\\nWe draw several conclusions from Table 7. First, W has a stronger correlation with W compared to a random matrix, indicating that W amplies some features that are already in W. Second, instead of repeating the top singular directions of W, W only amplies directions that are not emphasized in W. Third, the amplication factor is rather huge: 21.5  6.91/0.32 for r = 4. See Section H.4 for why r = 64 has a smaller amplication factor. We also provide a visualization in Section H.3 for how the correlation changes as we include more top singular directions from Wq. This suggests that the low-rank adaptation matrix potentially amplies the important features for specic downstream tasks that were learned but not emphasized in the general pre-training model.\\n8 CONCLUSION AND FUTURE WORK\\nFine-tuning enormous language models is prohibitively expensive in terms of the hardware required and the storage/switching cost for hosting independent instances for different tasks. We propose LoRA, an efcient adaptation strategy that neither introduces inference latency nor reduces input sequence length while retaining high model quality. Importantly, it allows for quick task-switching when deployed as a service by sharing the vast majority of the model parameters. While we focused on Transformer language models, the proposed principles are generally applicable to any neural networks with dense layers.\\nThere are many directions for future works. 1) LoRA can be combined with other efcient adapta- tion methods, potentially providing orthogonal improvement. 2) The mechanism behind ne-tuning or LoRA is far from clear  how are features learned during pre-training transformed to do well on downstream tasks? We believe that LoRA makes it more tractable to answer this than full ne-\\n12\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 13}}\\ntuning. 3) We mostly depend on heuristics to select the weight matrices to apply LoRA to. Are there more principled ways to do it? 4) Finally, the rank-deciency of W suggests that W could be rank-decient as well, which can also be a source of inspiration for future works.\\nREFERENCES\\nArmen Aghajanyan, Luke Zettlemoyer, and Sonal Gupta.\\nIntrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning. arXiv:2012.13255 [cs], December 2020. URL http://arxiv.org/abs/2012.13255.\\nZeyuan Allen-Zhu and Yuanzhi Li. What Can ResNet Learn Efciently, Going Beyond Kernels? In\\nNeurIPS, 2019. Full version available at http://arxiv.org/abs/1905.10337.\\nZeyuan Allen-Zhu and Yuanzhi Li. Backward feature correction: How deep learning performs deep\\nlearning. arXiv preprint arXiv:2001.04413, 2020a.\\nZeyuan Allen-Zhu and Yuanzhi Li. Feature purication: How adversarial training performs robust\\ndeep learning. arXiv preprint arXiv:2005.10190, 2020b.\\nZeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over- parameterization. In ICML, 2019. Full version available at http://arxiv.org/abs/1811. 03962.\\nJimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization, 2016.\\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari- wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language Models are Few-Shot Learners. arXiv:2005.14165 [cs], July 2020. URL http://arxiv.org/abs/2005.14165.\\nJian-Feng Cai, Emmanuel J Cand`es, and Zuowei Shen. A singular value thresholding algorithm for\\nmatrix completion. SIAM Journal on optimization, 20(4):19561982, 2010.\\nDaniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation. Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), 2017. doi: 10.18653/ v1/s17-2001. URL http://dx.doi.org/10.18653/v1/S17-2001.\\nRonan Collobert and Jason Weston. A unied architecture for natural language processing: deep In Proceedings of the 25th international conference neural networks with multitask learning. on Machine learning, ICML 08, pp. 160167, New York, NY, USA, July 2008. Association for Computing Machinery. ISBN 978-1-60558-205-4. doi: 10.1145/1390156.1390177. URL https://doi.org/10.1145/1390156.1390177.\\nMisha Denil, Babak Shakibi, Laurent Dinh, MarcAurelio Ranzato, and Nando de Freitas. Predicting\\nparameters in deep learning, 2014.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\\nbidirectional transformers for language understanding, 2019a.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805 [cs], May 2019b. URL http://arxiv.org/abs/1810.04805. arXiv: 1810.04805.\\nWilliam B. Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In Proceedings of the Third International Workshop on Paraphrasing (IWP2005), 2005. URL https://aclanthology.org/I05-5002.\\nClaire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. The webnlg challenge: Generating text from rdf data. In Proceedings of the 10th International Conference on Natural Language Generation, pp. 124133, 2017.\\n13\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 14}}\\nBehrooz Ghorbani, Song Mei, Theodor Misiakiewicz, and Andrea Montanari. When do neural\\nnetworks outperform kernel methods? arXiv preprint arXiv:2006.13409, 2020.\\nBogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. Samsum corpus: A human- annotated dialogue dataset for abstractive summarization. CoRR, abs/1911.12237, 2019. URL http://arxiv.org/abs/1911.12237.\\nLars Grasedyck, Daniel Kressner, and Christine Tobler. A literature survey of low-rank tensor\\napproximation techniques. GAMM-Mitteilungen, 36(1):5378, 2013.\\nJihun Ham and Daniel D. Lee. Grassmann discriminant analysis: a unifying view on subspace-based In ICML, pp. 376383, 2008. URL https://doi.org/10.1145/1390156.\\nlearning. 1390204.\\nKaren Hambardzumyan, Hrant Khachatrian, and Jonathan May. WARP: Word-level Adversarial ReProgramming. arXiv:2101.00121 [cs], December 2020. URL http://arxiv.org/abs/ 2101.00121. arXiv: 2101.00121.\\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert\\nwith disentangled attention, 2021.\\nNeil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-Efcient Transfer Learning for NLP. arXiv:1902.00751 [cs, stat], June 2019. URL http://arxiv.org/abs/1902. 00751.\\nMax Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Speeding up convolutional neural networks\\nwith low rank expansions. arXiv preprint arXiv:1405.3866, 2014.\\nMikhail Khodak, Neil Tenenholtz, Lester Mackey, and Nicol`o Fusi. Initialization and regularization\\nof factorized neural layers, 2021.\\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.\\nDmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation and automatic sharding, 2020.\\nBrian Lester, Rami Al-Rfou, and Noah Constant. The Power of Scale for Parameter-Efcient Prompt Tuning. arXiv:2104.08691 [cs], April 2021. URL http://arxiv.org/abs/2104.08691. arXiv: 2104.08691.\\nChunyuan Li, Heerad Farkhoor, Rosanne Liu, and Jason Yosinski. Measuring the Intrinsic Di- mension of Objective Landscapes. arXiv:1804.08838 [cs, stat], April 2018a. URL http: //arxiv.org/abs/1804.08838. arXiv: 1804.08838.\\nXiang Lisa Li and Percy Liang. Prex-Tuning: Optimizing Continuous Prompts for Generation. arXiv:2101.00190 [cs], January 2021. URL http://arxiv.org/abs/2101.00190.\\nYuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gradient\\ndescent on structured data. In Advances in Neural Information Processing Systems, 2018.\\nYuanzhi Li, Yingyu Liang, and Andrej Risteski. Recovery guarantee of weighted low-rank ap- proximation via alternating minimization. In International Conference on Machine Learning, pp. 23582367. PMLR, 2016.\\nYuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations. In Conference On Learning The- ory, pp. 247. PMLR, 2018b.\\nZhaojiang Lin, Andrea Madotto, and Pascale Fung. Exploring versatile generative language model via parameter-efcient transfer learning. In Findings of the Association for Computational Lin- guistics: EMNLP 2020, pp. 441459, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ndings-emnlp.41. URL https://aclanthology. org/2020.findings-emnlp.41.\\n14\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 15}}\\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. GPT Understands, Too. arXiv:2103.10385 [cs], March 2021. URL http://arxiv.org/abs/ 2103.10385. arXiv: 2103.10385.\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization.\\narXiv preprint\\narXiv:1711.05101, 2017.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2019.\\nRabeeh Karimi Mahabadi, James Henderson, and Sebastian Ruder. Compacter: Efcient low-rank\\nhypercomplex adapter layers, 2021.\\nLinyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad, Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna, et al. Dart: Open-domain structured data record to text generation. arXiv preprint arXiv:2007.02871, 2020.\\nJekaterina Novikova, Ondrej Dusek, and Verena Rieser. The e2e dataset: New challenges for end-\\nto-end generation. arXiv preprint arXiv:1706.09254, 2017.\\nSamet Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi. Generalization guaran- tees for neural networks via harnessing the low-rank structure of the jacobian. arXiv preprint arXiv:1906.05392, 2019.\\nJonas Pfeiffer, Aishwarya Kamath, Andreas Ruckle, Kyunghyun Cho, and Iryna Gurevych. Adapter-\\nfusion: Non-destructive task composition for transfer learning, 2021.\\nDaniel Povey, Gaofeng Cheng, Yiming Wang, Ke Li, Hainan Xu, Mahsa Yarmohammadi, and San- jeev Khudanpur. Semi-orthogonal low-rank matrix factorization for deep neural networks. In Interspeech, pp. 37433747, 2018.\\nAlec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving Language Under-\\nstanding by Generative Pre-Training. pp. 12, a.\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\\nModels are Unsupervised Multitask Learners. pp. 24, b.\\nPranav Rajpurkar, Robin Jia, and Percy Liang. Know what you dont know: Unanswerable questions for squad. CoRR, abs/1806.03822, 2018. URL http://arxiv.org/abs/1806.03822.\\nSylvestre-Alvise Rebuf, Hakan Bilen, and Andrea Vedaldi. Learning multiple visual domains with residual adapters. arXiv:1705.08045 [cs, stat], November 2017. URL http://arxiv.org/ abs/1705.08045. arXiv: 1705.08045.\\nAndreas Ruckle, Gregor Geigle, Max Glockner, Tilman Beck, Jonas Pfeiffer, Nils Reimers, and\\nIryna Gurevych. Adapterdrop: On the efciency of adapters in transformers, 2020.\\nTara N Sainath, Brian Kingsbury, Vikas Sindhwani, Ebru Arisoy, and Bhuvana Ramabhadran. Low- rank matrix factorization for deep neural network training with high-dimensional output targets. In 2013 IEEE international conference on acoustics, speech and signal processing, pp. 6655 6659. IEEE, 2013.\\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-lm: Training multi-billion parameter language models using model par- allelism, 2020.\\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 16311642, Seattle, Washington, USA, October 2013. Association for Computa- tional Linguistics. URL https://aclanthology.org/D13-1170.\\n15\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 16}}\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Proceedings of the 31st In- ternational Conference on Neural Information Processing Systems, pp. 60006010, 2017.\\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding, 2019.\\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems, 2020.\\nAlex Warstadt, Amanpreet Singh, and Samuel R Bowman. Neural network acceptability judgments.\\narXiv preprint arXiv:1805.12471, 2018.\\nAdina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sen- In Proceedings of the 2018 Conference of the North tence understanding through inference. American Chapter of the Association for Computational Linguistics: Human Language Technolo- gies, Volume 1 (Long Papers), pp. 11121122, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1101. URL https://www.aclweb. org/anthology/N18-1101.\\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gug- ger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 3845, Online, October 2020. As- sociation for Computational Linguistics. URL https://www.aclweb.org/anthology/ 2020.emnlp-demos.6.\\nGreg Yang and Edward J. Hu.\\nFeature Learning in Innite-Width Neural Networks. arXiv:2011.14522 [cond-mat], May 2021. URL http://arxiv.org/abs/2011.14522. arXiv: 2011.14522.\\nElad Ben Zaken, Shauli Ravfogel, and Yoav Goldberg. Bitt: Simple parameter-efcient ne-tuning\\nfor transformer-based masked language-models, 2021.\\nYu Zhang, Ekapol Chuangsuwanich, and James Glass. Extracting deep neural network bottleneck features using low-rank matrix factorization. In 2014 IEEE international conference on acoustics, speech and signal processing (ICASSP), pp. 185189. IEEE, 2014.\\nYong Zhao, Jinyu Li, and Yifan Gong. Low-rank plus diagonal adaptation for deep neural networks. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 50055009. IEEE, 2016.\\nVictor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: Generating structured queries from natural language using reinforcement learning. CoRR, abs/1709.00103, 2017. URL http:// arxiv.org/abs/1709.00103.\\nA LARGE LANGUAGE MODELS STILL NEED PARAMETER UPDATES\\nFew-shot learning, or prompt engineering, is very advantageous when we only have a handful of training samples. However, in practice, we can often afford to curate a few thousand or more training examples for performance-sensitive applications. As shown in Table 8, ne-tuning improves the model performance drastically compared to few-shot learning on datasets large and small. We take the GPT-3 few-shot result on RTE from the GPT-3 paper (Brown et al., 2020). For MNLI-matched, we use two demonstrations per class and six in-context examples in total.\\n16\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 17}}\\nMethod\\nMNLI-m (Val. Acc./%) RTE (Val. Acc./%)\\nGPT-3 Few-Shot GPT-3 Fine-Tuned\\n40.6 89.5\\n69.0 85.4\\nTable 8: Fine-tuning signicantly outperforms few-shot learning on GPT-3 (Brown et al., 2020).\\nB INFERENCE LATENCY INTRODUCED BY ADAPTER LAYERS\\nAdapter layers are external modules added to a pre-trained model in a sequential manner, whereas our proposal, LoRA, can be seen as external modules added in a parallel manner. Consequently, adapter layers must be computed in addition to the base model, inevitably introducing additional latency. While as pointed out in Ruckle et al. (2020), the latency introduced by adapter layers can be mitigated when the model batch size and/or sequence length is large enough to full utilize the hardware parallelism. We conrm their observation with a similar latency study on GPT-2 medium and point out that there are scenarios, notably online inference where the batch size is small, where the added latency can be signicant.\\nWe measure the latency of a single forward pass on an NVIDIA Quadro RTX8000 by averaging over 100 trials. We vary the input batch size, sequence length, and the adapter bottleneck dimension r. We test two adapter designs: the original one by Houlsby et al. (2019), which we call AdapterH, and a recent, more efcient variant by Lin et al. (2020), which we call AdapterL. See Section 5.1 for more details on the designs. We plot the slow-down in percentage compared to the no-adapter baseline in Figure 5.\\n12481632Batch Size010100250AdapterL r\\n10\\n010100250AdapterH r\\n0\\n25\\n12481632Batch Size\\n5\\n35\\n15\\n12481632Batch Size\\n30\\n20\\nSeq Len = 256\\nSeq Len = 128\\nSeq Len = 512\\nFigure 5: Percentage slow-down of inference latency compared to the no-adapter (r = 0) baseline. The top row shows the result for AdapterH and the bottom row AdapterL. Larger batch size and sequence length help to mitigate the latency, but the slow-down can be as high as over 30% in an online, short-sequence-length scenario. We tweak the colormap for better visibility.\\nC DATASET DETAILS\\nGLUE Benchmark is a wide-ranging collection of natural language understanding tasks. It includes MNLI (inference, Williams et al. (2018)), SST-2 (sentiment analysis, Socher et al. (2013)), MRPC (paraphrase detection, Dolan & Brockett (2005)), CoLA (linguistic acceptability, Warstadt et al. (2018)), QNLI (inference, Rajpurkar et al. (2018)), QQP8 (question-answering), RTE (inference),\\n8https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs\\n17\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 18}}\\nand STS-B (textual similarity, Cer et al. (2017)). The broad coverage makes GLUE benchmark a standard metric to evaluate NLU models such as RoBERTa and DeBERTa. The individual datasets are released under different permissive licenses.\\nWikiSQL is introduced in Zhong et al. (2017) and contains 56,355/8,421 training/validation ex- amples. The task is to generate SQL queries from natural language questions and table schemata. We encode context as x = {table schema,query} and target as y = {SQL}. The dataset is release under the BSD 3-Clause License.\\nSAMSum is introduced in Gliwa et al. (2019) and contains 14,732/819 training/test examples. It consists of staged chat conversations between two people and corresponding abstractive summaries written by linguists. We encode context as \\\\n concatenated utterances followed by a \\\\n\\\\n, and target as y = {summary}. The dataset is released under the non-commercial licence: Creative Commons BY-NC-ND 4.0.\\nE2E NLG Challenge was rst introduced in Novikova et al. (2017) as a dataset for training end-to- end, data-driven natural language generation systems and is commonly used for data-to-text evalua- tion. The E2E dataset consists of roughly 42,000 training, 4,600 validation, and 4,600 test exam- ples from the restaurant domain. Each source table used as input can have multiple references. Each sample input (x,y) consists of a sequence of slot-value pairs, along with a corresponding natural language reference text. The dataset is released under Creative Commons BY-NC-SA 4.0.\\nDART is an open-domain data-to-text dataset described in Nan et al. (2020). DART inputs are structured as sequences of ENTITY  RELATION  ENTITY triples. With 82K examples in total, DART is a signicantly larger and more complex data-to-text task compared to E2E. The dataset is released under the MIT license.\\nWebNLG is another commonly used dataset for data-to-text evaluation (Gardent et al., 2017). With 22K examples in total WebNLG comprises 14 distinct categories, nine of which are seen during training. Since ve of the 14 total categories are not seen during training, but are represented in the test set, evaluation is typically broken out by seen categories (S), unseen categories (U) and all (A). Each input example is represented by a sequence of SUBJECT  PROPERTY  OBJECT triples. The dataset is released under Creative Commons BY-NC-SA 4.0.\\nD HYPERPARAMETERS USED IN EXPERIMENTS\\nD.1 ROBERTA\\nWe train using AdamW with a linear learning rate decay schedule. We sweep learning rate, number of training epochs, and batch size for LoRA. Following Liu et al. (2019), we initialize the LoRA modules to our best MNLI checkpoint when adapting to MRPC, RTE, and STS-B, instead of the usual initialization; the pre-trained model stays frozen for all tasks. We report the median over 5 random seeds; the result for each run is taken from the best epoch. For a fair comparison with the setup in Houlsby et al. (2019) and Pfeiffer et al. (2021), we restrict the model sequence length to 128 and used a xed batch size for all tasks. Importantly, we start with the pre-trained RoBERTa large model when adapting to MRPC, RTE, and STS-B, instead of a model already adapted to MNLI. The runs with this restricted setup are marked with . See the hyperparameters used in our runs in Table 9.\\nD.2 DEBERTA\\nWe again train using AdamW with a linear learning rate decay schedule. Following He et al. (2021), we tune learning rate, dropout probability, warm-up steps, and batch size. We use the same model sequence length used by (He et al., 2021) to keep our comparison fair. Following He et al. (2021), we initialize the LoRA modules to our best MNLI checkpoint when adapting to MRPC, RTE, and STS-B, instead of the usual initialization; the pre-trained model stays frozen for all tasks. We report the median over 5 random seeds; the result for each run is taken from the best epoch. See the hyperparameters used in our runs in Table 10.\\n18\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 19}}\\nMethod\\nDataset\\nMNLI SST-2 MRPC CoLA QNLI QQP\\nRTE\\nOptimizer Warmup Ratio LR Schedule\\nAdamW 0.06 Linear\\nRoBERTa base LoRA\\nBatch Size # Epochs Learning Rate LoRA Cong. LoRA  Max Seq. Len.\\n16 30 5E-04\\n16 60 5E-04\\n16 30 4E-04\\n32 80 4E-04 rq = rv = 8 8 512\\n32 25 4E-04\\n16 25 5E-04\\n32 80 5E-04\\nRoBERTa large LoRA\\nBatch Size # Epochs Learning Rate LoRA Cong. LoRA  Max Seq. Len.\\n4 10 3E-04\\n128\\n4 10 4E-04\\n128\\n4 20 3E-04\\n512\\n4 20 2E-04 rq = rv = 8 16\\n4 10 2E-04\\n128\\n512\\n4 20 3E-04\\n512\\n8 20 4E-04\\n512\\nRoBERTa large LoRA\\nBatch Size # Epochs Learning Rate LoRA Cong. LoRA  Max Seq. Len.\\n10 3E-04\\n10 4E-04\\n20 3E-04\\n4\\n20 2E-04 rq = rv = 8 16 128\\n10 2E-04\\n20 3E-04\\n20 4E-04\\nRoBERTa large AdptP (3M)\\nBatch Size # Epochs Learning Rate Bottleneck r Max Seq. Len.\\n10 3E-05\\n20 3E-05\\n20 3E-04\\n20 3E-04\\n32\\n64 128\\n10 3E-04\\n20 3E-04\\n20 3E-04\\nRoBERTa large AdptP (0.8M)\\nBatch Size # Epochs Learning Rate Bottleneck r Max Seq. Len.\\n5 3E-04\\n20 3E-04\\n20 3E-04\\n20 3E-04\\n32\\n16 128\\n10 3E-04\\n20 3E-04\\n20 3E-04\\nRoBERTa large AdptH (6M)\\nBatch Size # Epochs Learning Rate Bottleneck r Max Seq. Len.\\n10 3E-05\\n5 3E-04\\n10 3E-04\\n10 3E-04\\n32\\n64 128\\n5 3E-04\\n20 3E-04\\n20 3E-04\\nRoBERTa large AdptH (0.8M)\\nBatch Size # Epochs Learning Rate Bottleneck r Max Seq. Len.\\n10 3E-04\\n5 3E-04\\n10 3E-04\\n10 3E-04\\n32\\n8 128\\n5 3E-04\\n20 3E-04\\n20 3E-04\\nTable 9: The hyperparameters we used for RoBERTa on the GLUE benchmark.\\nD.3 GPT-2\\nWe train all of our GPT-2 models using AdamW (Loshchilov & Hutter, 2017) with a linear learning rate schedule for 5 epochs. We use the batch size, learning rate, and beam search beam size described in Li & Liang (2021). Accordingly, we also tune the above hyperparameters for LoRA. We report the mean over 3 random seeds; the result for each run is taken from the best epoch. The hyperparameters used for LoRA in GPT-2 are listed in Table 11. For those used for other baselines, see Li & Liang (2021).\\nD.4 GPT-3\\nFor all GPT-3 experiments, we train using AdamW (Loshchilov & Hutter, 2017) for 2 epochs with a batch size of 128 samples and a weight decay factor of 0.1. We use a sequence length of 384 for\\n19\\nSTS-B\\n16 40 4E-04\\n8 30 2E-04\\n512\\n10 2E-04\\n20 3E-04\\n20 3E-04\\n10 3E-04\\n10 3E-04\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 20}}\\nMethod\\nDataset\\nMNLI SST-2 MRPC CoLA QNLI QQP\\nRTE\\nOptimizer Warmup Ratio LR Schedule\\nAdamW 0.1 Linear\\nDeBERTa XXL LoRA\\nBatch Size # Epochs Learning Rate Weight Decay CLS Dropout LoRA Cong. LoRA  Max Seq. Len.\\n8 5 1E-04 0 0.15\\n256\\n8 16 6E-05 0.01 0\\n128\\n32 30 2E-04 0.01 0\\n128\\n6 4 8 10 1E-04 1E-04 0.01 0 0.1 0.1 rq = rv = 8 8\\n64\\n512\\n8 11 1E-04 0.01 0.2\\n320\\n4 11 2E-04 0.01 0.2\\n320\\nTable 10: The hyperparameters for DeBERTa XXL on tasks included in the GLUE benchmark.\\nDataset\\nE2E WebNLG DART\\nTraining\\nOptimizer Weight Decay Dropout Prob Batch Size # Epoch Warmup Steps Learning Rate Schedule Label Smooth Learning Rate Adaptation LoRA \\n0.01 0.1\\n0.1\\nAdamW 0.01 0.1 8 5 500 Linear 0.1 0.0002 rq = rv = 4 32\\n0.0 0.0\\n0.0\\nInference\\nBeam Size Length Penalty no repeat ngram size\\n0.9\\n10 0.8 4\\n0.8\\nTable 11: The hyperparameters for GPT-2 LoRA on E2E, WebNLG and DART.\\nWikiSQL (Zhong et al., 2017), 768 for MNLI (Williams et al., 2018), and 2048 for SAMSum (Gliwa et al., 2019). We tune learning rate for all method-dataset combinations. See Section D.4 for more details on the hyperparameters used. For prex-embedding tuning, we nd the optimal lp and li to be 256 and 8, respectively, totalling 3.2M trainable parameters. We use lp = 8 and li = 8 for prex-layer tuning with 20.2M trainable parameters to obtain the overall best performance. We present two parameter budgets for LoRA: 4.7M (rq = rv = 1 or rv = 2) and 37.7M (rq = rv = 8 or rq = rk = rv = ro = 2). We report the best validation performance from each run. The training hyperparameters used in our GPT-3 experiments are listed in Table 12.\\nE COMBINING LORA WITH PREFIX TUNING\\nLoRA can be naturally combined with existing prex-based approaches. In this section, we evaluate two combinations of LoRA and variants of prex-tuning on WikiSQL and MNLI.\\nLoRA+PrexEmbed (LoRA+PE) combines LoRA with prex-embedding tuning, where we insert lp + li special tokens whose embeddings are treated as trainable parameters. For more on prex- embedding tuning, see Section 5.1.\\nLoRA+PrexLayer (LoRA+PL) combines LoRA with prex-layer tuning. We also insert lp + li special tokens; however, instead of letting the hidden representations of these tokens evolve natu-\\n20\\nSTS-B\\n4 10 2E-04 0.1 0.2\\n128\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 21}}\\nHyperparameters\\nFine-Tune\\nPreEmbed\\nPreLayer\\nBitFit\\nAdapterH\\nLoRA\\nOptimizer Batch Size # Epoch Warmup Tokens LR Schedule\\nAdamW 128 2 250,000 Linear\\nLearning Rate\\n5.00E-06\\n5.00E-04\\n1.00E-04\\n1.6E-03\\n1.00E-04\\n2.00E-04\\nTable 12: The training hyperparameters used for different GPT-3 adaption methods. We use the same hyperparameters for all datasets after tuning learning rate.\\nrally, we replace them after every Transformer block with an input agnostic vector. Thus, both the embeddings and subsequent Transformer block activations are treated as trainable parameters. For more on prex-layer tuning, see Section 5.1.\\nIn Table 15, we show the evaluation results of LoRA+PE and LoRA+PL on WikiSQL and MultiNLI. First of all, LoRA+PE signicantly outperforms both LoRA and prex-embedding tuning on WikiSQL, which indicates that LoRA is somewhat orthogonal to prex-embedding tuning. On MultiNLI, the combination of LoRA+PE doesnt perform better than LoRA, possibly because LoRA on its own already achieves performance comparable to the human baseline. Secondly, we notice that LoRA+PL performs slightly worse than LoRA even with more trainable parameters. We at- tribute this to the fact that prex-layer tuning is very sensitive to the choice of learning rate and thus makes the optimization of LoRA weights more difcult in LoRA+PL.\\nF ADDITIONAL EMPIRICAL EXPERIMENTS\\nF.1 ADDITIONAL EXPERIMENTS ON GPT-2\\nWe also repeat our experiment on DART (Nan et al., 2020) and WebNLG (Gardent et al., 2017) following the setup of Li & Liang (2021). The result is shown in Table 13. Similar to our result on E2E NLG Challenge, reported in Section 5, LoRA performs better than or at least on-par with prex-based approaches given the same number of trainable parameters.\\nMethod\\n# Trainable Parameters BLEU MET TER\\nDART\\nFine-Tune AdapterL AdapterL FTTop2 PrefLayer LoRA\\nGPT-2 Medium 46.2 42.4 45.2 41.0 46.4 47.1.2\\n354M 0.37M 11M 24M 0.35M 0.35M\\n0.39 0.36 0.38 0.34 0.38 0.39\\n0.46 0.48 0.46 0.56 0.46 0.46\\nFine-Tune AdapterL AdapterL PrefLayer LoRA\\nGPT-2 Large 47.0 45.7.1 47.1.1 46.7 47.5.1\\n774M 0.88M 23M 0.77M 0.77M\\n0.39 0.38 0.39 0.38 0.39\\n0.46 0.46 0.45 0.45 0.45\\nTable 13: GPT-2 with different adaptation methods on DART. The variances of MET and TER are less than 0.01 for all adaption approaches.\\n21\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 22}}\\nMethod\\nWebNLG\\nU\\nBLEU S\\nA\\nU\\nMET S\\nA\\nU\\nTER S\\nFine-Tune (354M) AdapterL (0.37M) AdapterL (11M) FTTop2 (24M) Prex (0.35M) LoRA (0.35M)\\n27.7 45.1 48.3 18.9 45.6 46.7.4\\n64.2 54.5 60.4 53.6 62.9 62.1.2\\nGPT-2 Medium .45 .30 .39 .36 .38 .43 .38 .23 .38 .44 .38 .44\\n46.5 50.2 54.9 36.0 55.1 55.3.2\\n.38 .38 .41 .31 .41 .41\\n.76 .46 .45 .99 .49 .46\\n.33 .40 .35 .49 .35 .33\\nFine-Tune (774M) AdapterL (0.88M) AdapterL (23M) Prex (0.77M) LoRA (0.77M)\\n43.1 49.8.0 49.2.1 47.7 48.4.3\\n65.3 61.1.0 64.7.2 63.4 64.0.3\\nGPT-2 Large .38 .38 .39 .39 .39\\n55.5 56.0.0 57.7.1 56.3 57.0.1\\n.46 .43 .46 .45 .45\\n.42 .41 .43 .42 .42\\n.53 .44 .46 .48 .45\\n.33 .35 .33 .34 .32\\nTable 14: GPT-2 with different adaptation methods on WebNLG. The variances of MET and TER are less than 0.01 for all the experiments we ran. U indicates unseen categories, S indicates seen categories, and A indicates all categories in the test set of WebNLG.\\nF.2 ADDITIONAL EXPERIMENTS ON GPT-3\\nWe present additional runs on GPT-3 with different adaptation methods in Table 15. The focus is on identifying the trade-off between performance and the number of trainable parameters.\\nF.3 LOW-DATA REGIME\\nTo evaluate the performance of different adaptation approaches in the low-data regime. we randomly sample 100, 1k and 10k training examples from the full training set of MNLI to form the low-data MNLI-n tasks. In Table 16, we show the performance of different adaptation approaches on MNLI- n. To our surprise, PrexEmbed and PrexLayer performs very poorly on MNLI-100 dataset, with PrexEmbed performing only slightly better than random chance (37.6% vs. 33.3%). PrexLayer performs better than PrexEmbed but is still signicantly worse than Fine-Tune or LoRA on MNLI- 100. The gap between prex-based approaches and LoRA/Fine-tuning becomes smaller as we in- crease the number of training examples, which might suggest that prex-based approaches are not suitable for low-data tasks in GPT-3. LoRA achieves better performance than ne-tuning on both MNLI-100 and MNLI-Full, and comparable results on MNLI-1k and MNLI-10K considering the (0.3) variance due to random seeds.\\nThe training hyperparameters of different adaptation approaches on MNLI-n are reported in Ta- ble 17. We use a smaller learning rate for PrexLayer on the MNLI-100 set, as the training loss does not decrease with a larger learning rate.\\nG MEASURING SIMILARITY BETWEEN SUBSPACES\\nB) = (cid:107)Ui(cid:62) A  Rdi and Uj\\nA UB(cid:107)2 F min{i,j}\\nA,Uj In this paper we use the measure (A,B,i,j) = (Ui to measure the subspace B  Rdj, obtained by similarity between two column orthonormal matrices Ui taking columns of the left singular matrices of A and B. We point out that this similarity is simply a reverse of the standard Projection Metric that measures distance between subspaces Ham & Lee (2008).\\n22\\nA\\n.53 .43 .39 .72 .40 .39\\n.42 .39 .39 .40 .38\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 23}}\\nMethod\\nHyperparameters\\n# Trainable Parameters WikiSQL MNLI-m\\nFine-Tune\\n\\n175B\\n73.8\\n89.5\\nPrexEmbed\\nPrexLayer\\nAdapterH\\nlp = 32,li = 8 lp = 64,li = 8 lp = 128,li = 8 lp = 256,li = 8 lp = 512,li = 8 lp = 2,li = 2 lp = 8,li = 0 lp = 8,li = 8 lp = 32,li = 4 lp = 64,li = 0 r = 1 r = 4 r = 8 r = 16 r = 64\\n0.4 M 0.9 M 1.7 M 3.2 M 6.4 M\\n5.1 M 10.1 M 20.2 M 44.1 M 76.1 M\\n7.1 M 21.2 M 40.1 M 77.9 M 304.4 M\\n55.9 58.7 60.6 63.1 55.9\\n68.5 69.8 70.1 66.4 64.9\\n71.9 73.2 73.2 73.2 72.6\\n84.9 88.1 88.0 88.6 85.8\\n89.2 88.2 89.5 89.6 87.9\\n89.8 91.0 91.5 91.5 91.5\\nLoRA\\nLoRA+PE\\nrv = 2 rq = rv = 1 rq = rv = 2 rq = rk = rv = ro = 1 rq = rv = 4 rq = rk = rv = ro = 2 rq = rv = 8 rq = rk = rv = ro = 4 rq = rv = 64 rq = rk = rv = ro = 64 rq = rv = 8,lp = 8,li = 4 rq = rv = 32,lp = 8,li = 4 rq = rv = 64,lp = 8,li = 4 rq = rv = 8,lp = 8,li = 4\\n4.7 M 4.7 M 9.4 M 9.4 M 18.8 M 18.8 M 37.7 M 37.7 M 301.9 M 603.8 M\\n37.8 M 151.1 M 302.1 M\\n73.4 73.4 73.3 74.1 73.7 73.7 73.8 74.0 73.6 73.9\\n75.0 75.9 76.2\\n91.7 91.3 91.4 91.2 91.3 91.7 91.6 91.7 91.4 91.4\\n91.4 91.1 91.3\\nLoRA+PL\\n52.8 M\\n72.9\\n90.2\\nTable 15: Hyperparameter analysis of different adaptation approaches on WikiSQL and MNLI. Both prex-embedding tuning (PrexEmbed) and prex-layer tuning (PrexLayer) perform worse as we increase the number of trainable parameters, while LoRAs performance stabilizes. Performance is measured in validation accuracy.\\nMethod\\nMNLI(m)-100 MNLI(m)-1k MNLI(m)-10k MNLI(m)-392K\\nGPT-3 (Fine-Tune) GPT-3 (PrexEmbed) GPT-3 (PrexLayer) GPT-3 (LoRA)\\n60.2 37.6 48.3 63.8\\n85.8 75.2 82.5 85.6\\n88.9 79.5 85.9 89.2\\n89.5 88.6 89.6 91.7\\nTable 16: Validation accuracy of different methods on subsets of MNLI using GPT-3 175B. MNLI- n describes a subset with n training examples. We evaluate with the full validation set. LoRA performs exhibits favorable sample-efciency compared to other methods, including ne-tuning.\\nA Uj\\nTo be concrete, let the singular values of Ui(cid:62) know that the Projection Metric Ham & Lee (2008) is dened as:\\nB to be 1,2, ,p where p = min{i,j}. We\\nA,Uj\\nd(Ui\\nB) =\\n(cid:118) (cid:117) (cid:117) (cid:116)p \\np (cid:88)\\n2 i  [0,\\n\\np]\\ni=1\\n23\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 24}}\\nHyperparameters\\nAdaptation\\nMNLI-100 MNLI-1k MNLI-10K MNLI-392K\\nOptimizer Warmup Tokens LR Schedule Batch Size # Epoch\\n- - - -\\n20 40\\n20 40\\nAdamW 250,000 Linear\\n100 4\\n128 2\\nLearning Rate\\nFineTune PrexEmbed PrexLayer LoRA\\n2.00E-04 5.00E-05\\n2.00E-04 5.00E-05\\n5.00E-6\\n4.00E-04 5.00E-05\\n2.00E-4\\n5.00E-04 1.00E-04\\nAdaptation- Specic\\nPrexEmbed lp PrexEmbed li PrexTune LoRA\\n16\\n32\\n64\\n8 lp = li = 8 rq = rv = 8\\n256\\nTable 17: The hyperparameters used for different GPT-3 adaptation methods on MNLI(m)-n.\\nwhere our similarity is dened as:\\n(A,B,i,j) = (Ui\\nA,Uj\\nB) =\\n(cid:80)p\\ni=1 2 i p\\n=\\n1 p\\n(cid:16)\\n1  d(Ui\\nB)2(cid:17)\\nA,Uj\\nA and Uj\\nThis similarity satises that if Ui they are completely orthogonal, then (A,B,i,j) = 0. Otherwise, (A,B,i,j)  (0,1).\\nB share the same column span, then (A,B,i,j) = 1. If\\nH ADDITIONAL EXPERIMENTS ON LOW-RANK MATRICES\\nWe present additional results from our investigation into the low-rank update matrices.\\nH.1 CORRELATION BETWEEN LORA MODULES\\nSee Figure 6 and Figure 7 for how the results presented in Figure 3 and Figure 4 generalize to other layers.\\nH.2 EFFECT OF r ON GPT-2\\nWe repeat our experiment on the effect of r (Section 7.2) in GPT-2. Using the E2E NLG Challenge dataset as an example, we report the validation loss and test metrics achieved by different choices of r after training for 26,000 steps. We present our result in Table 18. The optimal rank for GPT-2 Medium is between 4 and 16 depending on the metric used, which is similar to that for GPT-3 175B. Note that the relationship between model size and the optimal rank for adaptation is still an open question.\\nH.3 CORRELATION BETWEEN W AND W\\nSee Figure 8 for the normalized subspace similarity between W and W with varying r.\\nNote again that W does not contain the top singular directions of W, since the similarity between the top 4 directions in W and the top-10% of those in W barely exceeds 0.2. This gives evidence that W contains those task-specic directions that are otherwise not emphasized in W.\\nAn interesting next question to answer, is how strong do we need to amplify those task-specic directions, in order for the model adaptation to work well?\\n24\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 25}}\\n0.6\\nWq\\n0.0\\n0.8\\nWv\\n12345678j\\nWq\\nWv\\n12345678Layer 64i\\n12345678Layer 32i\\n12345678j\\n0.2\\n1.0\\n16121823293540465258j12345678Layer 96i\\n0.4\\n12345678Layer 1i\\n(Ar=8,Ar=64,i,j)\\n16121823293540465258j\\nFigure 6: Normalized subspace similarity between the column vectors of Ar=8 and Ar=64 for both Wq and Wv from the 1st, 32nd, 64th, and 96th layers in a 96-layer Transformer.\\nH.4 AMPLIFICATION FACTOR\\n(cid:107)W(cid:107)F (cid:107)U(cid:62)WV (cid:62)(cid:107)F\\nOne can naturally consider a feature amplication factor as the ratio , where U and V are the left- and right-singular matrices of the SVD decomposition of W. (Recall UU(cid:62)WV (cid:62)V gives the projection of W onto the subspace spanned by W.)\\nIntuitively, when W mostly contains task-specic directions, this quantity measures how much of them are amplied by W. As shown in Section 7.3, for r = 4, this amplication factor is as large as 20. In other words, there are (generally speaking) four feature directions in each layer (out of the entire feature space from the pre-trained model W), that need to be amplied by a very large factor 20, in order to achieve our reported accuracy for the downstream specic task. And, one should expect a very different set of feature directions to be amplied for each different downstream task.\\nOne may notice, however, for r = 64, this amplication factor is only around 2, meaning that most directions learned in W with r = 64 are not being amplied by much. This should not be surprising, and in fact gives evidence (once again) that the intrinsic rank needed to represent the task-specic directions (thus for model adaptation) is low. In contrast, those directions in the rank-4 version of W (corresponding to r = 4) are amplied by a much larger factor 20.\\n25\\n\\n{\"asksage_metadata\": {\"filename\": \"LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf\", \"page_number\": 26}}\\n0.5\\n17131925313743495561Layer 1i\\n0.8\\n0.4\\n0.2\\n0.1\\n161116212631364146515661j\\nWq\\n161116212631364146515661jLayer 96\\n161116212631364146515661j17131925313743495561Layer 64i\\nWv\\nLayer 32\\n0.0\\n0.3\\n(Ar=64,A0r=64,i,j)\\nWv\\n0.6\\n161116212631364146515661j\\nWq\\n0.7\\nFigure 7: Normalized subspace similarity between the column vectors of Ar=64 from two randomly seeded runs, for both Wq and Wv from the 1st, 32nd, 64th, and 96th layers in a 96-layer Trans- former.\\nRank r\\nval loss BLEU NIST METEOR ROUGE L CIDEr\\n1 2 4 8 16 32 64 128 256 512 1024\\n1.23 1.21 1.18 1.17 1.16 1.16 1.16 1.16 1.16 1.16 1.17\\n68.72 69.17 70.38 69.57 69.61 69.33 69.24 68.73 68.92 68.78 69.37\\n8.7215 8.7413 8.8439 8.7457 8.7483 8.7736 8.7174 8.6718 8.6982 8.6857 8.7495\\n0.4565 0.4590 0.4689 0.4636 0.4629 0.4642 0.4651 0.4628 0.4629 0.4637 0.4659\\n0.7052 0.7052 0.7186 0.7196 0.7177 0.7105 0.7180 0.7127 0.7128 0.7128 0.7149\\n2.4329 2.4639 2.5349 2.5196 2.4985 2.5255 2.5070 2.5030 2.5012 2.5025 2.5090\\nTable 18: Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r using GPT-2 Medium. Unlike on GPT-3 where r = 1 sufces for many tasks, here the performance peaks at r = 16 for validation loss and r = 4 for BLEU, suggesting the GPT-2 Medium has a similar intrinsic rank for adaptation compared to GPT-3 175B. Note that some of our hyperparameters are tuned on r = 4, which matches the parameter count of another baseline, and thus might not be optimal for other choices of r.\\nj\\nWq\\nj\\nj45155565876286596910721176i\\n0.200\\n0.100\\n(Wq,Ar=4,i,j)\\n(Wq,Ar=8,i,j)\\nRandom(Wq,Arand,i,j)\\n0.125\\n(Wq,Ar=64,i,j)\\n0.175\\nj\\n0.150\\nFigure 8: Normalized subspace similarity between the singular directions of Wq and those of Wq with varying r and a random baseline. Wq amplies directions that are important but not empha- sized in W. W with a larger r tends to pick up more directions that are already emphasized in W.\\n26\\n',\n",
       " 'sent_filename': 'LORA-LOW-RANKADAPTATIONOFLARGELANGUAGEMODELS.pdf',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of chunks in LORA- LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS.pdf is: 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'OK',\n",
       " 'ret': '{\"asksage_metadata\": {\"filename\": \"random_photo.png\", \"page_number\": \"1\"}}\\nThe image depicts a black and white dog, likely a Border Collie or a similar breed, lying on a carpeted floor. The dog\\'s body is mostly black, with white markings on its chest, legs, and face. Its tail is black with a white tip, and its ears are upright, giving it an alert appearance. The dog is wearing a silver chain collar around its neck.\\n\\nThe dog is lying on its side, with its front legs crossed in a relaxed manner. Its head is turned slightly upward, and its gaze is directed toward the camera, showing one blue eye and one brown eye, which is a striking feature. The dog\\'s nose is pink with black spots.\\n\\nNear the dog, there are several objects visible:\\n1. A bright orange and blue rubber ball is positioned near the dog\\'s neck, partially under its head.\\n2. A spiked blue and white toy is on the carpet, slightly above the dog.\\n3. A pair of dumbbells, one marked with \"35\" (indicating 35 pounds), is placed near the spiked toy.\\n4. The carpet is beige and textured, while the adjacent flooring is wooden with a natural finish.\\n\\nThe overall setting appears to be indoors, possibly in a living room or workout area, given the presence of the dumbbells and toys. The dog looks comfortable and relaxed in its environment.',\n",
       " 'sent_filename': 'random_photo.png',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of chunks in random_photo.png is: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'OK',\n",
       " 'ret': '\\n{\"asksage_metadata\": {\"filename\": \"In the small village of Willowbrook.pdf\", \"page_number\": 1}}\\nIn the small village of Willowbrook, there lived a scruffy little dog named Toby who had an unusual dislike for cats. Toby, with his ruffled fur and eager eyes, was known around the village for his playful spirit, but he would always steer clear of any feline. One day, a new cat moved into the neighborhood. The cat, sleek and confident, quickly noticed Toby\\'s aversion. Curious and a bit mischievous, the cat decided to find out why Toby was so hesitant around its kind. This set the stage for a series of amusing encounters, as the cat tried to win over the reluctant Toby, leading to unexpected friendship and adventures that would change Toby\\'s mind about cats forever.\\n',\n",
       " 'sent_filename': 'InthesmallvillageofWillowbrook.pdf',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of chunks in In the small village of Willowbrook.pdf is: 1\n"
     ]
    }
   ],
   "source": [
    "# data path\n",
    "path = 'data/query_with_file/'\n",
    "\n",
    "# get files in the data path\n",
    "files = os.listdir(path)\n",
    "\n",
    "# iterate over each file in the directory\n",
    "for file in files:\n",
    "    # get the file endpoint\n",
    "    file_endpoint = ask_sage_client.file(file_path=path + file, strategy='auto')\n",
    "    \n",
    "    # display the full response for the current file\n",
    "    display(file_endpoint)\n",
    "    \n",
    "    # extract the 'ret' field from the response\n",
    "    ret = file_endpoint['ret']\n",
    "    \n",
    "    # count # of chunks by the number of 'asksage_metadata' appears in ret\n",
    "    count = ret.count('asksage_metadata')\n",
    "    print(f'The number of chunks in {file} is: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Token Volume Report  (Stage #3)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 49480\n",
      "The count of monthly inference/query tokens used are: 1420075\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #2)  Current End (Stage #3):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 1992}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #2)         49480       1418083\n",
      "End (Stage #3)           49480       1420075\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  3)</th>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (2  3)</th>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  3)                 0              1992        No Change   \n",
       "Prior vs End (2  3)                 0              1992        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  3)          Changed  \n",
       "Prior vs End (2  3)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 0, 'query_tokens_used': 1992}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 1992}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason this endpoint used tokens is that image and audio files require inference tokens to process. Therefore, the user will be charged for the inference tokens used when processing these files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Get Datasets\n",
    "\n",
    "The `get_datasets` function retrieves all the available `Ask Sage Datasets` that have been created by the user/account. These datasets are vector datasets that are used to perform RAG(Retrieval-Augmented Generation) where the model retrieves information from the dataset to generate responses leveraging sophisticated semantic search capabilities brought to you by Ask Sage. \n",
    "\n",
    "Access to custom datasets that are created on the account are only available to the user that created the dataset unless they share the dataset with other users. Likewise, if someone else shares a dataset with you, you will be able to see the dataset in your account. \n",
    "\n",
    "When a dataset is shared there are various permissions that can be set for the dataset, such as `read`, `edit`, `Admin` access. \n",
    "\n",
    "- `read`: Allows the user to select the dataset for use for querying - RAG. \n",
    "- `edit`: Allows the user to edit the dataset by being able to view the content and add more content to the dataset.\n",
    "- `Admin`: Allows the user to also edit the dataset and share the dataset with other users.\n",
    "\n",
    "Only the owner of the dataset can delete the dataset and delete the content within the dataset.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Sharing a dataset is easily done within the Ask Sage platform by navigating to `Data Management` and selecting the dataset you want to share. (There is a share icon next to the dataset name).\n",
    "\n",
    "Also, elevating a user to anything other than `read` access can only be done within the Ask Sage platform and not through the API.\n",
    "</div>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Index | Dataset Name              |\n",
    "|-------|---------------------------|\n",
    "| 0     | Acquisition.gov           |\n",
    "| 1     | Air Force                 |\n",
    "| 2     | DoD                       |\n",
    "| 3     | Department of Defense     |\n",
    "| 4     | Learn with Nic            |\n",
    "| 5     | In the Nic of Time        |\n",
    "| 6     | Platform One              |\n",
    "| 7     | Nic Chaillan's Website    |\n",
    "| 8     | Cloud One                 |\n",
    "| 9     | NIST_NVD_CVE              |\n",
    "| 10    | Sage                      |\n",
    "| 11    | user_custom_1514845_datasetname_content  |\n",
    "</center>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b>Custom datasets follow a specific naming convention, as demonstrated in the example above. The structure is outlined below:\n",
    "\n",
    "- **Prefix**: `user_custom_`\n",
    "- **ID**: A unique identifier, e.g., `1514845`\n",
    "- **Name**: The dataset name, e.g., `datasetname`\n",
    "- **Suffix**: `_content`\n",
    "\n",
    "When combined, the full dataset name becomes:  \n",
    "`user_custom_1514845_datasetname_content`\n",
    "\n",
    "This naming convention is essential for identifying datasets and their content. When using a dataset as a parameter in endpoints like `query` or `train`, ensure you provide the full dataset name in the format shown above.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acquisition.gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DoD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Department of Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learn with Nic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In the Nic of Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Platform One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nic Chaillan's Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloud One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIST_NVD_CVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_custom_43841_JFK-Files-March-2025_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_custom_11_Nic-Test_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user_custom_29540_Ask-Sage-Documentation_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_custom_812_Nic-ShareTest10_content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                    Acquisition.gov\n",
       "1                                          Air Force\n",
       "2                                                DoD\n",
       "3                              Department of Defense\n",
       "4                                     Learn with Nic\n",
       "5                                 In the Nic of Time\n",
       "6                                       Platform One\n",
       "7                             Nic Chaillan's Website\n",
       "8                                          Cloud One\n",
       "9                                       NIST_NVD_CVE\n",
       "10                                              Sage\n",
       "11    user_custom_43841_JFK-Files-March-2025_content\n",
       "12                   user_custom_11_Nic-Test_content\n",
       "13  user_custom_29540_Ask-Sage-Documentation_content\n",
       "14           user_custom_812_Nic-ShareTest10_content"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract relevant information from the response\n",
    "def extract_datasets(response):\n",
    "    return response['response']\n",
    "\n",
    "get_datasets = ask_sage_client.get_datasets() # Get the datasets using the get_datasets endpoint\n",
    "\n",
    "\n",
    "def display_datasets(ask_sage_client):\n",
    "    \"\"\"   \n",
    "    Function to display the datasets in a dataframe\n",
    "\n",
    "    Parameters:\n",
    "    ask_sage_client: AskSageClient - The AskSageClient instance\n",
    "\n",
    "    Returns:\n",
    "    None - Displays the datasets in a dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    get_datasets = ask_sage_client.get_datasets() # Get the datasets using the get_datasets endpoint\n",
    "    datasets = extract_datasets(get_datasets) # Extract the datasets using the extract_datasets function\n",
    "    datasets_df = pd.DataFrame(datasets)\n",
    "    return datasets_df\n",
    "\n",
    "user_datasets = display_datasets(ask_sage_client) # Display the datasets in a dataframe\n",
    "display(user_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Add Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint is used to create a new `Ask Sage dataset`, once the dataset is created via the API it will also be available on the AskSage platform for the user to use. \n",
    "\n",
    "The `add_dataset` function creates a new dataset in Ask Sage. The dataset can be used to store and manage data for utilizing retrieval-augmented generation (RAG) capabilities.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Datasets store embeddings rather than the actual files. These embeddings enable Retrieval-Augmented Generation (RAG), where the model retrieves relevant information from the dataset to generate responses. This process leverages Ask Sage's advanced semantic search capabilities for accurate and context-aware results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset name to be added is: 1-jupynotebk-asksage-ex-52\n",
      "API response for adding dataset: {'response': 'OK', 'status': 200}\n",
      "The dataset 1-jupynotebk-asksage-ex-52 was added successfully.\n",
      "The dataset name to be added is: 2-jupynotebk-asksage-ex-9\n",
      "API response for adding dataset: {'response': 'OK', 'status': 200}\n",
      "The dataset 2-jupynotebk-asksage-ex-9 was added successfully.\n",
      "--------------------------------------------------\n",
      "Updated Datasets List:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In the Nic of Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Platform One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nic Chaillan's Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloud One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIST_NVD_CVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_custom_43841_JFK-Files-March-2025_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_custom_11_Nic-Test_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user_custom_29540_Ask-Sage-Documentation_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_custom_812_Nic-ShareTest10_content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "5                                 In the Nic of Time\n",
       "6                                       Platform One\n",
       "7                             Nic Chaillan's Website\n",
       "8                                          Cloud One\n",
       "9                                       NIST_NVD_CVE\n",
       "10                                              Sage\n",
       "11    user_custom_43841_JFK-Files-March-2025_content\n",
       "12                   user_custom_11_Nic-Test_content\n",
       "13  user_custom_29540_Ask-Sage-Documentation_content\n",
       "14           user_custom_812_Nic-ShareTest10_content"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a unique dataset name to avoid conflicts\n",
    "def generate_unique_dataset_name(index, base_name='jupynotebk-asksage-ex'):\n",
    "    random_suffix = random.randint(1, 99)\n",
    "    return f'{index}-{base_name}-{random_suffix}'\n",
    "\n",
    "\n",
    "# Function to add a dataset and verify its addition\n",
    "def add_and_verify_dataset(dataset_name):\n",
    "        print(f'The dataset name to be added is: {dataset_name}')\n",
    "        create_dataset = ask_sage_client.add_dataset(dataset_name, classification=None) # classification can be 'Unclassified' or 'CUI' \n",
    "        print(f'API response for adding dataset: {create_dataset}') # Print the API response for adding the dataset\n",
    "        \n",
    "        # Retrieve the updated list of datasets\n",
    "        user_datasets = display_datasets(ask_sage_client)\n",
    "        \n",
    "        # Check if the dataset was added successfully\n",
    "        if any(user_datasets[0].str.contains(dataset_name, regex=True)):\n",
    "            print(f'The dataset {dataset_name} was added successfully.')\n",
    "            return user_datasets[user_datasets[0].str.contains(dataset_name, regex=True)].values[0][0]\n",
    "        else:\n",
    "            print(f'The dataset {dataset_name} was not added successfully.')\n",
    "            return None\n",
    "\n",
    "# Create and add the first dataset\n",
    "dataset_name_1 = generate_unique_dataset_name(1)\n",
    "dataset_entry_1 = add_and_verify_dataset(dataset_name_1)\n",
    "\n",
    "# Create and add the second dataset\n",
    "dataset_name_2 = generate_unique_dataset_name(2)\n",
    "dataset_entry_2 = add_and_verify_dataset(dataset_name_2)\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Updated Datasets List:\")\n",
    "display(user_datasets.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train\n",
    "\n",
    "The train endpoint is used to ingest provided text content into a `Ask Sage Dataset`. The content added to the dataset can then be used to perform RAG(Retrieval-Augmented Generation) where the model retrieves information from the dataset to generate responses leveraging sophisticated semantic search capabilities.\n",
    "\n",
    "Here are the parameters for the `train` endpoint:\n",
    "- The `content` is the text content that will be ingested into the dataset - Make sure the text is under 500 Tokens.\n",
    "- The `force_dataset` is the dataset where the intended embedding will be stored.\n",
    "  - Enter your custom dataset, must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by the user ID and DATASET-NAME by the name of your dataset. \n",
    "- The `context` is short context about the content (metadata). Under 20 tokens. \n",
    "- The `skip_vectordb` is whether to skip the VectorDB training. Default is False.\n",
    "\n",
    "Also, if users do not want to ingest the content into a dataset, they can not include the `force_dataset` parameter and the content will not be ingested into a dataset or set the `skip_vectordb` parameter to True which will skip the VectorDB training.\n",
    "\n",
    "----------\n",
    "\n",
    "For the output from the `train` endpoint, the following information will be returned in a JSON dictionary format:\n",
    "- `embedding`: The embedding of the content.\n",
    "- `response`: The response from the Ask Sage service. Which is the text content that was ingested into the dataset and the volume of tokens used. \n",
    "- `status`: The status of the request (success or failure).\n",
    "\n",
    "----------\n",
    "\n",
    "Usage: \n",
    "1) To create a vector embedding for a specific content and ingest it into a dataset.\n",
    "2) To use Ask Sage the embedding model via the /train  endpoint to return the embedding of the content and not ingest it into a dataset.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This is the first time actual training tokens are used - specifically `teach tokens` because users are using the embedding model to create a vector embedding for the content. Additionally, if you notice we have intentionally added token counts throughout the notebook to show the token usage. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> FAQ: <br>\n",
    "\n",
    "1) What Embedding Model is used in the Ask Sage API? <br>\n",
    "- Currently uses the embedding model: text-embedding-ada-002, 2 <br>\n",
    "\n",
    "2) Is there a limit to the number of tokens/volume of data that can be ingested into a dataset? <br>\n",
    "- Two limits to be aware of: <br>\n",
    "  - 500 tokens per content (train endpoint) <br>\n",
    "  - The volume of tokens available for the user in the current month. <br>\n",
    "  - Technically there is no limit to the number of contents that can be ingested into a dataset, but the user must be aware of the token usage. <br>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estimated tokens: 270'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Estimated tokens: 179'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Estimated tokens: 166'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 1  Soldering Instructions\n",
      "  Dataset: user_custom_34125_1-jupynotebk-asksage-ex-52_content\n",
      "  Context: Soldering Instructions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedding': [-0.007798455655574799,\n",
       "  0.01666206680238247,\n",
       "  0.002209562575444579,\n",
       "  -0.02471413090825081,\n",
       "  -0.02440980076789856,\n",
       "  0.008508559316396713,\n",
       "  -0.01534330379217863,\n",
       "  -0.03520083427429199,\n",
       "  -0.004346212837845087,\n",
       "  -0.024054748937487602,\n",
       "  0.01596464402973652,\n",
       "  0.016040725633502007,\n",
       "  -0.02599485218524933,\n",
       "  0.008762167766690254,\n",
       "  -0.018969902768731117,\n",
       "  -0.014468355104327202,\n",
       "  0.01410062238574028,\n",
       "  0.02880990505218506,\n",
       "  0.025436915457248688,\n",
       "  -0.026045573875308037,\n",
       "  -0.0377369187772274,\n",
       "  0.0011364823440089822,\n",
       "  0.008001342415809631,\n",
       "  -0.0065874760039150715,\n",
       "  0.0024282997474074364,\n",
       "  -0.01522917952388525,\n",
       "  0.011976652778685093,\n",
       "  0.00968149770051241,\n",
       "  0.002650206908583641,\n",
       "  0.010803714394569397,\n",
       "  0.01535598374903202,\n",
       "  0.017955468967556953,\n",
       "  -0.018843097612261772,\n",
       "  -0.021721553057432175,\n",
       "  -0.018120314925909042,\n",
       "  0.02142990380525589,\n",
       "  -0.011526498012244701,\n",
       "  0.0039372690953314304,\n",
       "  -0.013162272050976753,\n",
       "  -0.015584231354296207,\n",
       "  0.009789281524717808,\n",
       "  -0.007449744269251823,\n",
       "  0.012655055150389671,\n",
       "  0.015038973651826382,\n",
       "  -0.009903404861688614,\n",
       "  0.0035790475085377693,\n",
       "  -0.03139670938253403,\n",
       "  0.005059485789388418,\n",
       "  -0.02217804826796055,\n",
       "  0.02552567794919014,\n",
       "  0.019299592822790146,\n",
       "  -0.003978480584919453,\n",
       "  -0.03360310196876526,\n",
       "  -0.0333748534321785,\n",
       "  0.003804124891757965,\n",
       "  -0.007538507226854563,\n",
       "  0.00436840346083045,\n",
       "  0.025956811383366585,\n",
       "  0.024143511429429054,\n",
       "  -0.023915264755487442,\n",
       "  -0.013504642993211746,\n",
       "  -0.014138664118945599,\n",
       "  -0.0232685636729002,\n",
       "  0.015279901213943958,\n",
       "  0.0007715240935795009,\n",
       "  -0.00911087915301323,\n",
       "  0.020491551607847214,\n",
       "  -0.009218662045896053,\n",
       "  -0.009770260192453861,\n",
       "  0.0029941631946712732,\n",
       "  0.026400625705718994,\n",
       "  0.027541862800717354,\n",
       "  0.02541155368089676,\n",
       "  0.01200835406780243,\n",
       "  0.0014495300129055977,\n",
       "  0.009979487396776676,\n",
       "  -0.010695930570363998,\n",
       "  -0.0023633125238120556,\n",
       "  0.008698765188455582,\n",
       "  -0.010917838662862778,\n",
       "  0.0014423973625525832,\n",
       "  -0.011526498012244701,\n",
       "  -0.000331870251102373,\n",
       "  0.0226599033921957,\n",
       "  -0.010499384254217148,\n",
       "  -0.0076843323186039925,\n",
       "  0.019540520384907722,\n",
       "  -0.008800208568572998,\n",
       "  -0.006172192748636007,\n",
       "  -0.00975123979151249,\n",
       "  -0.015165777876973152,\n",
       "  0.033679183572530746,\n",
       "  -0.0002900645195040852,\n",
       "  -0.006815723609179258,\n",
       "  0.003013183828443289,\n",
       "  0.034820422530174255,\n",
       "  -0.019667325541377068,\n",
       "  0.027744749560952187,\n",
       "  -0.020694438368082047,\n",
       "  -0.00503095518797636,\n",
       "  -0.0028245626017451286,\n",
       "  -0.008007682859897614,\n",
       "  -0.008578301407396793,\n",
       "  -0.008844589814543724,\n",
       "  -0.021772274747490883,\n",
       "  -0.007544847670942545,\n",
       "  0.009459590539336205,\n",
       "  -0.022216089069843292,\n",
       "  0.011431395076215267,\n",
       "  -0.02142990380525589,\n",
       "  0.010023868642747402,\n",
       "  0.03943609446287155,\n",
       "  -0.0036044083535671234,\n",
       "  -0.020833924412727356,\n",
       "  0.011209487915039062,\n",
       "  0.01050572469830513,\n",
       "  0.02101144939661026,\n",
       "  -0.028657739982008934,\n",
       "  4.492631705943495e-05,\n",
       "  -0.03126990422606468,\n",
       "  0.012059075757861137,\n",
       "  0.009668816812336445,\n",
       "  0.00647969264537096,\n",
       "  -0.014861447736620903,\n",
       "  0.014303509145975113,\n",
       "  -0.0015676164766773582,\n",
       "  -0.028023719787597656,\n",
       "  0.02084660343825817,\n",
       "  -0.013999179005622864,\n",
       "  0.004105284810066223,\n",
       "  0.02243165671825409,\n",
       "  0.011723044328391552,\n",
       "  -0.004628351889550686,\n",
       "  0.01247118879109621,\n",
       "  0.015736395493149757,\n",
       "  0.010036549530923367,\n",
       "  0.005541341844946146,\n",
       "  0.006517733912914991,\n",
       "  -0.021696191281080246,\n",
       "  -0.02452392503619194,\n",
       "  0.008508559316396713,\n",
       "  0.00957371387630701,\n",
       "  0.0009771845070645213,\n",
       "  -0.04316413775086403,\n",
       "  0.008838250301778316,\n",
       "  0.007906239479780197,\n",
       "  0.003728042356669903,\n",
       "  -0.002670812653377652,\n",
       "  -0.00719613628461957,\n",
       "  0.005902733653783798,\n",
       "  0.00018287537386640906,\n",
       "  -0.005211650859564543,\n",
       "  0.0284548532217741,\n",
       "  -0.023091036826372147,\n",
       "  0.009161600843071938,\n",
       "  0.02457464672625065,\n",
       "  -0.011716704815626144,\n",
       "  0.0013647298328578472,\n",
       "  4.5273049181560054e-05,\n",
       "  0.011475776322185993,\n",
       "  0.017270727083086967,\n",
       "  -0.0017007607966661453,\n",
       "  0.01933763362467289,\n",
       "  0.011792787350714207,\n",
       "  -0.029215678572654724,\n",
       "  0.017067840322852135,\n",
       "  0.003076585941016674,\n",
       "  -0.010657889768481255,\n",
       "  0.023255882784724236,\n",
       "  0.013720210641622543,\n",
       "  0.025728564709424973,\n",
       "  0.013999179005622864,\n",
       "  -0.019908253103494644,\n",
       "  0.03608846291899681,\n",
       "  -0.010359900072216988,\n",
       "  -0.014823406003415585,\n",
       "  -0.011989333666861057,\n",
       "  0.00020506609871517867,\n",
       "  -0.004542759153991938,\n",
       "  -0.02103681117296219,\n",
       "  -3.672862658277154e-05,\n",
       "  0.0001706902839941904,\n",
       "  0.0082359304651618,\n",
       "  0.02822660654783249,\n",
       "  -0.029824338853359222,\n",
       "  -0.021049490198493004,\n",
       "  0.007062991615384817,\n",
       "  0.010607168078422546,\n",
       "  -0.01842464506626129,\n",
       "  -0.017562376335263252,\n",
       "  -0.009776600636541843,\n",
       "  0.028962070122361183,\n",
       "  0.0017831835430115461,\n",
       "  -0.008381755091249943,\n",
       "  -0.6492372751235962,\n",
       "  -0.023978667333722115,\n",
       "  0.014721962623298168,\n",
       "  -0.028936710208654404,\n",
       "  -0.002507552271708846,\n",
       "  -0.009928765706717968,\n",
       "  0.007113713305443525,\n",
       "  -0.017511654645204544,\n",
       "  -0.016839591786265373,\n",
       "  0.015317942947149277,\n",
       "  0.005550852045416832,\n",
       "  0.035733412951231,\n",
       "  0.004669563379138708,\n",
       "  -0.007037630770355463,\n",
       "  0.0005634860135614872,\n",
       "  -0.023141758516430855,\n",
       "  0.02229217067360878,\n",
       "  -0.02440980076789856,\n",
       "  0.00647969264537096,\n",
       "  -0.004748815670609474,\n",
       "  0.0014511151239275932,\n",
       "  0.01579979807138443,\n",
       "  -0.007918919436633587,\n",
       "  0.0010849680984392762,\n",
       "  -0.0022079774644225836,\n",
       "  -0.03012866899371147,\n",
       "  0.003499794751405716,\n",
       "  -0.01828516088426113,\n",
       "  0.006663558539003134,\n",
       "  0.008800208568572998,\n",
       "  -0.014924849383533001,\n",
       "  -0.0029529519379138947,\n",
       "  0.002364897634834051,\n",
       "  0.025005780160427094,\n",
       "  0.043544549494981766,\n",
       "  -0.013365158811211586,\n",
       "  -0.028885988518595695,\n",
       "  0.03728042170405388,\n",
       "  0.017422892153263092,\n",
       "  0.06071383133530617,\n",
       "  -0.0021271398290991783,\n",
       "  -0.007563868071883917,\n",
       "  0.032030731439590454,\n",
       "  -0.02031402662396431,\n",
       "  -0.026907842606306076,\n",
       "  -0.04689217731356621,\n",
       "  0.013453921303153038,\n",
       "  -0.000792922277469188,\n",
       "  -0.007785775698721409,\n",
       "  -0.0012403031578287482,\n",
       "  0.004580800421535969,\n",
       "  -0.016535261645913124,\n",
       "  -0.0018862119177356362,\n",
       "  0.00415283627808094,\n",
       "  -0.022495057433843613,\n",
       "  -0.016484541818499565,\n",
       "  0.013986499048769474,\n",
       "  2.957112701551523e-05,\n",
       "  0.006650878116488457,\n",
       "  0.048388466238975525,\n",
       "  0.005940774921327829,\n",
       "  0.009782941080629826,\n",
       "  -0.02229217067360878,\n",
       "  -0.021163614466786385,\n",
       "  -0.009916085749864578,\n",
       "  -0.01552082970738411,\n",
       "  -0.02363629639148712,\n",
       "  -0.012350725010037422,\n",
       "  0.0038485063705593348,\n",
       "  -0.019794128835201263,\n",
       "  -0.018665572628378868,\n",
       "  0.0011982993455603719,\n",
       "  -0.037052176892757416,\n",
       "  0.0002004100097110495,\n",
       "  -0.0002397391217527911,\n",
       "  0.03479506075382233,\n",
       "  -0.009465930983424187,\n",
       "  0.014354230836033821,\n",
       "  0.020212583243846893,\n",
       "  -0.0015240275533869863,\n",
       "  0.017321448773145676,\n",
       "  0.013124230317771435,\n",
       "  -0.019413717091083527,\n",
       "  -0.017537014558911324,\n",
       "  0.02115093357861042,\n",
       "  0.0007485407986678183,\n",
       "  -0.008102785795927048,\n",
       "  -0.015381344594061375,\n",
       "  -0.018373923376202583,\n",
       "  -0.002735799876973033,\n",
       "  -0.002185786608606577,\n",
       "  0.008369074203073978,\n",
       "  -0.0034268824383616447,\n",
       "  -0.0485406331717968,\n",
       "  0.0037724238354712725,\n",
       "  0.020833924412727356,\n",
       "  -0.0068410844542086124,\n",
       "  -0.008762167766690254,\n",
       "  0.017828665673732758,\n",
       "  0.004542759153991938,\n",
       "  -0.009662477299571037,\n",
       "  -0.00925036333501339,\n",
       "  -0.011456755921244621,\n",
       "  -0.011406034231185913,\n",
       "  0.030230112373828888,\n",
       "  -0.018538767471909523,\n",
       "  -0.024346398189663887,\n",
       "  0.0038580165710300207,\n",
       "  0.02619773894548416,\n",
       "  -0.021442582830786705,\n",
       "  0.0011737310560420156,\n",
       "  0.0021778615191578865,\n",
       "  0.00020080627291463315,\n",
       "  -0.009015776216983795,\n",
       "  -0.011792787350714207,\n",
       "  -0.01396113820374012,\n",
       "  0.004511057864874601,\n",
       "  -0.00855294056236744,\n",
       "  0.014417633414268494,\n",
       "  -0.025741243734955788,\n",
       "  0.02619773894548416,\n",
       "  -0.012686756439507008,\n",
       "  0.0011079513933509588,\n",
       "  0.007582888938486576,\n",
       "  -0.01719464361667633,\n",
       "  0.005902733653783798,\n",
       "  0.01800619065761566,\n",
       "  0.009706858545541763,\n",
       "  0.006181702949106693,\n",
       "  -0.019489798694849014,\n",
       "  -0.0003176048048771918,\n",
       "  0.01044866256415844,\n",
       "  -0.015951963141560555,\n",
       "  -0.01950247958302498,\n",
       "  -0.030103307217359543,\n",
       "  0.005173609592020512,\n",
       "  -0.015279901213943958,\n",
       "  -0.01621825248003006,\n",
       "  0.015153096988797188,\n",
       "  -0.009288405068218708,\n",
       "  0.008102785795927048,\n",
       "  0.0343385674059391,\n",
       "  0.003136817831546068,\n",
       "  0.03979114443063736,\n",
       "  -0.0003283038968220353,\n",
       "  -0.0226599033921957,\n",
       "  -0.039360012859106064,\n",
       "  0.0018767016008496284,\n",
       "  0.0077413939870893955,\n",
       "  0.008895311504602432,\n",
       "  0.0018497556447982788,\n",
       "  -0.012452168390154839,\n",
       "  -0.005332115106284618,\n",
       "  -0.008717785589396954,\n",
       "  -0.025703202933073044,\n",
       "  -0.011665983125567436,\n",
       "  -0.00118086370639503,\n",
       "  0.010917838662862778,\n",
       "  -0.01984485052525997,\n",
       "  -0.03522619605064392,\n",
       "  -0.01719464361667633,\n",
       "  0.041566405445337296,\n",
       "  -0.01534330379217863,\n",
       "  -0.003816805314272642,\n",
       "  0.004098944365978241,\n",
       "  -0.0106325289234519,\n",
       "  0.004809047561138868,\n",
       "  -0.0011523327557370067,\n",
       "  0.01936299540102482,\n",
       "  -0.030356915667653084,\n",
       "  0.017384851351380348,\n",
       "  0.000473930558655411,\n",
       "  -0.023839181289076805,\n",
       "  0.0011063662823289633,\n",
       "  0.0027468951884657145,\n",
       "  0.003046469995751977,\n",
       "  -0.01668742671608925,\n",
       "  0.013441241346299648,\n",
       "  0.02452392503619194,\n",
       "  0.0068093836307525635,\n",
       "  -0.01898258365690708,\n",
       "  -0.003151083365082741,\n",
       "  -0.013441241346299648,\n",
       "  0.0062799761071801186,\n",
       "  0.026096295565366745,\n",
       "  -0.007918919436633587,\n",
       "  0.031422071158885956,\n",
       "  -0.01120314747095108,\n",
       "  -0.001654794323258102,\n",
       "  0.017143921926617622,\n",
       "  0.006644538138061762,\n",
       "  0.013631447218358517,\n",
       "  0.011932271532714367,\n",
       "  -0.021975161507725716,\n",
       "  0.0003843751037493348,\n",
       "  0.008914332836866379,\n",
       "  -0.005490620154887438,\n",
       "  0.0028546787798404694,\n",
       "  -0.0014947040472179651,\n",
       "  0.013910416513681412,\n",
       "  0.01772722229361534,\n",
       "  -0.01591392233967781,\n",
       "  0.01959124207496643,\n",
       "  -0.027846192941069603,\n",
       "  -0.002602655440568924,\n",
       "  0.0002900645195040852,\n",
       "  0.01508969534188509,\n",
       "  -0.03157423436641693,\n",
       "  0.021493304520845413,\n",
       "  0.012084436602890491,\n",
       "  -0.0005607121274806559,\n",
       "  -0.05300413817167282,\n",
       "  -0.009852683171629906,\n",
       "  -0.01691567525267601,\n",
       "  0.026020213961601257,\n",
       "  0.01933763362467289,\n",
       "  0.017930109053850174,\n",
       "  0.023116398602724075,\n",
       "  0.0011729385005310178,\n",
       "  0.008844589814543724,\n",
       "  -0.0011364823440089822,\n",
       "  0.0018767016008496284,\n",
       "  0.023915264755487442,\n",
       "  -0.012965725734829903,\n",
       "  0.0051038675010204315,\n",
       "  0.004564949776977301,\n",
       "  0.010011188685894012,\n",
       "  -0.02371237799525261,\n",
       "  -0.015951963141560555,\n",
       "  -0.013225673697888851,\n",
       "  -0.0019321783911436796,\n",
       "  -0.00440327450633049,\n",
       "  0.02296423353254795,\n",
       "  0.001223660190589726,\n",
       "  0.012788199819624424,\n",
       "  0.01510237529873848,\n",
       "  -0.0036392793990671635,\n",
       "  -0.012750158086419106,\n",
       "  0.020301345735788345,\n",
       "  0.0039626299403607845,\n",
       "  0.017232686281204224,\n",
       "  0.02156938798725605,\n",
       "  -0.0008931768243201077,\n",
       "  0.012642375193536282,\n",
       "  0.02042815089225769,\n",
       "  0.026096295565366745,\n",
       "  0.05097527429461479,\n",
       "  0.010955879464745522,\n",
       "  0.005062656011432409,\n",
       "  0.03806661069393158,\n",
       "  -0.02000969648361206,\n",
       "  0.010829075239598751,\n",
       "  -0.011716704815626144,\n",
       "  0.017384851351380348,\n",
       "  0.021024130284786224,\n",
       "  0.013808973133563995,\n",
       "  0.012984746135771275,\n",
       "  -0.01006191037595272,\n",
       "  0.022304851561784744,\n",
       "  0.02399134635925293,\n",
       "  -0.0014503225684165955,\n",
       "  0.0057125273160636425,\n",
       "  0.0034427328500896692,\n",
       "  -0.00499608414247632,\n",
       "  0.004235258791595697,\n",
       "  0.0023458770010620356,\n",
       "  0.01288964319974184,\n",
       "  -0.007620930206030607,\n",
       "  -0.016433820128440857,\n",
       "  -0.008686085231602192,\n",
       "  -0.00588688300922513,\n",
       "  -0.0010500969365239143,\n",
       "  -0.0006074711563996971,\n",
       "  -0.030103307217359543,\n",
       "  0.023065676912665367,\n",
       "  -0.010550105944275856,\n",
       "  -0.01233170460909605,\n",
       "  0.007779435254633427,\n",
       "  0.0068093836307525635,\n",
       "  0.005664975848048925,\n",
       "  -0.03043299913406372,\n",
       "  -0.011475776322185993,\n",
       "  0.008350053802132607,\n",
       "  0.01326371543109417,\n",
       "  0.004542759153991938,\n",
       "  -0.023306604474782944,\n",
       "  -0.03431320562958717,\n",
       "  0.0015240275533869863,\n",
       "  0.013187632896006107,\n",
       "  0.008495878428220749,\n",
       "  0.015077014453709126,\n",
       "  0.01705515943467617,\n",
       "  0.026299182325601578,\n",
       "  0.016002684831619263,\n",
       "  0.013035467825829983,\n",
       "  -0.007170775439590216,\n",
       "  0.023141758516430855,\n",
       "  0.002599485218524933,\n",
       "  0.0355558879673481,\n",
       "  0.02850557491183281,\n",
       "  -0.0077287135645747185,\n",
       "  -0.017879387363791466,\n",
       "  -0.01037892047315836,\n",
       "  -0.050341252237558365,\n",
       "  0.0417439304292202,\n",
       "  0.011031961999833584,\n",
       "  0.011925931088626385,\n",
       "  -0.0016064501833170652,\n",
       "  0.014011859893798828,\n",
       "  0.0030337895732373,\n",
       "  -0.014303509145975113,\n",
       "  0.009047476574778557,\n",
       "  -0.007272218819707632,\n",
       "  -0.000346928252838552,\n",
       "  0.009415209293365479,\n",
       "  -0.007031290791928768,\n",
       "  -0.031472790986299515,\n",
       "  0.0018798717064782977,\n",
       "  0.021746912971138954,\n",
       "  0.011044641956686974,\n",
       "  0.002702513709664345,\n",
       "  -0.008755827322602272,\n",
       "  0.009288405068218708,\n",
       "  0.008159847930073738,\n",
       "  0.0541200153529644,\n",
       "  0.005652295425534248,\n",
       "  -0.009890724904835224,\n",
       "  0.030914854258298874,\n",
       "  -0.0009668817510828376,\n",
       "  -0.029697533696889877,\n",
       "  -0.023509491235017776,\n",
       "  -0.02624846063554287,\n",
       "  0.014734643511474133,\n",
       "  0.006048558279871941,\n",
       "  0.02708536945283413,\n",
       "  0.008140827529132366,\n",
       "  0.009326445870101452,\n",
       "  0.006004177033901215,\n",
       "  0.009155260398983955,\n",
       "  -8.648439688840881e-05,\n",
       "  0.01610412821173668,\n",
       "  -0.03012866899371147,\n",
       "  -0.013796292245388031,\n",
       "  -0.010264797136187553,\n",
       "  0.0038453361485153437,\n",
       "  -0.015165777876973152,\n",
       "  -0.006362398620694876,\n",
       "  0.000801640038844198,\n",
       "  0.044660426676273346,\n",
       "  0.01978144980967045,\n",
       "  0.004235258791595697,\n",
       "  0.0236616563051939,\n",
       "  0.01677619107067585,\n",
       "  -0.014899488538503647,\n",
       "  0.014240107499063015,\n",
       "  0.0034110320266336203,\n",
       "  0.000620547856669873,\n",
       "  0.00848319847136736,\n",
       "  0.02115093357861042,\n",
       "  0.02089732512831688,\n",
       "  0.025906089693307877,\n",
       "  0.02878454513847828,\n",
       "  -0.008743146434426308,\n",
       "  0.010150672867894173,\n",
       "  0.0015660313656553626,\n",
       "  -0.003477604128420353,\n",
       "  0.013441241346299648,\n",
       "  0.01467124093323946,\n",
       "  0.015558870509266853,\n",
       "  -0.008115466684103012,\n",
       "  -0.0006153964204713702,\n",
       "  -0.016535261645913124,\n",
       "  -0.010987580753862858,\n",
       "  -0.005592063535004854,\n",
       "  0.020922686904668808,\n",
       "  0.0284548532217741,\n",
       "  -0.00039368728175759315,\n",
       "  -0.007215156685560942,\n",
       "  0.0068664452992379665,\n",
       "  0.0005543719162233174,\n",
       "  0.010727631859481335,\n",
       "  -0.007234177552163601,\n",
       "  -0.002791276667267084,\n",
       "  -0.007234177552163601,\n",
       "  -0.009421548806130886,\n",
       "  -0.013251034542918205,\n",
       "  0.035987019538879395,\n",
       "  0.0030052585061639547,\n",
       "  -0.01780330389738083,\n",
       "  -0.0329437218606472,\n",
       "  -0.00461884168908,\n",
       "  0.004406444728374481,\n",
       "  -0.013238354586064816,\n",
       "  0.016763510182499886,\n",
       "  -0.014316190034151077,\n",
       "  0.0037153619341552258,\n",
       "  0.007291239220649004,\n",
       "  -0.0029117404483258724,\n",
       "  -0.011824487708508968,\n",
       "  0.006127811037003994,\n",
       "  0.028074441477656364,\n",
       "  -0.005696677137166262,\n",
       "  -0.008153507485985756,\n",
       "  -0.006745981518179178,\n",
       "  -0.0032556967344135046,\n",
       "  -0.029748255386948586,\n",
       "  0.013885055668652058,\n",
       "  -0.018716294318437576,\n",
       "  -0.015926603227853775,\n",
       "  0.03700145334005356,\n",
       "  0.016446499153971672,\n",
       "  -0.003905568039044738,\n",
       "  -0.010245775803923607,\n",
       "  0.03236042335629463,\n",
       "  0.025145264342427254,\n",
       "  0.007690672297030687,\n",
       "  0.009757580235600471,\n",
       "  -0.020631037652492523,\n",
       "  -0.004428635351359844,\n",
       "  0.06751053780317307,\n",
       "  -0.007360981311649084,\n",
       "  0.014290829189121723,\n",
       "  0.008331033401191235,\n",
       "  -0.001680155168287456,\n",
       "  -0.03279155492782593,\n",
       "  -0.025576399639248848,\n",
       "  0.0062451050616800785,\n",
       "  -0.04149032011628151,\n",
       "  -0.02196248061954975,\n",
       "  0.0032778875902295113,\n",
       "  -0.02201320230960846,\n",
       "  0.025627121329307556,\n",
       "  -0.023737739771604538,\n",
       "  0.0042606196366250515,\n",
       "  0.019908253103494644,\n",
       "  -0.039081040769815445,\n",
       "  -0.024397119879722595,\n",
       "  0.010455003008246422,\n",
       "  -0.003464923705905676,\n",
       "  0.014772684313356876,\n",
       "  0.0036044083535671234,\n",
       "  0.022482378408312798,\n",
       "  -0.016345055773854256,\n",
       "  0.01369484979659319,\n",
       "  -0.008115466684103012,\n",
       "  -0.0431387759745121,\n",
       "  0.03479506075382233,\n",
       "  0.0290635135024786,\n",
       "  -0.02182299643754959,\n",
       "  0.0024156193248927593,\n",
       "  0.01050572469830513,\n",
       "  -0.033400215208530426,\n",
       "  0.0009748069569468498,\n",
       "  -0.02321784198284149,\n",
       "  0.011348972097039223,\n",
       "  0.046689290553331375,\n",
       "  -0.017980830743908882,\n",
       "  -0.023357326164841652,\n",
       "  -0.017131242901086807,\n",
       "  -0.014823406003415585,\n",
       "  -0.0062672956846654415,\n",
       "  0.0014875712804496288,\n",
       "  -0.024980420246720314,\n",
       "  -0.0030750008299946785,\n",
       "  -0.019958974793553352,\n",
       "  0.0194771196693182,\n",
       "  0.009605415165424347,\n",
       "  -0.009656136855483055,\n",
       "  0.0012759668752551079,\n",
       "  -0.022051243111491203,\n",
       "  -0.014202065765857697,\n",
       "  0.015140417031943798,\n",
       "  -0.006295826751738787,\n",
       "  0.015622272156178951,\n",
       "  -0.022330213338136673,\n",
       "  0.008172527886927128,\n",
       "  -0.02082124352455139,\n",
       "  -0.008984074927866459,\n",
       "  -0.001482023624703288,\n",
       "  -0.0039721401408314705,\n",
       "  0.022203408181667328,\n",
       "  -0.02064371667802334,\n",
       "  0.04138887673616409,\n",
       "  0.02931712195277214,\n",
       "  0.011792787350714207,\n",
       "  0.02017454244196415,\n",
       "  -0.004051392897963524,\n",
       "  -0.021531347185373306,\n",
       "  0.002892719814553857,\n",
       "  -0.004542759153991938,\n",
       "  -0.020415470004081726,\n",
       "  -0.008952373638749123,\n",
       "  0.00018049779464490712,\n",
       "  0.017537014558911324,\n",
       "  0.012490210123360157,\n",
       "  0.007963301613926888,\n",
       "  0.006796703208237886,\n",
       "  0.014113303273916245,\n",
       "  0.02471413090825081,\n",
       "  -0.0019385186024010181,\n",
       "  -0.0065430947579443455,\n",
       "  -0.023344645276665688,\n",
       "  0.008343713358044624,\n",
       "  -0.030661245808005333,\n",
       "  -0.018348561599850655,\n",
       "  -0.027161451056599617,\n",
       "  0.002198467031121254,\n",
       "  0.019299592822790146,\n",
       "  -0.025398872792720795,\n",
       "  0.005249692127108574,\n",
       "  0.011532838456332684,\n",
       "  -0.0034966247621923685,\n",
       "  0.003750232979655266,\n",
       "  -0.004977063275873661,\n",
       "  0.02457464672625065,\n",
       "  0.015951963141560555,\n",
       "  0.021188974380493164,\n",
       "  -0.008007682859897614,\n",
       "  0.02159474790096283,\n",
       "  -0.004289150703698397,\n",
       "  -0.014582478441298008,\n",
       "  -0.04308805242180824,\n",
       "  0.00887629110366106,\n",
       "  -0.007189795840531588,\n",
       "  -0.0004469846608117223,\n",
       "  -0.010727631859481335,\n",
       "  -0.029266400262713432,\n",
       "  0.01791742816567421,\n",
       "  -0.030077947303652763,\n",
       "  0.025436915457248688,\n",
       "  0.004235258791595697,\n",
       "  -0.01959124207496643,\n",
       "  0.006581136025488377,\n",
       "  -0.004764666315168142,\n",
       "  -0.013327117078006268,\n",
       "  -0.03299444168806076,\n",
       "  0.004463506396859884,\n",
       "  0.011228508315980434,\n",
       "  0.013111550360918045,\n",
       "  0.0014281318290159106,\n",
       "  0.011532838456332684,\n",
       "  0.01730876788496971,\n",
       "  -0.013174952007830143,\n",
       "  -0.01836124248802662,\n",
       "  0.008254950866103172,\n",
       "  -0.026425987482070923,\n",
       "  0.035682689398527145,\n",
       "  0.007868197746574879,\n",
       "  0.01621825248003006,\n",
       "  0.01652258262038231,\n",
       "  0.019413717091083527,\n",
       "  -0.013783612288534641,\n",
       "  -0.022266810759902,\n",
       "  -0.00036178811569698155,\n",
       "  0.006080259568989277,\n",
       "  0.015863200649619102,\n",
       "  0.016408458352088928,\n",
       "  -0.01605340652167797,\n",
       "  -0.013377838768064976,\n",
       "  -0.009427889250218868,\n",
       "  -0.01822175830602646,\n",
       "  0.0060010068118572235,\n",
       "  -0.023167120292782784,\n",
       "  0.018145674839615822,\n",
       "  0.004932682029902935,\n",
       "  -0.02764330618083477,\n",
       "  -0.015394025482237339,\n",
       "  -0.0011816562619060278,\n",
       "  0.0007592398906126618,\n",
       "  0.00019862683257088065,\n",
       "  0.012445827946066856,\n",
       "  0.00705031119287014,\n",
       "  0.009630776010453701,\n",
       "  -0.005341625306755304,\n",
       "  -0.019768768921494484,\n",
       "  0.02731361612677574,\n",
       "  -0.03185320645570755,\n",
       "  0.03449073061347008,\n",
       "  0.013377838768064976,\n",
       "  0.0068981461226940155,\n",
       "  -0.012604333460330963,\n",
       "  -0.0074180434457957745,\n",
       "  0.0024378099478781223,\n",
       "  0.016902994364500046,\n",
       "  0.04925073683261871,\n",
       "  0.04608063027262688,\n",
       "  -0.017143921926617622,\n",
       "  0.009155260398983955,\n",
       "  0.0076843323186039925,\n",
       "  0.019134748727083206,\n",
       "  -0.00518946023657918,\n",
       "  -0.02936784364283085,\n",
       "  0.0329437218606472,\n",
       "  0.025449594482779503,\n",
       "  -0.0007778642466291785,\n",
       "  -0.0077096931636333466,\n",
       "  -0.0037946144584566355,\n",
       "  0.00855294056236744,\n",
       "  -0.009687838144600391,\n",
       "  0.025373512879014015,\n",
       "  0.005290903616696596,\n",
       "  -0.015000931918621063,\n",
       "  -0.007747734431177378,\n",
       "  -0.030255472287535667,\n",
       "  0.002431469736620784,\n",
       "  -0.006343378219753504,\n",
       "  -0.008153507485985756,\n",
       "  -0.01605340652167797,\n",
       "  0.00812180619686842,\n",
       "  -0.004162346478551626,\n",
       "  0.0008123391307890415,\n",
       "  -0.005535001400858164,\n",
       "  0.014493715949356556,\n",
       "  -0.00837541464716196,\n",
       "  -0.027567224577069283,\n",
       "  -0.009282064624130726,\n",
       "  -0.009757580235600471,\n",
       "  -0.011475776322185993,\n",
       "  0.00925036333501339,\n",
       "  0.0003088870143983513,\n",
       "  -0.012807220220565796,\n",
       "  -0.011811807751655579,\n",
       "  -0.022140005603432655,\n",
       "  0.025931451469659805,\n",
       "  0.021975161507725716,\n",
       "  0.03502330929040909,\n",
       "  0.016509901732206345,\n",
       "  0.010169693268835545,\n",
       "  0.006993249524384737,\n",
       "  -0.03613918647170067,\n",
       "  0.007792115677148104,\n",
       "  -0.003718531923368573,\n",
       "  -0.009884384460747242,\n",
       "  -0.015077014453709126,\n",
       "  0.01791742816567421,\n",
       "  -0.009890724904835224,\n",
       "  -0.007576548494398594,\n",
       "  -0.02619773894548416,\n",
       "  0.006016857456415892,\n",
       "  0.009066497907042503,\n",
       "  0.015279901213943958,\n",
       "  0.004089434165507555,\n",
       "  -0.00911087915301323,\n",
       "  0.0008376999758183956,\n",
       "  -0.03520083427429199,\n",
       "  0.014417633414268494,\n",
       "  0.00732294050976634,\n",
       "  -0.020073099061846733,\n",
       "  -0.015013612806797028,\n",
       "  0.014950210228562355,\n",
       "  0.0009613340371288359,\n",
       "  0.015038973651826382,\n",
       "  -0.020377429202198982,\n",
       "  0.0013243108987808228,\n",
       "  0.008102785795927048,\n",
       "  0.00015563229680992663,\n",
       "  -0.02683176100254059,\n",
       "  -0.008045723661780357,\n",
       "  0.011653302237391472,\n",
       "  0.007557528093457222,\n",
       "  -0.006219744216650724,\n",
       "  0.031219184398651123,\n",
       "  -0.04379815608263016,\n",
       "  -0.004235258791595697,\n",
       "  -0.006419460754841566,\n",
       "  0.03220825642347336,\n",
       "  0.004476186819374561,\n",
       "  -0.005766419228166342,\n",
       "  -0.0262738224118948,\n",
       "  0.0009811471682041883,\n",
       "  -0.0014883638359606266,\n",
       "  -0.011963972821831703,\n",
       "  -0.019210830330848694,\n",
       "  -0.0074434042908251286,\n",
       "  -0.010188714601099491,\n",
       "  0.03613918647170067,\n",
       "  0.01183082815259695,\n",
       "  -0.008090105839073658,\n",
       "  -0.005804460495710373,\n",
       "  -0.02850557491183281,\n",
       "  -0.03575877472758293,\n",
       "  -0.008090105839073658,\n",
       "  -0.01043598260730505,\n",
       "  -0.007069332059472799,\n",
       "  -0.015140417031943798,\n",
       "  0.0006320395041257143,\n",
       "  -0.002762745600193739,\n",
       "  0.04258083552122116,\n",
       "  0.005547681823372841,\n",
       "  -0.013580725528299809,\n",
       "  -0.013060828670859337,\n",
       "  -0.02761794626712799,\n",
       "  0.005195800680667162,\n",
       "  0.0009225002722814679,\n",
       "  -0.00705031119287014,\n",
       "  -0.007316600065678358,\n",
       "  -0.043011970818042755,\n",
       "  -0.003262036945670843,\n",
       "  -0.008755827322602272,\n",
       "  0.019718047231435776,\n",
       "  -0.021810315549373627,\n",
       "  0.015470108017325401,\n",
       "  0.019819490611553192,\n",
       "  -0.015203818678855896,\n",
       "  -0.0012228676350787282,\n",
       "  0.005683996714651585,\n",
       "  0.010898817330598831,\n",
       "  0.0020019207149744034,\n",
       "  0.015444747172296047,\n",
       "  -0.014430313371121883,\n",
       "  -0.002737384755164385,\n",
       "  0.008438817225396633,\n",
       "  -0.0068220640532672405,\n",
       "  -0.039081040769815445,\n",
       "  -0.020212583243846893,\n",
       "  -0.008242270909249783,\n",
       "  -0.0034807741176337004,\n",
       "  0.009700518101453781,\n",
       "  0.0022904002107679844,\n",
       "  -0.02312907949090004,\n",
       "  0.01214783824980259,\n",
       "  -0.03545444458723068,\n",
       "  0.0068664452992379665,\n",
       "  -0.006739641074091196,\n",
       "  -0.008242270909249783,\n",
       "  0.005607914179563522,\n",
       "  -0.003038544673472643,\n",
       "  -0.0032778875902295113,\n",
       "  -0.019832171499729156,\n",
       "  0.0014423973625525832,\n",
       "  -0.028607018291950226,\n",
       "  -0.010188714601099491,\n",
       "  -0.0028974751476198435,\n",
       "  -0.046968262642621994,\n",
       "  -0.019071346148848534,\n",
       "  0.00805206410586834,\n",
       "  -0.0012418882688507438,\n",
       "  -0.006454331800341606,\n",
       "  -0.020516913384199142,\n",
       "  -0.01050572469830513,\n",
       "  0.0010873456485569477,\n",
       "  -0.013174952007830143,\n",
       "  0.009022115729749203,\n",
       "  0.009890724904835224,\n",
       "  0.01672546938061714,\n",
       "  0.0042162383906543255,\n",
       "  0.006999589502811432,\n",
       "  -0.009275724180042744,\n",
       "  0.009789281524717808,\n",
       "  -0.032614029943943024,\n",
       "  0.004755156114697456,\n",
       "  -0.024042068049311638,\n",
       "  0.010550105944275856,\n",
       "  -0.023065676912665367,\n",
       "  -0.004390594083815813,\n",
       "  0.0004996876232326031,\n",
       "  -0.016205571591854095,\n",
       "  0.0155335096642375,\n",
       "  0.022672584280371666,\n",
       "  0.005718867760151625,\n",
       "  0.2134367674589157,\n",
       "  -0.010391601361334324,\n",
       "  -0.00016771831724327058,\n",
       "  0.03994331136345863,\n",
       "  0.0006340207764878869,\n",
       "  -0.009687838144600391,\n",
       "  0.030001863837242126,\n",
       "  -0.009174280799925327,\n",
       "  0.025322791188955307,\n",
       "  -0.0031526684761047363,\n",
       "  -0.008787528611719608,\n",
       "  0.0035568566527217627,\n",
       "  -0.017765263095498085,\n",
       "  -0.011412374675273895,\n",
       "  0.017435571178793907,\n",
       "  0.0008194718975573778,\n",
       "  -0.0017055160133168101,\n",
       "  -0.013251034542918205,\n",
       "  -0.03722970187664032,\n",
       "  0.01752433553338051,\n",
       "  0.02733897790312767,\n",
       "  -0.004717114847153425,\n",
       "  -0.0025661992840468884,\n",
       "  -0.019413717091083527,\n",
       "  0.017714541405439377,\n",
       "  0.005997836589813232,\n",
       "  -0.005836161319166422,\n",
       "  0.02189907804131508,\n",
       "  0.016535261645913124,\n",
       "  0.0135300038382411,\n",
       "  -0.022025883197784424,\n",
       "  0.04083094000816345,\n",
       "  0.001770503120496869,\n",
       "  0.027541862800717354,\n",
       "  0.005157759413123131,\n",
       "  -0.00957371387630701,\n",
       "  0.010163353756070137,\n",
       "  -0.024029389023780823,\n",
       "  0.008616343140602112,\n",
       "  0.009205982089042664,\n",
       "  0.03180248290300369,\n",
       "  0.013466602191329002,\n",
       "  -0.0034712639171630144,\n",
       "  -0.011285570450127125,\n",
       "  -0.013111550360918045,\n",
       "  0.011906910687685013,\n",
       "  ...],\n",
       " 'response': 'Ingesting the following content: To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder.\\nThank you, I have learned this content (265 tokens).',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tokens used in iteration 1: 345 training tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 2  Arduino Microcontroller Information\n",
      "  Dataset: user_custom_34125_1-jupynotebk-asksage-ex-52_content\n",
      "  Context: Arduino Microcontroller Information\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedding': [-0.007011552806943655,\n",
       "  -0.017461027950048447,\n",
       "  -0.02612045779824257,\n",
       "  -0.013544898480176926,\n",
       "  -0.01335103064775467,\n",
       "  0.005395987536758184,\n",
       "  -0.015910085290670395,\n",
       "  -0.02100234664976597,\n",
       "  -0.013919709250330925,\n",
       "  -0.023832816630601883,\n",
       "  0.011418814770877361,\n",
       "  0.013363954611122608,\n",
       "  -0.03419828414916992,\n",
       "  -0.020782630890607834,\n",
       "  -0.033965643495321274,\n",
       "  -0.008084287866950035,\n",
       "  0.018559612333774567,\n",
       "  -0.001958064967766404,\n",
       "  0.013699992559850216,\n",
       "  -0.009977729991078377,\n",
       "  -0.03202696517109871,\n",
       "  0.02420762926340103,\n",
       "  -0.0025396684650331736,\n",
       "  0.00763839203864336,\n",
       "  -0.019490178674459457,\n",
       "  0.02018810249865055,\n",
       "  0.015393104404211044,\n",
       "  -0.02564224973320961,\n",
       "  4.563971742754802e-05,\n",
       "  -0.009589995257556438,\n",
       "  0.010119900107383728,\n",
       "  -0.0013958483468741179,\n",
       "  -0.0054703038185834885,\n",
       "  -0.011741927824914455,\n",
       "  -0.037817150354385376,\n",
       "  0.026353098452091217,\n",
       "  0.0025428994558751583,\n",
       "  -0.00509872380644083,\n",
       "  -0.00727004325017333,\n",
       "  0.006284548435360193,\n",
       "  0.035852622240781784,\n",
       "  -0.0018336664652451873,\n",
       "  0.006675515323877335,\n",
       "  0.000727812119293958,\n",
       "  -0.01019744761288166,\n",
       "  0.006804760545492172,\n",
       "  0.014682256616652012,\n",
       "  -0.021066969260573387,\n",
       "  -0.00968046672642231,\n",
       "  0.023005647584795952,\n",
       "  0.01184532418847084,\n",
       "  0.009706315584480762,\n",
       "  -0.01822357438504696,\n",
       "  -0.0113606546074152,\n",
       "  -0.0013457657769322395,\n",
       "  -0.008982541970908642,\n",
       "  -0.014359143562614918,\n",
       "  0.0017916617216542363,\n",
       "  0.032595641911029816,\n",
       "  -0.01668555662035942,\n",
       "  -0.013570747338235378,\n",
       "  0.0207050833851099,\n",
       "  -0.020369045436382294,\n",
       "  0.032492246478796005,\n",
       "  -0.014992444775998592,\n",
       "  0.016039330512285233,\n",
       "  0.009926032274961472,\n",
       "  0.018934423103928566,\n",
       "  0.005299053620547056,\n",
       "  0.0018272042507305741,\n",
       "  0.03432752937078476,\n",
       "  0.006232850253582001,\n",
       "  0.024569515138864517,\n",
       "  0.03696412965655327,\n",
       "  0.020201027393341064,\n",
       "  -0.0052247378043830395,\n",
       "  -0.025215741246938705,\n",
       "  -0.00021668768022209406,\n",
       "  0.018585462123155594,\n",
       "  -0.010132825002074242,\n",
       "  -0.025422533974051476,\n",
       "  -0.030398475006222725,\n",
       "  0.00999065488576889,\n",
       "  -0.015354331582784653,\n",
       "  -0.01093414518982172,\n",
       "  -0.004995327442884445,\n",
       "  -0.0028320858255028725,\n",
       "  0.02131253480911255,\n",
       "  -0.0008998697740025818,\n",
       "  -0.014501312747597694,\n",
       "  -0.0255388543009758,\n",
       "  0.01198103092610836,\n",
       "  0.004148771520704031,\n",
       "  -0.0032489015720784664,\n",
       "  0.014798576943576336,\n",
       "  0.02804621122777462,\n",
       "  -0.0028369324281811714,\n",
       "  0.04060884565114975,\n",
       "  -0.007334665860980749,\n",
       "  0.008026127703487873,\n",
       "  -0.0006526883225888014,\n",
       "  -0.003127734176814556,\n",
       "  -0.019619423896074295,\n",
       "  -0.010326692834496498,\n",
       "  -0.016401218250393867,\n",
       "  0.011134475469589233,\n",
       "  0.014527161605656147,\n",
       "  -0.02049829065799713,\n",
       "  0.03241470083594322,\n",
       "  -0.00787749607115984,\n",
       "  -0.0038256582338362932,\n",
       "  0.05025053769350052,\n",
       "  0.008853296749293804,\n",
       "  -0.04071224108338356,\n",
       "  0.009589995257556438,\n",
       "  -0.0028126989491283894,\n",
       "  -9.350083564640954e-05,\n",
       "  -0.015470651909708977,\n",
       "  0.007295892108231783,\n",
       "  0.020123479887843132,\n",
       "  0.03799809142947197,\n",
       "  0.03414658457040787,\n",
       "  -0.001974220620468259,\n",
       "  -0.008724051527678967,\n",
       "  0.0018578999442979693,\n",
       "  0.02317366749048233,\n",
       "  -0.011063390411436558,\n",
       "  0.0023231827653944492,\n",
       "  0.005266742315143347,\n",
       "  -0.0011405890109017491,\n",
       "  -0.008904995396733284,\n",
       "  -0.025461306795477867,\n",
       "  0.0086141936480999,\n",
       "  0.02447904273867607,\n",
       "  -0.0012124816421419382,\n",
       "  0.02509942092001438,\n",
       "  -0.01474687922745943,\n",
       "  0.03515469655394554,\n",
       "  -0.023225365206599236,\n",
       "  -0.026042910292744637,\n",
       "  0.023974986746907234,\n",
       "  -0.01575499214231968,\n",
       "  -0.0319235660135746,\n",
       "  -0.02269545942544937,\n",
       "  -0.007153722457587719,\n",
       "  0.006940467748790979,\n",
       "  0.012019804678857327,\n",
       "  0.017965083941817284,\n",
       "  0.0022052463609725237,\n",
       "  0.02649526856839657,\n",
       "  0.024970175698399544,\n",
       "  0.007276505697518587,\n",
       "  0.007347590290009975,\n",
       "  -0.016401218250393867,\n",
       "  0.016452915966510773,\n",
       "  -0.00562216667458415,\n",
       "  -0.005295822396874428,\n",
       "  0.011405889876186848,\n",
       "  0.005279666744172573,\n",
       "  0.022062158212065697,\n",
       "  0.021894138306379318,\n",
       "  0.02234649658203125,\n",
       "  -0.014901973307132721,\n",
       "  -5.5888456699904054e-05,\n",
       "  0.00622961949557066,\n",
       "  0.01921876333653927,\n",
       "  0.016194425523281097,\n",
       "  -0.0005274820141494274,\n",
       "  0.007515609264373779,\n",
       "  0.0009119865135289729,\n",
       "  -0.0014402763918042183,\n",
       "  0.02014932781457901,\n",
       "  -0.02887338027358055,\n",
       "  0.007463911082595587,\n",
       "  0.005463841371238232,\n",
       "  0.02228187397122383,\n",
       "  -6.093709816923365e-05,\n",
       "  0.026081683114171028,\n",
       "  -0.005505845881998539,\n",
       "  0.0031616610940545797,\n",
       "  0.0011147399200126529,\n",
       "  -0.018107254058122635,\n",
       "  0.01960649900138378,\n",
       "  0.018869800493121147,\n",
       "  0.004391106311231852,\n",
       "  -0.0200459323823452,\n",
       "  0.008504334837198257,\n",
       "  0.0036414838396012783,\n",
       "  0.010578720830380917,\n",
       "  -0.0027480763383209705,\n",
       "  -0.0009111787658184767,\n",
       "  0.016776029020547867,\n",
       "  -0.005202119704335928,\n",
       "  0.009577070362865925,\n",
       "  -0.6447784900665283,\n",
       "  -0.0038870498538017273,\n",
       "  0.007896882481873035,\n",
       "  -0.03799809142947197,\n",
       "  -0.019516026601195335,\n",
       "  -0.0006955008138902485,\n",
       "  0.017590273171663284,\n",
       "  0.00403245072811842,\n",
       "  0.003048571525141597,\n",
       "  -0.0028450102545320988,\n",
       "  0.0005686789518222213,\n",
       "  -0.01273711584508419,\n",
       "  0.016052255406975746,\n",
       "  -0.019541876390576363,\n",
       "  -0.019335083663463593,\n",
       "  -0.023315835744142532,\n",
       "  0.009176409803330898,\n",
       "  -0.03693828359246254,\n",
       "  -0.011438201181590557,\n",
       "  -0.013622445054352283,\n",
       "  -0.012943907640874386,\n",
       "  0.007909807376563549,\n",
       "  0.010203909128904343,\n",
       "  -0.03127733990550041,\n",
       "  -0.014320369809865952,\n",
       "  0.008904995396733284,\n",
       "  -0.002775541041046381,\n",
       "  -0.005134265869855881,\n",
       "  -0.012019804678857327,\n",
       "  0.030501870438456535,\n",
       "  0.009085938334465027,\n",
       "  -0.0172283872961998,\n",
       "  0.009415513835847378,\n",
       "  0.01575499214231968,\n",
       "  0.036783188581466675,\n",
       "  -0.006895232014358044,\n",
       "  -0.014578860253095627,\n",
       "  0.021131591871380806,\n",
       "  -0.0063524022698402405,\n",
       "  0.035619981586933136,\n",
       "  -0.0016624165000393987,\n",
       "  -0.02560347691178322,\n",
       "  0.04047960042953491,\n",
       "  -0.019916687160730362,\n",
       "  -0.011890559457242489,\n",
       "  -0.018107254058122635,\n",
       "  0.011231409385800362,\n",
       "  -0.025176966562867165,\n",
       "  -0.005576930940151215,\n",
       "  -0.022876402363181114,\n",
       "  -0.006407331209629774,\n",
       "  -0.018339896574616432,\n",
       "  0.010804899968206882,\n",
       "  -0.007573769427835941,\n",
       "  -0.001927369274199009,\n",
       "  -0.004135846626013517,\n",
       "  0.04027280956506729,\n",
       "  0.011237870901823044,\n",
       "  -0.010391315445303917,\n",
       "  -0.012439851649105549,\n",
       "  -0.008368627168238163,\n",
       "  -0.008058439008891582,\n",
       "  -0.02856319211423397,\n",
       "  -0.008730513975024223,\n",
       "  0.012653105892241001,\n",
       "  0.011076314374804497,\n",
       "  -0.016427066177129745,\n",
       "  -0.013880935497581959,\n",
       "  0.010035891085863113,\n",
       "  -0.016194425523281097,\n",
       "  0.011283107101917267,\n",
       "  0.01768074557185173,\n",
       "  -0.025151118636131287,\n",
       "  -0.015974707901477814,\n",
       "  0.004077686462551355,\n",
       "  0.032285455614328384,\n",
       "  0.028614889830350876,\n",
       "  -0.00310188508592546,\n",
       "  -0.018236499279737473,\n",
       "  0.01145112607628107,\n",
       "  0.013092540204524994,\n",
       "  -0.0031762011349201202,\n",
       "  -0.007470373529940844,\n",
       "  -0.016155650839209557,\n",
       "  0.03393979370594025,\n",
       "  0.007909807376563549,\n",
       "  0.0002776752517092973,\n",
       "  -0.0023377228062599897,\n",
       "  0.017073292285203934,\n",
       "  0.006533345673233271,\n",
       "  0.01743518002331257,\n",
       "  0.012155512347817421,\n",
       "  -0.019696969538927078,\n",
       "  -0.02982979454100132,\n",
       "  -0.004171389155089855,\n",
       "  0.007108486723154783,\n",
       "  -0.012129663489758968,\n",
       "  -0.0017076523508876562,\n",
       "  0.010578720830380917,\n",
       "  0.014708105474710464,\n",
       "  -0.016672631725668907,\n",
       "  -0.0049791717901825905,\n",
       "  0.013880935497581959,\n",
       "  0.012627257034182549,\n",
       "  0.030812058597803116,\n",
       "  -0.0067142886109650135,\n",
       "  -0.004720681346952915,\n",
       "  0.026624513790011406,\n",
       "  0.033991489559412,\n",
       "  -0.03055356815457344,\n",
       "  -0.02406545914709568,\n",
       "  -0.010791975073516369,\n",
       "  -0.005189195275306702,\n",
       "  0.029442058876156807,\n",
       "  0.0006736906943842769,\n",
       "  -0.011761314235627651,\n",
       "  -0.01060456968843937,\n",
       "  -0.015987632796168327,\n",
       "  0.030217530205845833,\n",
       "  -0.01610395312309265,\n",
       "  0.01768074557185173,\n",
       "  -0.007341128308326006,\n",
       "  -0.00626516155898571,\n",
       "  -0.019684046506881714,\n",
       "  -0.004145540297031403,\n",
       "  -0.021234989166259766,\n",
       "  -0.002751307561993599,\n",
       "  -0.006559194531291723,\n",
       "  -0.017254235222935677,\n",
       "  -0.011897021904587746,\n",
       "  0.012536785565316677,\n",
       "  0.011606220155954361,\n",
       "  -0.018701782450079918,\n",
       "  0.012090889737010002,\n",
       "  -0.008329854346811771,\n",
       "  0.024737533181905746,\n",
       "  0.01565159484744072,\n",
       "  -0.005677096080034971,\n",
       "  0.018701782450079918,\n",
       "  -0.004614054225385189,\n",
       "  -0.005328133702278137,\n",
       "  -0.0036188659723848104,\n",
       "  0.01764197088778019,\n",
       "  0.009344428777694702,\n",
       "  -0.004148771520704031,\n",
       "  -0.028950927779078484,\n",
       "  0.0031245029531419277,\n",
       "  -0.027451682835817337,\n",
       "  0.016840651631355286,\n",
       "  0.018275273963809013,\n",
       "  -0.011722540482878685,\n",
       "  -0.03422413393855095,\n",
       "  0.004662521183490753,\n",
       "  0.033319417387247086,\n",
       "  -0.010578720830380917,\n",
       "  -0.005021176300942898,\n",
       "  -0.016181500628590584,\n",
       "  -0.006746599916368723,\n",
       "  0.006623817142099142,\n",
       "  0.00037016638088971376,\n",
       "  -0.021635647863149643,\n",
       "  0.021713195368647575,\n",
       "  0.003043724689632654,\n",
       "  -0.012304143980145454,\n",
       "  -0.01675017923116684,\n",
       "  -0.0007722401642240584,\n",
       "  -0.015418954193592072,\n",
       "  0.025758570060133934,\n",
       "  -0.030295077711343765,\n",
       "  -0.03926469385623932,\n",
       "  0.017603198066353798,\n",
       "  0.027503380551934242,\n",
       "  -0.004210162907838821,\n",
       "  0.02584904246032238,\n",
       "  -0.013635369949042797,\n",
       "  0.02889923006296158,\n",
       "  -0.02427225187420845,\n",
       "  -0.005531695205718279,\n",
       "  0.012103814631700516,\n",
       "  -0.02773602306842804,\n",
       "  -0.013338105753064156,\n",
       "  -0.00039399595698341727,\n",
       "  -0.0127694271504879,\n",
       "  -0.010016503743827343,\n",
       "  0.0008029358577914536,\n",
       "  0.015638669952750206,\n",
       "  0.017086217179894447,\n",
       "  0.03523224592208862,\n",
       "  0.0028627815190702677,\n",
       "  0.01977451704442501,\n",
       "  0.00876928772777319,\n",
       "  0.019244613125920296,\n",
       "  0.005299053620547056,\n",
       "  -0.00011107010504929349,\n",
       "  -0.01637536846101284,\n",
       "  0.00947367399930954,\n",
       "  0.023936213925480843,\n",
       "  0.005874195136129856,\n",
       "  -0.004171389155089855,\n",
       "  0.02887338027358055,\n",
       "  0.002571979770436883,\n",
       "  0.008510797284543514,\n",
       "  -0.000617549754679203,\n",
       "  -0.003013028996065259,\n",
       "  -0.007735325954854488,\n",
       "  -0.028925077989697456,\n",
       "  0.008672353811562061,\n",
       "  -0.014940747059881687,\n",
       "  0.0306569654494524,\n",
       "  0.022876402363181114,\n",
       "  0.023302912712097168,\n",
       "  -0.013596596196293831,\n",
       "  -0.006946930196136236,\n",
       "  -0.03536149114370346,\n",
       "  0.012698342092335224,\n",
       "  0.02742583490908146,\n",
       "  0.003993676975369453,\n",
       "  0.026831306517124176,\n",
       "  -0.020407818257808685,\n",
       "  0.0017383481608703732,\n",
       "  0.006310397293418646,\n",
       "  0.007916268892586231,\n",
       "  0.01689234934747219,\n",
       "  -0.019722819328308105,\n",
       "  0.01438499242067337,\n",
       "  0.028175456449389458,\n",
       "  0.005305516067892313,\n",
       "  -0.001953218365088105,\n",
       "  -0.02008470520377159,\n",
       "  -0.02794281579554081,\n",
       "  0.02581026963889599,\n",
       "  -0.007534996140748262,\n",
       "  -0.005324902944266796,\n",
       "  0.01146405003964901,\n",
       "  -0.0012876053806394339,\n",
       "  0.010190985165536404,\n",
       "  -0.008400938473641872,\n",
       "  -0.013777540065348148,\n",
       "  0.030398475006222725,\n",
       "  0.007871033623814583,\n",
       "  -0.015535274520516396,\n",
       "  0.025836117565631866,\n",
       "  0.021997535601258278,\n",
       "  -0.006400869227945805,\n",
       "  -0.0015662903897464275,\n",
       "  0.006778911221772432,\n",
       "  0.03362960368394852,\n",
       "  -0.005612473469227552,\n",
       "  -0.016711406409740448,\n",
       "  0.022062158212065697,\n",
       "  -0.015173387713730335,\n",
       "  -0.0032489015720784664,\n",
       "  -0.05141374468803406,\n",
       "  0.0023474162444472313,\n",
       "  -0.016711406409740448,\n",
       "  -0.006255468353629112,\n",
       "  0.012905134819447994,\n",
       "  -0.005118110217154026,\n",
       "  0.0414101667702198,\n",
       "  0.02708979696035385,\n",
       "  0.005738487467169762,\n",
       "  0.008026127703487873,\n",
       "  -0.008271693252027035,\n",
       "  0.013150700367987156,\n",
       "  -0.02856319211423397,\n",
       "  0.0037384177558124065,\n",
       "  0.02574564702808857,\n",
       "  -0.036679793149232864,\n",
       "  -0.006303935311734676,\n",
       "  -0.016013482585549355,\n",
       "  0.010733814910054207,\n",
       "  -0.005984053481370211,\n",
       "  -0.0013691914500668645,\n",
       "  -0.0030631115660071373,\n",
       "  0.005738487467169762,\n",
       "  -0.0012666031252592802,\n",
       "  -0.019412631168961525,\n",
       "  0.01254971046000719,\n",
       "  0.01689234934747219,\n",
       "  0.022501591593027115,\n",
       "  -0.037713754922151566,\n",
       "  -0.016142727807164192,\n",
       "  0.001759350416250527,\n",
       "  0.01631074585020542,\n",
       "  0.017719518393278122,\n",
       "  -0.0025412840768694878,\n",
       "  -0.03086375631392002,\n",
       "  0.0017981240525841713,\n",
       "  0.020033007487654686,\n",
       "  0.007741788402199745,\n",
       "  -0.015160463750362396,\n",
       "  0.020847253501415253,\n",
       "  0.0265728160738945,\n",
       "  0.008336315862834454,\n",
       "  0.009182872250676155,\n",
       "  -0.011392965912818909,\n",
       "  0.02317366749048233,\n",
       "  0.004491270985454321,\n",
       "  0.008090750314295292,\n",
       "  -0.006585043389350176,\n",
       "  -0.0010929298587143421,\n",
       "  -0.01081136241555214,\n",
       "  0.004113228991627693,\n",
       "  -0.03200111538171768,\n",
       "  0.032285455614328384,\n",
       "  0.023535553365945816,\n",
       "  0.01660800911486149,\n",
       "  -0.0037319555412977934,\n",
       "  0.027555080130696297,\n",
       "  -0.013105464167892933,\n",
       "  0.0017528882017359138,\n",
       "  0.005786954425275326,\n",
       "  0.023315835744142532,\n",
       "  -0.024672910571098328,\n",
       "  0.004142309073358774,\n",
       "  0.01569036953151226,\n",
       "  0.015444803051650524,\n",
       "  0.00023102581326384097,\n",
       "  -0.006333015393465757,\n",
       "  0.02011055499315262,\n",
       "  -0.0029532532207667828,\n",
       "  -0.011683767661452293,\n",
       "  -0.002739998511970043,\n",
       "  -0.01115386188030243,\n",
       "  0.0781158059835434,\n",
       "  -0.020795553922653198,\n",
       "  -0.019761592149734497,\n",
       "  0.019115367904305458,\n",
       "  -0.04104828089475632,\n",
       "  0.0006223964737728238,\n",
       "  -0.05340412259101868,\n",
       "  -0.012304143980145454,\n",
       "  0.029054323211312294,\n",
       "  0.01206504087895155,\n",
       "  -0.0024233476724475622,\n",
       "  0.001444315304979682,\n",
       "  0.03569752722978592,\n",
       "  -0.01898612268269062,\n",
       "  -0.022436968982219696,\n",
       "  0.0014725876972079277,\n",
       "  0.022501591593027115,\n",
       "  -5.1906340559071396e-06,\n",
       "  -0.004720681346952915,\n",
       "  -0.033862244337797165,\n",
       "  0.014372067525982857,\n",
       "  0.005370138678699732,\n",
       "  0.031561680138111115,\n",
       "  -0.0042489361949265,\n",
       "  0.020549988374114037,\n",
       "  -0.017900461331009865,\n",
       "  -0.003109962912276387,\n",
       "  0.001933831488713622,\n",
       "  -0.01672433130443096,\n",
       "  0.009014853276312351,\n",
       "  0.011548059992492199,\n",
       "  0.008316929452121258,\n",
       "  -0.0026818381156772375,\n",
       "  -0.008329854346811771,\n",
       "  -0.006517190020531416,\n",
       "  0.026521118357777596,\n",
       "  0.017150839790701866,\n",
       "  0.036369603127241135,\n",
       "  -0.010488249361515045,\n",
       "  0.019800366833806038,\n",
       "  0.02365187369287014,\n",
       "  0.018663009628653526,\n",
       "  -0.0033216020092368126,\n",
       "  -0.013880935497581959,\n",
       "  -0.026210928335785866,\n",
       "  0.0018336664652451873,\n",
       "  -0.010669192299246788,\n",
       "  0.011612682603299618,\n",
       "  -0.009809711948037148,\n",
       "  -0.009926032274961472,\n",
       "  -0.0002447581209708005,\n",
       "  0.008620656095445156,\n",
       "  -0.029700549319386482,\n",
       "  0.02721904218196869,\n",
       "  0.012362305074930191,\n",
       "  -0.013829237781465054,\n",
       "  0.01179362554103136,\n",
       "  -0.002206861972808838,\n",
       "  -0.01422989834100008,\n",
       "  -0.012937446124851704,\n",
       "  -0.01014574896544218,\n",
       "  0.008762825280427933,\n",
       "  0.03409488871693611,\n",
       "  -0.02502187341451645,\n",
       "  -0.003993676975369453,\n",
       "  -0.03024337999522686,\n",
       "  0.013738766312599182,\n",
       "  0.026094608008861542,\n",
       "  -0.024349797517061234,\n",
       "  0.0051407283172011375,\n",
       "  0.007295892108231783,\n",
       "  -0.031768474727869034,\n",
       "  -0.028408097103238106,\n",
       "  0.012174898758530617,\n",
       "  -0.01108923926949501,\n",
       "  0.0013635370414704084,\n",
       "  0.027891116216778755,\n",
       "  -0.011580371297895908,\n",
       "  0.004788535181432962,\n",
       "  0.03843752667307854,\n",
       "  -0.020549988374114037,\n",
       "  -0.02972639910876751,\n",
       "  0.01778414100408554,\n",
       "  -0.04042790085077286,\n",
       "  -0.007076175417751074,\n",
       "  0.016181500628590584,\n",
       "  0.0069598546251654625,\n",
       "  0.02197168581187725,\n",
       "  0.008336315862834454,\n",
       "  0.019541876390576363,\n",
       "  0.009932494722306728,\n",
       "  -0.0038805874064564705,\n",
       "  0.043581485748291016,\n",
       "  -0.023561403155326843,\n",
       "  -0.019386781379580498,\n",
       "  0.02667621150612831,\n",
       "  0.02124791219830513,\n",
       "  0.005127803888171911,\n",
       "  -0.02622385323047638,\n",
       "  -0.018029706552624702,\n",
       "  -0.00916348583996296,\n",
       "  -0.025086496025323868,\n",
       "  -0.003903205506503582,\n",
       "  -0.021157441660761833,\n",
       "  -0.014191124588251114,\n",
       "  0.003518700832501054,\n",
       "  -0.011231409385800362,\n",
       "  0.022359421476721764,\n",
       "  -0.03507715091109276,\n",
       "  -0.010268531739711761,\n",
       "  0.006895232014358044,\n",
       "  -0.019994234666228294,\n",
       "  0.008323391899466515,\n",
       "  0.01273711584508419,\n",
       "  0.01946432888507843,\n",
       "  0.013751690275967121,\n",
       "  -0.0009919570293277502,\n",
       "  -0.0034379225689917803,\n",
       "  -0.0012140972539782524,\n",
       "  -0.0027916966937482357,\n",
       "  -0.009758013300597668,\n",
       "  -0.03634375333786011,\n",
       "  0.024840930476784706,\n",
       "  0.02763262577354908,\n",
       "  -0.017344707623124123,\n",
       "  0.013622445054352283,\n",
       "  0.013312256895005703,\n",
       "  -0.0048240777105093,\n",
       "  -0.017693670466542244,\n",
       "  0.003444385016337037,\n",
       "  0.0028320858255028725,\n",
       "  0.037920545786619186,\n",
       "  -0.01108923926949501,\n",
       "  -0.010565795935690403,\n",
       "  0.0032569793984293938,\n",
       "  -0.02217847853899002,\n",
       "  0.0038159650284796953,\n",
       "  0.0062974728643894196,\n",
       "  -0.02698639966547489,\n",
       "  0.007166646886616945,\n",
       "  0.000313419644953683,\n",
       "  0.023638948798179626,\n",
       "  0.023768194019794464,\n",
       "  -0.0006712673348374665,\n",
       "  -0.033526208251714706,\n",
       "  -0.02646941877901554,\n",
       "  -0.0060486760921776295,\n",
       "  0.010895371437072754,\n",
       "  -0.018249424174427986,\n",
       "  0.0362403579056263,\n",
       "  -0.02234649658203125,\n",
       "  0.03487036004662514,\n",
       "  0.00044589597382582724,\n",
       "  -0.0026769915129989386,\n",
       "  0.0004701294528786093,\n",
       "  -0.02241111919283867,\n",
       "  -0.007282967679202557,\n",
       "  -0.019451403990387917,\n",
       "  0.05084506794810295,\n",
       "  0.02512526884675026,\n",
       "  0.016737254336476326,\n",
       "  -0.00272061163559556,\n",
       "  0.018210651353001595,\n",
       "  -0.022992722690105438,\n",
       "  -0.0026947627775371075,\n",
       "  -0.011005230247974396,\n",
       "  -0.010701503604650497,\n",
       "  -0.016155650839209557,\n",
       "  -0.02076970599591732,\n",
       "  -0.0015525581547990441,\n",
       "  0.027193192392587662,\n",
       "  0.028511494398117065,\n",
       "  -0.010029428638517857,\n",
       "  -0.014565935358405113,\n",
       "  0.0061811525374650955,\n",
       "  0.021054044365882874,\n",
       "  0.019076593220233917,\n",
       "  0.0039096674881875515,\n",
       "  -0.0012811431661248207,\n",
       "  -0.027555080130696297,\n",
       "  -0.000979032483883202,\n",
       "  0.02097649872303009,\n",
       "  -0.0049242423847317696,\n",
       "  0.022941024973988533,\n",
       "  -0.01939970627427101,\n",
       "  0.0006102797342464328,\n",
       "  0.029261115938425064,\n",
       "  0.008368627168238163,\n",
       "  0.020239800214767456,\n",
       "  -0.017551500350236893,\n",
       "  -0.00034573095035739243,\n",
       "  0.005651246756315231,\n",
       "  0.0114317387342453,\n",
       "  0.009202259592711926,\n",
       "  0.03347450867295265,\n",
       "  -0.025422533974051476,\n",
       "  0.01689234934747219,\n",
       "  -0.039523184299468994,\n",
       "  0.012317068874835968,\n",
       "  0.018314046785235405,\n",
       "  0.02537083439528942,\n",
       "  0.002803005510941148,\n",
       "  -0.020808478817343712,\n",
       "  -0.0007415444124490023,\n",
       "  -0.031975265592336655,\n",
       "  0.01998130977153778,\n",
       "  -0.0054735345765948296,\n",
       "  -0.013738766312599182,\n",
       "  0.015935935080051422,\n",
       "  -0.017797065898776054,\n",
       "  -0.014100653119385242,\n",
       "  -0.03724846988916397,\n",
       "  -0.023703571408987045,\n",
       "  -0.002386189764365554,\n",
       "  -0.015871312469244003,\n",
       "  0.03308677300810814,\n",
       "  0.019968384876847267,\n",
       "  0.021583950147032738,\n",
       "  -0.018559612333774567,\n",
       "  -0.008885608054697514,\n",
       "  0.021648572757840157,\n",
       "  -0.015884237363934517,\n",
       "  0.020226875320076942,\n",
       "  -0.015832537785172462,\n",
       "  0.013557822443544865,\n",
       "  0.014216973446309566,\n",
       "  0.039704129099845886,\n",
       "  -0.00599051546305418,\n",
       "  -0.03244054690003395,\n",
       "  0.0029758710879832506,\n",
       "  0.008446174673736095,\n",
       "  0.02622385323047638,\n",
       "  0.0025913664139807224,\n",
       "  0.0029532532207667828,\n",
       "  -0.023470930755138397,\n",
       "  0.006643204018473625,\n",
       "  -0.00727004325017333,\n",
       "  0.008336315862834454,\n",
       "  -0.01179362554103136,\n",
       "  0.007463911082595587,\n",
       "  0.023806968703866005,\n",
       "  -0.010313767939805984,\n",
       "  9.774169302545488e-05,\n",
       "  -0.011250795796513557,\n",
       "  -0.0024669680278748274,\n",
       "  0.010514098219573498,\n",
       "  0.012207210063934326,\n",
       "  -0.01836574450135231,\n",
       "  0.000979032483883202,\n",
       "  -0.016879424452781677,\n",
       "  -0.005848345812410116,\n",
       "  -0.010300843045115471,\n",
       "  -0.022333573549985886,\n",
       "  0.021958760917186737,\n",
       "  0.014462538994848728,\n",
       "  0.007573769427835941,\n",
       "  -0.008181221783161163,\n",
       "  -0.006045444868505001,\n",
       "  -0.02670206129550934,\n",
       "  -0.008026127703487873,\n",
       "  0.008084287866950035,\n",
       "  -0.008788674138486385,\n",
       "  -0.011011691763997078,\n",
       "  0.03507715091109276,\n",
       "  0.020071782171726227,\n",
       "  0.003172969911247492,\n",
       "  0.009208721108734608,\n",
       "  -0.01344150211662054,\n",
       "  0.01675017923116684,\n",
       "  0.030191682279109955,\n",
       "  -0.02276008203625679,\n",
       "  -0.02495725080370903,\n",
       "  0.004142309073358774,\n",
       "  -0.0007984930998645723,\n",
       "  -0.004988864995539188,\n",
       "  0.0033732999581843615,\n",
       "  -0.002027534181252122,\n",
       "  -0.026857154443860054,\n",
       "  -0.027710173279047012,\n",
       "  -0.019684046506881714,\n",
       "  -0.00513103511184454,\n",
       "  0.010029428638517857,\n",
       "  -0.01081136241555214,\n",
       "  -0.009725701995193958,\n",
       "  -0.006555963307619095,\n",
       "  -0.014372067525982857,\n",
       "  -0.013053766451776028,\n",
       "  -0.0031471208203583956,\n",
       "  0.026378948241472244,\n",
       "  -0.0008259576861746609,\n",
       "  -0.022113855928182602,\n",
       "  0.006675515323877335,\n",
       "  -0.005938817746937275,\n",
       "  -0.005864501465111971,\n",
       "  0.024220552295446396,\n",
       "  0.006255468353629112,\n",
       "  -0.01549650076776743,\n",
       "  0.0237552709877491,\n",
       "  -0.02371649630367756,\n",
       "  0.011942258104681969,\n",
       "  -0.0015355946961790323,\n",
       "  0.006122991908341646,\n",
       "  0.002667298074811697,\n",
       "  0.013531973585486412,\n",
       "  -0.0012633719015866518,\n",
       "  -0.026727909222245216,\n",
       "  0.0218295156955719,\n",
       "  -0.022682534530758858,\n",
       "  -0.008161835372447968,\n",
       "  -0.030631115660071373,\n",
       "  0.003996908199042082,\n",
       "  0.00853018369525671,\n",
       "  -0.0030889606568962336,\n",
       "  0.009137636981904507,\n",
       "  0.032905831933021545,\n",
       "  -0.005793416872620583,\n",
       "  0.008937306702136993,\n",
       "  -0.007567307446151972,\n",
       "  -0.022579139098525047,\n",
       "  -0.0010880831396207213,\n",
       "  -0.007386364042758942,\n",
       "  -0.00430709682404995,\n",
       "  0.013635369949042797,\n",
       "  -0.003706106450408697,\n",
       "  0.01323470938950777,\n",
       "  -0.012976218946278095,\n",
       "  0.010688578709959984,\n",
       "  0.019231688231229782,\n",
       "  -0.035439036786556244,\n",
       "  -0.02371649630367756,\n",
       "  -0.0006660167127847672,\n",
       "  0.003077651606872678,\n",
       "  -0.011412352323532104,\n",
       "  -0.002853088080883026,\n",
       "  -0.020058857277035713,\n",
       "  -0.019645271822810173,\n",
       "  -0.027193192392587662,\n",
       "  -0.014514237642288208,\n",
       "  -0.02029149793088436,\n",
       "  -0.0005690828547812998,\n",
       "  0.0010872753337025642,\n",
       "  0.0016260662814602256,\n",
       "  -0.007018015254288912,\n",
       "  0.001378077082335949,\n",
       "  -0.00971277803182602,\n",
       "  0.012969757430255413,\n",
       "  -0.011787163093686104,\n",
       "  -0.013635369949042797,\n",
       "  -0.025409609079360962,\n",
       "  0.009421976283192635,\n",
       "  -0.017693670466542244,\n",
       "  0.030501870438456535,\n",
       "  -0.00745744863525033,\n",
       "  0.004862850997596979,\n",
       "  -0.010643343441188335,\n",
       "  -0.004930704832077026,\n",
       "  -0.04681261628866196,\n",
       "  0.0018465910106897354,\n",
       "  0.00873697642236948,\n",
       "  0.012498011812567711,\n",
       "  0.01481150183826685,\n",
       "  -0.0020630767103284597,\n",
       "  0.03649884834885597,\n",
       "  0.026094608008861542,\n",
       "  -0.007534996140748262,\n",
       "  0.011283107101917267,\n",
       "  -0.03153583034873009,\n",
       "  -0.021532252430915833,\n",
       "  0.007515609264373779,\n",
       "  0.014191124588251114,\n",
       "  -0.029131870716810226,\n",
       "  -0.029442058876156807,\n",
       "  -0.021751970052719116,\n",
       "  -0.026391873136162758,\n",
       "  0.011354192160069942,\n",
       "  -0.017771216109395027,\n",
       "  -0.02354847826063633,\n",
       "  0.025306211784482002,\n",
       "  0.00858188234269619,\n",
       "  0.0098355608060956,\n",
       "  -0.0028902459889650345,\n",
       "  0.011560983955860138,\n",
       "  -0.009764475747942924,\n",
       "  0.017551500350236893,\n",
       "  0.014204048551619053,\n",
       "  -0.026288475841283798,\n",
       "  -0.03223375603556633,\n",
       "  -0.0010888909455388784,\n",
       "  -0.018288196995854378,\n",
       "  -0.010591644793748856,\n",
       "  0.004129384644329548,\n",
       "  -0.008336315862834454,\n",
       "  -0.011289569549262524,\n",
       "  0.03538734093308449,\n",
       "  -0.012006880715489388,\n",
       "  -0.0055575440637767315,\n",
       "  -0.01130895595997572,\n",
       "  -0.010139286518096924,\n",
       "  0.01720253750681877,\n",
       "  -0.018210651353001595,\n",
       "  0.008478485979139805,\n",
       "  0.023302912712097168,\n",
       "  -0.00763839203864336,\n",
       "  0.01091475784778595,\n",
       "  -0.03326771780848503,\n",
       "  0.004349101334810257,\n",
       "  -0.01600055769085884,\n",
       "  0.009150560945272446,\n",
       "  0.005240893457084894,\n",
       "  -0.018663009628653526,\n",
       "  -0.029131870716810226,\n",
       "  -0.00870466511696577,\n",
       "  0.009182872250676155,\n",
       "  -0.03453432023525238,\n",
       "  0.01782291568815708,\n",
       "  -0.010119900107383728,\n",
       "  0.009350891225039959,\n",
       "  -0.017293009907007217,\n",
       "  0.007625467609614134,\n",
       "  -0.011573908850550652,\n",
       "  0.007819334976375103,\n",
       "  -0.016556311398744583,\n",
       "  0.01026207022368908,\n",
       "  0.012691879644989967,\n",
       "  -0.017318857833743095,\n",
       "  -0.034792810678482056,\n",
       "  0.00839447695761919,\n",
       "  -0.016982821747660637,\n",
       "  0.007515609264373779,\n",
       "  0.007412212900817394,\n",
       "  -0.013855086639523506,\n",
       "  -0.007567307446151972,\n",
       "  0.01730593480169773,\n",
       "  0.03546488657593727,\n",
       "  -0.0014903588453307748,\n",
       "  -0.01386801153421402,\n",
       "  0.19738328456878662,\n",
       "  -0.005838652607053518,\n",
       "  0.004985634237527847,\n",
       "  0.027451682835817337,\n",
       "  -0.0012795275542885065,\n",
       "  0.024672910571098328,\n",
       "  -0.009842023253440857,\n",
       "  -0.0013449579710140824,\n",
       "  -0.019968384876847267,\n",
       "  0.0010169983142986894,\n",
       "  -0.019128290936350822,\n",
       "  0.013738766312599182,\n",
       "  -0.02381989359855652,\n",
       "  -0.0037804224994033575,\n",
       "  -0.004452497698366642,\n",
       "  -0.013699992559850216,\n",
       "  0.018520839512348175,\n",
       "  -0.023974986746907234,\n",
       "  -0.003680257359519601,\n",
       "  0.008135986514389515,\n",
       "  0.020485365763306618,\n",
       "  0.0004713411326520145,\n",
       "  -0.03890280798077583,\n",
       "  -0.012898672372102737,\n",
       "  0.027038099244236946,\n",
       "  0.021907063201069832,\n",
       "  -0.006471953820437193,\n",
       "  0.0052247378043830395,\n",
       "  0.016349518671631813,\n",
       "  -0.0021276993211358786,\n",
       "  -0.017344707623124123,\n",
       "  0.010863060131669044,\n",
       "  -0.018792254850268364,\n",
       "  0.010359004139900208,\n",
       "  0.005554312840104103,\n",
       "  -0.015729142352938652,\n",
       "  0.003580092452466488,\n",
       "  0.0038353516720235348,\n",
       "  0.00583542138338089,\n",
       "  0.009434900246560574,\n",
       "  0.0016333364183083177,\n",
       "  0.01438499242067337,\n",
       "  0.0010573874460533261,\n",
       "  -0.035206396132707596,\n",
       "  0.019115367904305458,\n",
       "  0.013124851509928703,\n",
       "  ...],\n",
       " 'response': 'Ingesting the following content: Arduino is an open-source electronics platform based on easy-to-use hardware and software. It consists of a physical programmable circuit board (often referred to as a microcontroller) and a piece of software, or IDE (Integrated Development Environment), that runs on your computer. You use the IDE to write and upload computer code to the physical board. The platform is designed to enable users of all ages to create interactive electronic objects and projects that can sense and control physical devices. Arduino boards can read inputs - light on a sensor, a finger on a button, or a Twitter message - and turn it into an output - activating a motor, turning on an LED, publishing something online. You can tell your board what to do by sending a set of instructions to the microcontroller on the board. Arduino is widely used in robotics, home automation, scientific experimentation, and artistic projects.\\nThank you, I have learned this content (174 tokens).',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tokens used in iteration 2: 227 training tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 3  ApplePie Instructions\n",
      "  Dataset: None\n",
      "  Context: ApplePie Instructions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedding': [0.01928705908358097,\n",
       "  -0.0018624502699822187,\n",
       "  -0.012249375693500042,\n",
       "  -0.014151452109217644,\n",
       "  -0.001438445644453168,\n",
       "  0.0010358394356444478,\n",
       "  -0.01670023612678051,\n",
       "  0.0026898537762463093,\n",
       "  -0.0010952792363241315,\n",
       "  -0.03920814394950867,\n",
       "  0.013441343791782856,\n",
       "  0.025513192638754845,\n",
       "  -0.02536102570593357,\n",
       "  0.014607951045036316,\n",
       "  -0.017156733199954033,\n",
       "  0.03413594141602516,\n",
       "  0.01030291710048914,\n",
       "  0.027364546433091164,\n",
       "  -0.016636833548545837,\n",
       "  -0.0106833316385746,\n",
       "  -0.046512119472026825,\n",
       "  0.009586467407643795,\n",
       "  0.022698117420077324,\n",
       "  0.002498060930520296,\n",
       "  -0.03142230957746506,\n",
       "  -0.0033793565817177296,\n",
       "  0.0028578706551343203,\n",
       "  0.002965654945001006,\n",
       "  0.015178574249148369,\n",
       "  -0.0011745324591174722,\n",
       "  0.026502272114157677,\n",
       "  0.0046569183468818665,\n",
       "  -0.02307853288948536,\n",
       "  -0.00022091831488069147,\n",
       "  -0.03180272504687309,\n",
       "  0.00026609262567944825,\n",
       "  -0.021886564791202545,\n",
       "  0.006337086204439402,\n",
       "  0.006264173425734043,\n",
       "  -0.02066923677921295,\n",
       "  0.029469512403011322,\n",
       "  0.002642301842570305,\n",
       "  -0.013682273216545582,\n",
       "  0.028100015595555305,\n",
       "  -0.009681571274995804,\n",
       "  0.014848880469799042,\n",
       "  0.005164138972759247,\n",
       "  -0.012724895030260086,\n",
       "  0.006796754896640778,\n",
       "  0.0028895719442516565,\n",
       "  0.002280907239764929,\n",
       "  0.006872837897390127,\n",
       "  -0.0164719857275486,\n",
       "  -0.020770680159330368,\n",
       "  -0.0030369828455150127,\n",
       "  0.004412818234413862,\n",
       "  -0.005319475196301937,\n",
       "  0.025487830862402916,\n",
       "  0.0032779125031083822,\n",
       "  0.005902778822928667,\n",
       "  -0.023319462314248085,\n",
       "  0.0056047867983579636,\n",
       "  -0.0190080888569355,\n",
       "  -0.0002274566941196099,\n",
       "  -0.029951371252536774,\n",
       "  -0.021911926567554474,\n",
       "  0.008838317357003689,\n",
       "  -0.011824578046798706,\n",
       "  -0.007202531211078167,\n",
       "  0.019616752862930298,\n",
       "  0.015977445989847183,\n",
       "  0.012883400544524193,\n",
       "  0.025348344817757607,\n",
       "  0.021024290472269058,\n",
       "  0.016941165551543236,\n",
       "  0.011716794222593307,\n",
       "  -0.010448742657899857,\n",
       "  -0.00355688389390707,\n",
       "  0.009903480298817158,\n",
       "  -0.0023680857848376036,\n",
       "  0.016776317730545998,\n",
       "  -0.000747754005715251,\n",
       "  -0.0069045391865074635,\n",
       "  0.04542159661650658,\n",
       "  -0.0010073082521557808,\n",
       "  0.004777383059263229,\n",
       "  -0.03132086619734764,\n",
       "  0.016231056302785873,\n",
       "  -0.007196191232651472,\n",
       "  -0.0008797105983830988,\n",
       "  -0.005871077533811331,\n",
       "  0.01757519133388996,\n",
       "  0.003052833490073681,\n",
       "  -0.00938992016017437,\n",
       "  -0.03677348792552948,\n",
       "  0.03814298287034035,\n",
       "  -0.0026327914092689753,\n",
       "  0.0360887385904789,\n",
       "  -0.01917293481528759,\n",
       "  -0.027415268123149872,\n",
       "  0.0036551577504724264,\n",
       "  -0.004679109435528517,\n",
       "  -0.02108769305050373,\n",
       "  -0.01782880164682865,\n",
       "  -0.02617257833480835,\n",
       "  -0.013555468060076237,\n",
       "  0.034034498035907745,\n",
       "  -0.020529750734567642,\n",
       "  -0.002723140176385641,\n",
       "  -0.008121868595480919,\n",
       "  -0.005661848932504654,\n",
       "  -0.011082768440246582,\n",
       "  0.015901362523436546,\n",
       "  -0.03471924364566803,\n",
       "  -0.002046317793428898,\n",
       "  0.01827261969447136,\n",
       "  -0.006650928873568773,\n",
       "  -0.025880927219986916,\n",
       "  -0.026552993804216385,\n",
       "  -0.05204082280397415,\n",
       "  0.030737562105059624,\n",
       "  0.019223656505346298,\n",
       "  0.021303260698914528,\n",
       "  -0.009123628959059715,\n",
       "  0.002177878050133586,\n",
       "  -0.020174695178866386,\n",
       "  -0.005753782577812672,\n",
       "  -0.010442402213811874,\n",
       "  -0.001076258486136794,\n",
       "  -0.009472343139350414,\n",
       "  0.05665653198957443,\n",
       "  -0.009009504690766335,\n",
       "  -0.00546213099732995,\n",
       "  0.01965479552745819,\n",
       "  -0.0036836890503764153,\n",
       "  -0.0005361479124985635,\n",
       "  -0.02487916685640812,\n",
       "  -0.00569355022162199,\n",
       "  0.009662550874054432,\n",
       "  -0.00018317396461497992,\n",
       "  0.003591755172237754,\n",
       "  0.019122213125228882,\n",
       "  -0.010905240662395954,\n",
       "  -0.0025044013746082783,\n",
       "  -0.02097356878221035,\n",
       "  0.012826338410377502,\n",
       "  0.013403302058577538,\n",
       "  0.011241274885833263,\n",
       "  -0.02201336994767189,\n",
       "  -0.000870992720592767,\n",
       "  0.023522350937128067,\n",
       "  0.00024152414698619395,\n",
       "  0.03185344859957695,\n",
       "  -0.0050278231501579285,\n",
       "  0.0064321900717914104,\n",
       "  -0.000607872090768069,\n",
       "  0.004305033944547176,\n",
       "  -0.02612185664474964,\n",
       "  -0.02356039360165596,\n",
       "  -0.007976042106747627,\n",
       "  -0.010797456838190556,\n",
       "  0.001967064570635557,\n",
       "  0.016852401196956635,\n",
       "  -0.00019377408898435533,\n",
       "  -0.0004707640327978879,\n",
       "  0.01945190690457821,\n",
       "  0.014709394425153732,\n",
       "  -0.0001077843553503044,\n",
       "  0.014417743310332298,\n",
       "  0.012718554586172104,\n",
       "  0.021823162212967873,\n",
       "  -0.0072786142118275166,\n",
       "  -0.03522646427154541,\n",
       "  0.020770680159330368,\n",
       "  0.025399066507816315,\n",
       "  0.01554630883038044,\n",
       "  0.011513905599713326,\n",
       "  0.012490305118262768,\n",
       "  0.016459304839372635,\n",
       "  0.01602816767990589,\n",
       "  -0.02397884987294674,\n",
       "  -0.015533627942204475,\n",
       "  0.0041877394542098045,\n",
       "  0.06888054311275482,\n",
       "  -0.03621554374694824,\n",
       "  -0.012674172408878803,\n",
       "  0.0005266375374048948,\n",
       "  0.019325101748108864,\n",
       "  0.0007576606585644186,\n",
       "  -0.01774003729224205,\n",
       "  0.010892560705542564,\n",
       "  0.0217597596347332,\n",
       "  -0.003772452473640442,\n",
       "  -0.01463331189006567,\n",
       "  -0.6399093866348267,\n",
       "  -0.02903837338089943,\n",
       "  -0.0014883752446621656,\n",
       "  -0.017359621822834015,\n",
       "  0.0005416956846602261,\n",
       "  0.003794643562287092,\n",
       "  0.007069386076182127,\n",
       "  -0.02721238136291504,\n",
       "  -0.023737920448184013,\n",
       "  -0.0041972496546804905,\n",
       "  0.017334261909127235,\n",
       "  0.02108769305050373,\n",
       "  0.03761040046811104,\n",
       "  0.013289177790284157,\n",
       "  -0.010011265054345131,\n",
       "  -0.008667130954563618,\n",
       "  -0.0005488284514285624,\n",
       "  -0.0277449619024992,\n",
       "  -0.04765336588025093,\n",
       "  -0.011171531863510609,\n",
       "  -0.0037122201174497604,\n",
       "  0.01628177799284458,\n",
       "  -0.016154972836375237,\n",
       "  -0.009706932120025158,\n",
       "  0.0022381104063242674,\n",
       "  0.002337969606742263,\n",
       "  0.0200986135751009,\n",
       "  -0.020986247807741165,\n",
       "  0.005173649173229933,\n",
       "  -0.006898198742419481,\n",
       "  0.01478547789156437,\n",
       "  0.009840077720582485,\n",
       "  0.00010184037091676146,\n",
       "  0.0015707985730841756,\n",
       "  0.0468418151140213,\n",
       "  0.00627685384824872,\n",
       "  -0.04093269631266594,\n",
       "  -0.0168650820851326,\n",
       "  0.025310304015874863,\n",
       "  0.050899580121040344,\n",
       "  -0.0013401716714724898,\n",
       "  -0.016294458881020546,\n",
       "  0.018678395077586174,\n",
       "  -0.007101087365299463,\n",
       "  -0.006007392890751362,\n",
       "  -0.031219422817230225,\n",
       "  0.0051197572611272335,\n",
       "  0.012331798672676086,\n",
       "  0.01661147177219391,\n",
       "  -0.011418801732361317,\n",
       "  0.0035061617381870747,\n",
       "  0.011152511462569237,\n",
       "  -0.002715214854106307,\n",
       "  0.013162372633814812,\n",
       "  0.022533271461725235,\n",
       "  -0.013745675794780254,\n",
       "  0.021493468433618546,\n",
       "  -0.0052433921955525875,\n",
       "  -0.005753782577812672,\n",
       "  0.006619227584451437,\n",
       "  -0.003994361497461796,\n",
       "  0.022786881774663925,\n",
       "  -0.030889729037880898,\n",
       "  0.003290593158453703,\n",
       "  -0.015584350563585758,\n",
       "  0.006967941764742136,\n",
       "  -0.01644662581384182,\n",
       "  0.010759415104985237,\n",
       "  0.03053467534482479,\n",
       "  -0.01762591302394867,\n",
       "  -0.01153926644474268,\n",
       "  -0.0022222597617655993,\n",
       "  -0.026324745267629623,\n",
       "  0.0018989067757502198,\n",
       "  0.011577308177947998,\n",
       "  0.008495943620800972,\n",
       "  0.004920038860291243,\n",
       "  -0.009586467407643795,\n",
       "  -0.005817185156047344,\n",
       "  -0.002756426576524973,\n",
       "  0.023141935467720032,\n",
       "  0.008870018646121025,\n",
       "  -0.0064448704943060875,\n",
       "  -0.024283181875944138,\n",
       "  0.00589009840041399,\n",
       "  0.0075005232356488705,\n",
       "  0.0108798798173666,\n",
       "  -0.008559346199035645,\n",
       "  -0.018703756853938103,\n",
       "  0.005237051751464605,\n",
       "  0.017892204225063324,\n",
       "  0.03697637468576431,\n",
       "  0.007329336367547512,\n",
       "  -0.045446958392858505,\n",
       "  -0.023395545780658722,\n",
       "  0.008850998245179653,\n",
       "  -0.005943990312516689,\n",
       "  -0.00612151762470603,\n",
       "  0.0029101776890456676,\n",
       "  -0.010791116394102573,\n",
       "  0.006165899336338043,\n",
       "  -0.009573787450790405,\n",
       "  0.02148078940808773,\n",
       "  -0.01448114588856697,\n",
       "  0.035074297338724136,\n",
       "  -0.0005333740846253932,\n",
       "  -0.007823876105248928,\n",
       "  -0.0031241613905876875,\n",
       "  0.06091718375682831,\n",
       "  -0.01681436039507389,\n",
       "  -0.0020875295158475637,\n",
       "  -0.01463331189006567,\n",
       "  -0.00913630984723568,\n",
       "  0.009415281005203724,\n",
       "  0.01464599184691906,\n",
       "  -0.01591404341161251,\n",
       "  0.015622391365468502,\n",
       "  -0.00446988083422184,\n",
       "  -0.000501276517752558,\n",
       "  -0.010131729766726494,\n",
       "  0.016598790884017944,\n",
       "  -0.010499464347958565,\n",
       "  0.010835498571395874,\n",
       "  -0.007582946680486202,\n",
       "  -0.056605808436870575,\n",
       "  0.013935883529484272,\n",
       "  0.009586467407643795,\n",
       "  0.0039436393417418,\n",
       "  -0.010328277945518494,\n",
       "  -0.012376180849969387,\n",
       "  0.005088055972009897,\n",
       "  0.03165055811405182,\n",
       "  -0.0048059141263365746,\n",
       "  0.011279315687716007,\n",
       "  -0.021670997142791748,\n",
       "  0.010930602438747883,\n",
       "  0.014341659843921661,\n",
       "  -0.03750895708799362,\n",
       "  0.017638593912124634,\n",
       "  -0.030636118724942207,\n",
       "  0.0070313443429768085,\n",
       "  0.0323353074491024,\n",
       "  -0.018906645476818085,\n",
       "  -0.011513905599713326,\n",
       "  0.011234934441745281,\n",
       "  -0.024042252451181412,\n",
       "  -0.015749197453260422,\n",
       "  -0.01219865307211876,\n",
       "  0.0016342010349035263,\n",
       "  0.00796970259398222,\n",
       "  -0.0017102841520681977,\n",
       "  -0.016877762973308563,\n",
       "  0.00427333265542984,\n",
       "  -0.0008575196843594313,\n",
       "  -0.0024140526074916124,\n",
       "  0.0013409642269834876,\n",
       "  0.01056920737028122,\n",
       "  -0.01596476510167122,\n",
       "  -0.012718554586172104,\n",
       "  -0.007785834837704897,\n",
       "  9.079445590032265e-05,\n",
       "  0.04331663250923157,\n",
       "  -0.011355399154126644,\n",
       "  -0.009491363540291786,\n",
       "  -0.007912639528512955,\n",
       "  -0.030915090814232826,\n",
       "  0.007107427343726158,\n",
       "  -0.0058266958221793175,\n",
       "  0.0015501927118748426,\n",
       "  -0.022862965241074562,\n",
       "  0.001643711468204856,\n",
       "  -0.003496651304885745,\n",
       "  0.01335258036851883,\n",
       "  0.0160788893699646,\n",
       "  -0.014303618110716343,\n",
       "  0.04111022129654884,\n",
       "  -0.015419503673911095,\n",
       "  0.00977033469825983,\n",
       "  0.005997882690280676,\n",
       "  -0.022989770397543907,\n",
       "  -0.0015684209065511823,\n",
       "  0.0321577787399292,\n",
       "  -0.0023141936399042606,\n",
       "  0.014062688685953617,\n",
       "  0.004479391034692526,\n",
       "  0.005934480112046003,\n",
       "  -0.008052125573158264,\n",
       "  0.006511443294584751,\n",
       "  -0.03261427953839302,\n",
       "  0.020529750734567642,\n",
       "  0.0072659337893128395,\n",
       "  0.019109532237052917,\n",
       "  0.031777363270521164,\n",
       "  0.006390978582203388,\n",
       "  0.039791449904441833,\n",
       "  -0.0023221189621835947,\n",
       "  0.006007392890751362,\n",
       "  -0.019337782636284828,\n",
       "  0.0063212355598807335,\n",
       "  0.006695310585200787,\n",
       "  0.013771036639809608,\n",
       "  0.013783717527985573,\n",
       "  0.03340047225356102,\n",
       "  -0.019249018281698227,\n",
       "  0.02210213430225849,\n",
       "  -0.030509313568472862,\n",
       "  0.01397392526268959,\n",
       "  0.0029640698339790106,\n",
       "  0.010398020036518574,\n",
       "  0.022533271461725235,\n",
       "  -0.004672768991440535,\n",
       "  -0.010943282395601273,\n",
       "  -0.03928422927856445,\n",
       "  -0.022393785417079926,\n",
       "  0.007101087365299463,\n",
       "  0.020872123539447784,\n",
       "  0.01591404341161251,\n",
       "  0.023382864892482758,\n",
       "  0.011577308177947998,\n",
       "  0.008090167306363583,\n",
       "  0.018970048055052757,\n",
       "  0.001064370502717793,\n",
       "  0.014113410376012325,\n",
       "  0.031980253756046295,\n",
       "  -0.025183498859405518,\n",
       "  0.008172590285539627,\n",
       "  0.034846048802137375,\n",
       "  -0.0022523761726915836,\n",
       "  -0.0021192308049649,\n",
       "  -0.026781242340803146,\n",
       "  -0.005994712468236685,\n",
       "  -0.016687555238604546,\n",
       "  -0.018259938806295395,\n",
       "  0.014189493842422962,\n",
       "  0.006245152559131384,\n",
       "  0.03213242068886757,\n",
       "  0.0048059141263365746,\n",
       "  -0.011025706306099892,\n",
       "  -0.00362345646135509,\n",
       "  0.010340957902371883,\n",
       "  0.00653046416118741,\n",
       "  0.0063117253594100475,\n",
       "  0.023826682940125465,\n",
       "  -0.019109532237052917,\n",
       "  0.01808241195976734,\n",
       "  0.009434301406145096,\n",
       "  0.03492213040590286,\n",
       "  0.04374776780605316,\n",
       "  0.003981681074947119,\n",
       "  -0.006127857603132725,\n",
       "  -0.009992243722081184,\n",
       "  0.022190896794199944,\n",
       "  -0.02845507115125656,\n",
       "  0.001597744645550847,\n",
       "  0.005452620331197977,\n",
       "  0.022786881774663925,\n",
       "  0.01101936586201191,\n",
       "  -0.018513549119234085,\n",
       "  0.0017879522638395429,\n",
       "  0.03890381380915642,\n",
       "  0.020390264689922333,\n",
       "  0.016015486791729927,\n",
       "  -0.016294458881020546,\n",
       "  -0.02536102570593357,\n",
       "  -0.010562866926193237,\n",
       "  -0.007690730970352888,\n",
       "  0.000920129707083106,\n",
       "  -0.02035222388803959,\n",
       "  -0.020567791536450386,\n",
       "  0.0017879522638395429,\n",
       "  -0.020390264689922333,\n",
       "  -0.008102847263216972,\n",
       "  0.034085217863321304,\n",
       "  -0.007665370125323534,\n",
       "  0.016383223235607147,\n",
       "  -0.011710453778505325,\n",
       "  0.008255014196038246,\n",
       "  0.003991191275417805,\n",
       "  0.0005523948348127306,\n",
       "  -0.028657959774136543,\n",
       "  -0.03398377448320389,\n",
       "  -0.022457187995314598,\n",
       "  0.01852623000741005,\n",
       "  0.015330740250647068,\n",
       "  0.0010786361526697874,\n",
       "  0.01209086924791336,\n",
       "  -0.004809084348380566,\n",
       "  -0.011710453778505325,\n",
       "  0.027897128835320473,\n",
       "  0.026806604117155075,\n",
       "  0.0069362404756248,\n",
       "  0.02150614932179451,\n",
       "  0.008077486418187618,\n",
       "  0.016624152660369873,\n",
       "  0.013530107215046883,\n",
       "  -0.004355756100267172,\n",
       "  0.038219064474105835,\n",
       "  0.0038643863517791033,\n",
       "  0.006720671895891428,\n",
       "  0.019299739971756935,\n",
       "  -0.009117288514971733,\n",
       "  -4.301963053876534e-05,\n",
       "  -0.028100015595555305,\n",
       "  -0.042860131710767746,\n",
       "  0.030636118724942207,\n",
       "  0.007437120657414198,\n",
       "  -0.010100028477609158,\n",
       "  -0.012116230092942715,\n",
       "  0.03271572291851044,\n",
       "  0.0018703755922615528,\n",
       "  -0.017308900132775307,\n",
       "  0.000380019104341045,\n",
       "  0.009643529541790485,\n",
       "  0.0007509241113439202,\n",
       "  0.008159910328686237,\n",
       "  0.008204291574656963,\n",
       "  0.001951213926076889,\n",
       "  -0.019274380058050156,\n",
       "  0.040780529379844666,\n",
       "  0.010150750167667866,\n",
       "  0.00446988083422184,\n",
       "  -0.021189136430621147,\n",
       "  -0.020060570910573006,\n",
       "  0.012293756939470768,\n",
       "  0.05964913219213486,\n",
       "  -0.0056238071992993355,\n",
       "  -0.0013607775326818228,\n",
       "  0.0032779125031083822,\n",
       "  -0.010638950392603874,\n",
       "  0.005344836041331291,\n",
       "  0.006131027825176716,\n",
       "  -0.006070795468986034,\n",
       "  0.02007325179874897,\n",
       "  -0.004802744369953871,\n",
       "  0.011507565155625343,\n",
       "  0.03593657165765762,\n",
       "  0.009618168696761131,\n",
       "  -0.0004707640327978879,\n",
       "  0.00944698229432106,\n",
       "  -0.020821401849389076,\n",
       "  0.017537148669362068,\n",
       "  -0.0294948723167181,\n",
       "  -0.015533627942204475,\n",
       "  0.004178228788077831,\n",
       "  -0.014937643893063068,\n",
       "  0.012934123165905476,\n",
       "  0.012027466669678688,\n",
       "  0.001429727766662836,\n",
       "  0.022812241688370705,\n",
       "  0.006454381160438061,\n",
       "  0.029647039249539375,\n",
       "  0.017917564138770103,\n",
       "  0.010797456838190556,\n",
       "  -0.0007901544449850917,\n",
       "  0.005912289023399353,\n",
       "  -0.0029482191894203424,\n",
       "  -0.0008353287703357637,\n",
       "  0.005065864883363247,\n",
       "  0.005677699577063322,\n",
       "  0.018336022272706032,\n",
       "  0.002764351898804307,\n",
       "  0.014367020688951015,\n",
       "  0.004644237924367189,\n",
       "  -0.0019179275259375572,\n",
       "  -0.012388860806822777,\n",
       "  0.0033476552926003933,\n",
       "  -0.010651630349457264,\n",
       "  -0.01621837541460991,\n",
       "  0.015165893360972404,\n",
       "  -0.022305022925138474,\n",
       "  -0.011101788841187954,\n",
       "  0.011501224711537361,\n",
       "  -0.011659731157124043,\n",
       "  -0.015673113986849785,\n",
       "  -0.0032557216472923756,\n",
       "  0.007925320416688919,\n",
       "  0.00940260011702776,\n",
       "  0.014024646952748299,\n",
       "  -0.0032367007806897163,\n",
       "  0.016535388305783272,\n",
       "  -0.0045332834124565125,\n",
       "  -0.01995912753045559,\n",
       "  0.01998448744416237,\n",
       "  -0.018538909032940865,\n",
       "  -0.006292704492807388,\n",
       "  0.015863321721553802,\n",
       "  0.014810838736593723,\n",
       "  0.0023363844957202673,\n",
       "  -0.008096507750451565,\n",
       "  -0.007906300015747547,\n",
       "  -0.012445922940969467,\n",
       "  -0.010778435505926609,\n",
       "  -0.004162378143519163,\n",
       "  0.03078828565776348,\n",
       "  -0.004945400170981884,\n",
       "  -0.024790402501821518,\n",
       "  -0.0018624502699822187,\n",
       "  0.019134894013404846,\n",
       "  -0.0034681202378124,\n",
       "  0.009091927669942379,\n",
       "  0.013441343791782856,\n",
       "  -0.014075369574129581,\n",
       "  -0.007050365209579468,\n",
       "  -0.002764351898804307,\n",
       "  -0.006070795468986034,\n",
       "  -0.020453667268157005,\n",
       "  -0.0038548759184777737,\n",
       "  -0.021075012162327766,\n",
       "  -0.011165191419422626,\n",
       "  0.02007325179874897,\n",
       "  0.01138710044324398,\n",
       "  -0.0015739686787128448,\n",
       "  -9.302345279138535e-05,\n",
       "  0.003693199250847101,\n",
       "  0.009282135404646397,\n",
       "  0.015089809894561768,\n",
       "  0.02527226135134697,\n",
       "  -0.02305317297577858,\n",
       "  -0.031194061040878296,\n",
       "  -0.003068684134632349,\n",
       "  -0.027288462966680527,\n",
       "  0.015318059362471104,\n",
       "  0.005779143888503313,\n",
       "  -0.0189193245023489,\n",
       "  -0.001914757420308888,\n",
       "  -0.017778078094124794,\n",
       "  -0.010226833634078503,\n",
       "  -0.024587513878941536,\n",
       "  -0.004885167349129915,\n",
       "  0.0040609342977404594,\n",
       "  -0.00472349114716053,\n",
       "  0.009916161186993122,\n",
       "  0.0029244432225823402,\n",
       "  -0.0006522538606077433,\n",
       "  0.019223656505346298,\n",
       "  0.00930749624967575,\n",
       "  0.02023809775710106,\n",
       "  0.005912289023399353,\n",
       "  0.012388860806822777,\n",
       "  0.02527226135134697,\n",
       "  0.01269319374114275,\n",
       "  0.002735820598900318,\n",
       "  -0.01449382584542036,\n",
       "  0.003677348606288433,\n",
       "  -0.01732158102095127,\n",
       "  -0.04590345546603203,\n",
       "  0.012325458228588104,\n",
       "  -0.008147229440510273,\n",
       "  -0.024536792188882828,\n",
       "  0.004235291387885809,\n",
       "  -0.016497347503900528,\n",
       "  -0.03494749218225479,\n",
       "  -0.01700456812977791,\n",
       "  -0.013935883529484272,\n",
       "  -0.0024917207192629576,\n",
       "  0.004875657148659229,\n",
       "  -0.009142649360001087,\n",
       "  0.0108798798173666,\n",
       "  -0.021036971360445023,\n",
       "  -0.009294816292822361,\n",
       "  0.004752022214233875,\n",
       "  0.033577997237443924,\n",
       "  0.008578366599977016,\n",
       "  0.007988722994923592,\n",
       "  -0.00853398535400629,\n",
       "  0.0220640916377306,\n",
       "  0.007437120657414198,\n",
       "  0.004130676854401827,\n",
       "  0.0034332487266510725,\n",
       "  -0.027136297896504402,\n",
       "  -0.00024469426716677845,\n",
       "  -0.012896081432700157,\n",
       "  9.663937817094848e-05,\n",
       "  0.010556526482105255,\n",
       "  0.025728760287165642,\n",
       "  -0.014341659843921661,\n",
       "  -0.03971536457538605,\n",
       "  -0.00028154702158644795,\n",
       "  -0.015077129937708378,\n",
       "  0.005262412596493959,\n",
       "  0.021100373938679695,\n",
       "  0.028023933991789818,\n",
       "  0.012870720587670803,\n",
       "  -0.0005670567043125629,\n",
       "  0.030940450727939606,\n",
       "  0.028936930000782013,\n",
       "  0.021810481324791908,\n",
       "  -0.01954066939651966,\n",
       "  -0.005871077533811331,\n",
       "  0.010334618389606476,\n",
       "  0.011165191419422626,\n",
       "  -0.03159983828663826,\n",
       "  -0.009326517581939697,\n",
       "  0.02898765169084072,\n",
       "  0.013771036639809608,\n",
       "  0.02825218252837658,\n",
       "  -0.004203590098768473,\n",
       "  0.0021017950493842363,\n",
       "  0.01864035427570343,\n",
       "  0.010689672082662582,\n",
       "  -0.002748501254245639,\n",
       "  -0.01681436039507389,\n",
       "  -0.023915447294712067,\n",
       "  -0.022203577682375908,\n",
       "  0.013263816013932228,\n",
       "  -0.012464944273233414,\n",
       "  -0.00950404442846775,\n",
       "  0.030965812504291534,\n",
       "  0.014405062422156334,\n",
       "  -0.004777383059263229,\n",
       "  -0.011647051200270653,\n",
       "  0.006489252205938101,\n",
       "  0.009871779009699821,\n",
       "  0.008331096731126308,\n",
       "  0.03865020349621773,\n",
       "  -0.012743915431201458,\n",
       "  0.027770323678851128,\n",
       "  -0.03436418995261192,\n",
       "  0.0034078878816217184,\n",
       "  -0.018336022272706032,\n",
       "  0.0005619052099063993,\n",
       "  -0.021125733852386475,\n",
       "  0.0010239514522254467,\n",
       "  -0.006581186316907406,\n",
       "  -0.006235642358660698,\n",
       "  -0.021417386829853058,\n",
       "  -0.013859800063073635,\n",
       "  -0.0075005232356488705,\n",
       "  -0.015165893360972404,\n",
       "  0.012851699255406857,\n",
       "  -0.026730520650744438,\n",
       "  -0.021303260698914528,\n",
       "  5.8994104620069265e-05,\n",
       "  -0.023129254579544067,\n",
       "  -0.011862619780004025,\n",
       "  -0.01234447956085205,\n",
       "  -0.025995051488280296,\n",
       "  0.0019084172090515494,\n",
       "  0.007684390526264906,\n",
       "  -0.0009874949464574456,\n",
       "  -0.006676290184259415,\n",
       "  0.018881283700466156,\n",
       "  -0.029697760939598083,\n",
       "  -0.010753074660897255,\n",
       "  0.01133003830909729,\n",
       "  -0.019997168332338333,\n",
       "  0.06142440438270569,\n",
       "  0.0220640916377306,\n",
       "  0.045244067907333374,\n",
       "  0.017359621822834015,\n",
       "  0.014328979887068272,\n",
       "  0.01965479552745819,\n",
       "  0.016915803775191307,\n",
       "  -0.004067274276167154,\n",
       "  -0.014011966995894909,\n",
       "  0.007741453126072884,\n",
       "  0.0037407511845231056,\n",
       "  0.018970048055052757,\n",
       "  0.024308543652296066,\n",
       "  -0.03464316204190254,\n",
       "  0.021544191986322403,\n",
       "  -0.014595270156860352,\n",
       "  0.0012046487536281347,\n",
       "  0.029976733028888702,\n",
       "  0.0010540676303207874,\n",
       "  -0.013415982946753502,\n",
       "  -0.02820146083831787,\n",
       "  -0.019236337393522263,\n",
       "  -0.020986247807741165,\n",
       "  0.02288832515478134,\n",
       "  0.005414579063653946,\n",
       "  -0.0034776306711137295,\n",
       "  0.011336378753185272,\n",
       "  -0.013314538635313511,\n",
       "  -0.029393428936600685,\n",
       "  0.045193348079919815,\n",
       "  0.012154271826148033,\n",
       "  0.025208858773112297,\n",
       "  0.014050007797777653,\n",
       "  -0.019883044064044952,\n",
       "  0.005313134752213955,\n",
       "  -0.03659595921635628,\n",
       "  -0.03854876011610031,\n",
       "  -0.0014598440611734986,\n",
       "  0.023496991023421288,\n",
       "  0.007633668836206198,\n",
       "  -0.031752005219459534,\n",
       "  0.012135250493884087,\n",
       "  -0.007665370125323534,\n",
       "  0.005512853153049946,\n",
       "  -0.028531154617667198,\n",
       "  -0.01605352945625782,\n",
       "  0.02229234203696251,\n",
       "  0.02487916685640812,\n",
       "  -0.015622391365468502,\n",
       "  -0.00047393416753038764,\n",
       "  0.004920038860291243,\n",
       "  0.003845365485176444,\n",
       "  0.033755525946617126,\n",
       "  -0.017499107867479324,\n",
       "  -0.015597030520439148,\n",
       "  -0.0031653731130063534,\n",
       "  -0.0035632241051644087,\n",
       "  -0.013111650012433529,\n",
       "  0.016738276928663254,\n",
       "  -0.0030877047684043646,\n",
       "  -0.023002449423074722,\n",
       "  -0.0065558250062167645,\n",
       "  0.0003358354442752898,\n",
       "  -0.005424089264124632,\n",
       "  -0.010676992125809193,\n",
       "  -0.002120815683156252,\n",
       "  -0.009732293896377087,\n",
       "  -0.009567447006702423,\n",
       "  -0.012858039699494839,\n",
       "  -0.014392382465302944,\n",
       "  -0.020656555891036987,\n",
       "  -0.01711869239807129,\n",
       "  0.006847477052360773,\n",
       "  -0.0017641762970015407,\n",
       "  -0.006448040716350079,\n",
       "  -0.011425142176449299,\n",
       "  -0.04318982735276222,\n",
       "  0.029190540313720703,\n",
       "  0.0018450146308168769,\n",
       "  0.014671353623270988,\n",
       "  0.006910879630595446,\n",
       "  -0.0033666761592030525,\n",
       "  -0.0006157974130474031,\n",
       "  0.009377239271998405,\n",
       "  0.023547712713479996,\n",
       "  -0.0023760111071169376,\n",
       "  -0.0038802369963377714,\n",
       "  -0.03755968064069748,\n",
       "  0.01711869239807129,\n",
       "  0.004542793612927198,\n",
       "  -0.021151095628738403,\n",
       "  -0.017334261909127235,\n",
       "  -0.02071995846927166,\n",
       "  0.016636833548545837,\n",
       "  0.008058466017246246,\n",
       "  0.003373016370460391,\n",
       "  -0.029697760939598083,\n",
       "  -0.003192319069057703,\n",
       "  -0.014430423267185688,\n",
       "  0.0025028162635862827,\n",
       "  0.009168011136353016,\n",
       "  0.005290944129228592,\n",
       "  -0.02122717909514904,\n",
       "  -0.03104189597070217,\n",
       "  0.009313836693763733,\n",
       "  0.004539623390883207,\n",
       "  -0.008210632018744946,\n",
       "  0.01642126403748989,\n",
       "  -0.026603715494275093,\n",
       "  0.022140175104141235,\n",
       "  -0.0329439714550972,\n",
       "  0.019642114639282227,\n",
       "  -0.025741441175341606,\n",
       "  0.005566745065152645,\n",
       "  0.00047670802450738847,\n",
       "  0.013035567477345467,\n",
       "  -0.014176812954246998,\n",
       "  -0.020364902913570404,\n",
       "  -0.024384625256061554,\n",
       "  0.013771036639809608,\n",
       "  0.02769424021244049,\n",
       "  0.016345180571079254,\n",
       "  0.026299383491277695,\n",
       "  -0.0019417034927755594,\n",
       "  -0.014455785043537617,\n",
       "  -0.03139695152640343,\n",
       "  -0.011247614398598671,\n",
       "  -0.02797321043908596,\n",
       "  0.01082281768321991,\n",
       "  0.032994695007801056,\n",
       "  0.029849927872419357,\n",
       "  -0.018310660496354103,\n",
       "  -0.03340047225356102,\n",
       "  -0.02372523956000805,\n",
       "  -0.02522153966128826,\n",
       "  -0.03677348792552948,\n",
       "  -0.00388657720759511,\n",
       "  -0.0009867023909464478,\n",
       "  -0.016877762973308563,\n",
       "  0.007798515260219574,\n",
       "  -0.009732293896377087,\n",
       "  0.03870092332363129,\n",
       "  -0.008521304465830326,\n",
       "  0.007735112681984901,\n",
       "  -0.024866485968232155,\n",
       "  0.00039626602665521204,\n",
       "  -0.006489252205938101,\n",
       "  -0.02381400391459465,\n",
       "  -0.006413169205188751,\n",
       "  -0.01869107596576214,\n",
       "  -0.00036912181531079113,\n",
       "  -0.004102145787328482,\n",
       "  0.016294458881020546,\n",
       "  0.01737230271100998,\n",
       "  -0.012908762320876122,\n",
       "  -0.0009763994603417814,\n",
       "  0.016294458881020546,\n",
       "  -0.006714331451803446,\n",
       "  0.0012466529151424766,\n",
       "  0.017423024401068687,\n",
       "  0.02238110452890396,\n",
       "  0.005148288328200579,\n",
       "  0.010087347589433193,\n",
       "  -0.0034205683041363955,\n",
       "  -0.00885733775794506,\n",
       "  0.00022587164130527526,\n",
       "  -0.017727356404066086,\n",
       "  -0.017942925915122032,\n",
       "  -0.016231056302785873,\n",
       "  -0.004114826209843159,\n",
       "  -0.017980966717004776,\n",
       "  0.016154972836375237,\n",
       "  0.03347655385732651,\n",
       "  -0.027516713365912437,\n",
       "  -0.01635786145925522,\n",
       "  -0.048845335841178894,\n",
       "  0.02153151109814644,\n",
       "  -0.031194061040878296,\n",
       "  0.000998590374365449,\n",
       "  -0.009358218871057034,\n",
       "  0.0008107603061944246,\n",
       "  -0.02873404137790203,\n",
       "  -0.021011609584093094,\n",
       "  0.005931309890002012,\n",
       "  -0.04017186537384987,\n",
       "  -0.027516713365912437,\n",
       "  -0.006758713163435459,\n",
       "  -0.013200413435697556,\n",
       "  -0.008438881486654282,\n",
       "  0.002777032321318984,\n",
       "  0.022901006042957306,\n",
       "  -0.008064806461334229,\n",
       "  -0.010480443947017193,\n",
       "  -0.01776539906859398,\n",
       "  -0.004403308033943176,\n",
       "  -0.0022872474510222673,\n",
       "  0.03659595921635628,\n",
       "  0.030357148498296738,\n",
       "  0.0033920372370630503,\n",
       "  -0.006581186316907406,\n",
       "  0.014709394425153732,\n",
       "  -0.03474460542201996,\n",
       "  0.00802676472812891,\n",
       "  -0.0009011089568957686,\n",
       "  -0.010182451456785202,\n",
       "  -0.012179632671177387,\n",
       "  0.01610425114631653,\n",
       "  -0.021379344165325165,\n",
       "  -0.013251136057078838,\n",
       "  -0.03159983828663826,\n",
       "  -0.015736516565084457,\n",
       "  -0.0064353602938354015,\n",
       "  0.022736160084605217,\n",
       "  0.022533271461725235,\n",
       "  0.21932214498519897,\n",
       "  -0.006695310585200787,\n",
       "  0.00899682380259037,\n",
       "  0.027821045368909836,\n",
       "  0.001795877586118877,\n",
       "  -0.005043673794716597,\n",
       "  0.008261353708803654,\n",
       "  0.02434658445417881,\n",
       "  -0.008946102112531662,\n",
       "  0.009979563765227795,\n",
       "  0.00959914829581976,\n",
       "  -0.005956670735031366,\n",
       "  -0.03885309025645256,\n",
       "  -0.0016405413625761867,\n",
       "  -0.004628387279808521,\n",
       "  0.0007334884139709175,\n",
       "  -0.021721718832850456,\n",
       "  -0.01810777187347412,\n",
       "  -0.010543846525251865,\n",
       "  -0.00040498387534171343,\n",
       "  0.00796970259398222,\n",
       "  -0.010746734216809273,\n",
       "  -0.008793935179710388,\n",
       "  -0.016966525465250015,\n",
       "  0.04138919338583946,\n",
       "  0.00041687185876071453,\n",
       "  -0.009529405273497105,\n",
       "  0.002054243115708232,\n",
       "  0.0059630111791193485,\n",
       "  -0.0112729761749506,\n",
       "  -0.011488544754683971,\n",
       "  0.01810777187347412,\n",
       "  -0.0028689659666270018,\n",
       "  0.014772797003388405,\n",
       "  -0.051888659596443176,\n",
       "  0.00493271928280592,\n",
       "  0.03243675082921982,\n",
       "  -0.011374419555068016,\n",
       "  0.014278257265686989,\n",
       "  0.02619794011116028,\n",
       "  0.0037249005399644375,\n",
       "  2.3602595319971442e-05,\n",
       "  0.011818237602710724,\n",
       "  -0.009028525091707706,\n",
       "  -0.029139818623661995,\n",
       "  0.02974848262965679,\n",
       "  ...],\n",
       " 'response': 'Ingesting the following content: To make a classic apple pie, mix 2  cups of flour,  teaspoon of salt, and 1 tablespoon of sugar with 1 cup of cold butter until crumbly, then add 6-8 tablespoons of ice water to form a dough. Refrigerate for an hour. For the filling, toss 6-8 sliced apples with  cup of sugar, 2 tablespoons of flour, 1 teaspoon of cinnamon, and 1 tablespoon of lemon juice. Preheat the oven to 425F (220C), fill the bottom crust with the apple mixture, cover with the top crust, and bake for 15 minutes, then reduce to 350F (175C) for 35-45 minutes. Let cool for 2 hours before serving. Enjoy!\\nThank you, I have learned this content (161 tokens).',\n",
       " 'status': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tokens used in iteration 3: 210 training tokens'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Final TeachToken Volume Report\n",
      "\n",
      " Token Volume Report  (Stage #4)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 50262\n",
      "The count of monthly inference/query tokens used are: 1420075\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #3)  Current End (Stage #4):\n",
      "{'teach_tokens_diff': 782, 'query_tokens_diff': 0}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #3)         49480       1420075\n",
      "End (Stage #4)           50262       1420075\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  4)</th>\n",
       "      <td>782</td>\n",
       "      <td>1992</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (3  4)</th>\n",
       "      <td>782</td>\n",
       "      <td>0</td>\n",
       "      <td> Changed</td>\n",
       "      <td> No Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  4)               782              1992          Changed   \n",
       "Prior vs End (3  4)               782                 0          Changed   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  4)          Changed  \n",
       "Prior vs End (3  4)        No Change  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 782, 'query_tokens_used': 1992}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 782, 'query_tokens_used_this_stage': 0}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "#  Helpers\n",
    "# -----------------------------\n",
    "def tokenize_and_display(text: str, client: ask_sage_client) -> int:\n",
    "    \"\"\"Tokenize *text*, display the count, and return it.\"\"\"\n",
    "    result = client.tokenizer(text)['response']\n",
    "    display(f\"Estimated tokens: {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_text(\n",
    "    text: str,\n",
    "    client: ask_sage_client,\n",
    "    *,\n",
    "    context: str | None = None,\n",
    "    dataset_entry: str | None = None,\n",
    "    skip_vectordb: bool = False,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Train *text* with optional context & dataset hints.\n",
    "    Returns **cumulative** monthly teachtoken usage after this train.\n",
    "    \"\"\"\n",
    "    train_data = client.train(\n",
    "        text,\n",
    "        force_dataset=dataset_entry,\n",
    "        context=context,\n",
    "        skip_vectordb=skip_vectordb,\n",
    "    )\n",
    "    display(train_data)\n",
    "    return client.count_monthly_teach_tokens()['response']\n",
    "\n",
    "\n",
    "def print_token_delta(\n",
    "    label: str,\n",
    "    start: int,\n",
    "    end: int,\n",
    ") -> None:\n",
    "    delta = end - start\n",
    "    display(f\"{label}: {delta} training tokens\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "#  Content to process\n",
    "# -----------------------------\n",
    "contents: List[str] = [\n",
    "    # 0  soldering\n",
    "    (\"Soldering Instructions\", \"\"\"To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder.\"\"\"),\n",
    "    # 1  arduino\n",
    "    (\"Arduino Microcontroller Information\", \"\"\"Arduino is an open-source electronics platform based on easy-to-use hardware and software. It consists of a physical programmable circuit board (often referred to as a microcontroller) and a piece of software, or IDE (Integrated Development Environment), that runs on your computer. You use the IDE to write and upload computer code to the physical board. The platform is designed to enable users of all ages to create interactive electronic objects and projects that can sense and control physical devices. Arduino boards can read inputs - light on a sensor, a finger on a button, or a Twitter message - and turn it into an output - activating a motor, turning on an LED, publishing something online. You can tell your board what to do by sending a set of instructions to the microcontroller on the board. Arduino is widely used in robotics, home automation, scientific experimentation, and artistic projects.\"\"\"),\n",
    "    # 2  apple pie\n",
    "    (\"ApplePie Instructions\", \"\"\"To make a classic apple pie, mix 2  cups of flour,  teaspoon of salt, and 1 tablespoon of sugar with 1 cup of cold butter until crumbly, then add 6-8 tablespoons of ice water to form a dough. Refrigerate for an hour. For the filling, toss 6-8 sliced apples with  cup of sugar, 2 tablespoons of flour, 1 teaspoon of cinnamon, and 1 tablespoon of lemon juice. Preheat the oven to 425F (220C), fill the bottom crust with the apple mixture, cover with the top crust, and bake for 15 minutes, then reduce to 350F (175C) for 35-45 minutes. Let cool for 2 hours before serving. Enjoy!\"\"\"),\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "#  1. Quick token estimates\n",
    "# -----------------------------\n",
    "for _, text in contents:\n",
    "    tokenize_and_display(text, ask_sage_client)\n",
    "\n",
    "# -----------------------------\n",
    "#  2. Training runs\n",
    "# -----------------------------\n",
    "training_plan: List[Tuple[str, str | None, bool]] = [\n",
    "    # (dataset_entry, context, skip_vectordb)\n",
    "    (dataset_entry_1, contents[0][0], False),   # add to dataset\n",
    "    (dataset_entry_1, contents[1][0], True),    # *dont* store in vectordb\n",
    "    (None,               contents[2][0], False),  # no dataset specified\n",
    "]\n",
    "\n",
    "start_tokens = ask_sage_client.count_monthly_teach_tokens()['response']\n",
    "previous_tokens = start_tokens\n",
    "\n",
    "for idx, ((title, text), (ds_entry, ctx, skip)) in enumerate(zip(contents, training_plan), start=1):\n",
    "    print(f\" Iteration {idx}  {title}\")\n",
    "    print(f\"  Dataset: {ds_entry}\")\n",
    "    print(f\"  Context: {ctx}\")\n",
    "    after_train = train_text(\n",
    "        text,\n",
    "        ask_sage_client,\n",
    "        context=ctx,\n",
    "        dataset_entry=ds_entry,\n",
    "        skip_vectordb=skip,\n",
    "    )\n",
    "    print_token_delta(f\"Tokens used in iteration {idx}\", previous_tokens, after_train)\n",
    "    previous_tokens = after_train\n",
    "\n",
    "# -----------------------------\n",
    "#  3. Final usage report\n",
    "# -----------------------------\n",
    "print(\"\\n  Final TeachToken Volume Report\")\n",
    "print_token_volume_report(ask_sage_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train` endpoint utilizes `teach tokens` to generate vector embeddings for the provided text content. Importantly, only the first example ingests the content into a dataset, while subsequent examples do not. However, all examples still return embeddings for the content.\n",
    "\n",
    "To verify this behavior, visit your Ask Sage account, select the dataset created, and perform the following prompts (one at a time). You'll observe that only the first example has its content ingested into the dataset. \n",
    "\n",
    "```python\n",
    "\n",
    "prompt_1 = \"Provide me with instructions on how to solder a circuit board.\"\n",
    "\n",
    "prompt_2 = \"What is an Arduino microcontroller?\"\n",
    "\n",
    "prompt_3 = \"Provide me with instructions on how to make an Apple Pie.\"\n",
    "\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "Because question 1 will use embeddings stored in the dataset, the model will be able to provide a more accurate response and moreover users will see the explainability feature in Ask Sage showing the content that was used to generate the response.\n",
    "</div>\n",
    "\n",
    "To see the dataset name execute the cell below: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "The dataset name for this step was: 1-jupynotebk-asksage-ex-52\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------\")\n",
    "print(f\"The dataset name for this step was: {dataset_name_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Train With File\n",
    "\n",
    "This endpoint is used to create an embedding of the file and store it within a `Ask Sage dataset` based on the provided file. The files that can be ingested are listed below: (Note: The file types listed here is not exhaustive and continually updated by Ask Sage Team - if you run into issues with file types, please reach out to Ask Sage support for more information.)\n",
    "\n",
    "- Format supported: zip, pdf, xlsx, pptx, docx, ppt, csv, cc, sql, cs, hh, c, php, js, py, html, xml, msg, odt, epub, eml, rtf, txt, doc, json, md, jpeg, jpg, png, tsv (50MB)\n",
    "\n",
    "- Audio Format supported: mp3, mp4, mpeg, mpga, m4a, wav, webm (500MB max)\n",
    "\n",
    "The files uploaded will be vectorized and only the embeddings will be stored. The files will not be stored on Ask Sage.\n",
    "\n",
    "\n",
    "Reminder of the following: \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> FAQ: <br>\n",
    "\n",
    "1) What Embedding Model is used in the Ask Sage API? <br>\n",
    "- Currently uses the embedding model: text-embedding-ada-002, 2 <br>\n",
    "\n",
    "2) Is there a limit to the number of tokens/volume of data that can be ingested into a dataset? <br>\n",
    "- Two limits to be aware of: <br>\n",
    "  - File Size as noted above <br>\n",
    "  - The volume of tokens available for the user in the current month. <br>\n",
    "  - Technically there is no limit to the number of embeddings that can be ingested into a dataset, but the user must be aware of the token usage. <br>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 16:43:21,166 - INFO - Dataset target: user_custom_34125_2-jupynotebk-asksage-ex-9_content\n",
      "2025-05-08 16:43:21,167 - INFO -   Ingesting training_image_example.jpg \n",
      "2025-05-08 16:43:30,512 - INFO - Finished training_image_example.jpg  teach =566, query =777 | API said: Successfully imported\n",
      "2025-05-08 16:43:30,513 - INFO -   Ingesting random_story_genAI.pdf \n",
      "2025-05-08 16:43:32,627 - INFO - Finished random_story_genAI.pdf  teach =575, query =0 | API said: Successfully imported\n",
      "2025-05-08 16:43:32,629 - INFO -   Ingesting random_story_genAI_word_doc.docx \n",
      "2025-05-08 16:43:34,559 - INFO - Finished random_story_genAI_word_doc.docx  teach =571, query =0 | API said: Successfully imported\n",
      "2025-05-08 16:43:34,559 - INFO -   Ingesting Ask_Sage_Intro.mp3 \n",
      "2025-05-08 16:43:42,077 - INFO - Finished Ask_Sage_Intro.mp3  teach =431, query =1300 | API said: Successfully imported\n",
      "2025-05-08 16:43:42,084 - INFO -   All done  total teach tokens used: 2143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>teach_tokens</th>\n",
       "      <th>query_tokens</th>\n",
       "      <th>api_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_image_example.jpg</td>\n",
       "      <td>566</td>\n",
       "      <td>777</td>\n",
       "      <td>Successfully imported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_story_genAI.pdf</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>Successfully imported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_story_genAI_word_doc.docx</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>Successfully imported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ask_Sage_Intro.mp3</td>\n",
       "      <td>431</td>\n",
       "      <td>1300</td>\n",
       "      <td>Successfully imported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file  teach_tokens  query_tokens  \\\n",
       "0        training_image_example.jpg           566           777   \n",
       "1            random_story_genAI.pdf           575             0   \n",
       "2  random_story_genAI_word_doc.docx           571             0   \n",
       "3                Ask_Sage_Intro.mp3           431          1300   \n",
       "\n",
       "             api_message  \n",
       "0  Successfully imported  \n",
       "1  Successfully imported  \n",
       "2  Successfully imported  \n",
       "3  Successfully imported  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #5)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422152\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #4)  Current End (Stage #5):\n",
      "{'teach_tokens_diff': 2143, 'query_tokens_diff': 2077}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #4)         50262       1420075\n",
      "End (Stage #5)           52405       1422152\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  5)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4069</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (4  5)</th>\n",
       "      <td>2143</td>\n",
       "      <td>2077</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  5)              2925              4069          Changed   \n",
       "Prior vs End (4  5)              2143              2077          Changed   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  5)          Changed  \n",
       "Prior vs End (4  5)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4069}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 2143, 'query_tokens_used_this_stage': 2077}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# === Logging Configuration ===\n",
    "LOG_FORMAT = \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"  # Format for log messages\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)  # Set logging level to INFO and apply format\n",
    "logger = logging.getLogger(\"asksagetraining\")  # Create a logger instance for the \"ask-sage-training\" module\n",
    "\n",
    "# \n",
    "# Helper utilities\n",
    "# \n",
    "def _current_token_counts(client) -> Tuple[int, int]:\n",
    "    \"\"\"Return (teach_tokens, query_tokens).\"\"\"\n",
    "    teach = client.count_monthly_teach_tokens().get(\"response\", 0)\n",
    "    query = client.count_monthly_tokens().get(\"response\", 0)\n",
    "    return teach, query\n",
    "\n",
    "\n",
    "def _iter_training_files(folder: Union[str, Path]) -> List[Path]:\n",
    "    \"\"\"Return every eligible file inside *folder*.\"\"\"\n",
    "    p = Path(folder).expanduser().resolve()\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"{p} does not exist\")\n",
    "\n",
    "    return [\n",
    "        f for f in p.iterdir()\n",
    "        if f.is_file() and not f.name.startswith(\".\") and f.name != \"query_with_file\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# \n",
    "# Public API\n",
    "# \n",
    "def train_directory(\n",
    "    data_dir: Union[str, Path],\n",
    "    dataset_name: str,\n",
    "    client,\n",
    ") -> Tuple[pd.DataFrame, int]:\n",
    "    \"\"\"\n",
    "    Ingest every file in *data_dir* into AskSage and return:\n",
    "\n",
    "        (results_dataframe, total_teach_tokens_used)\n",
    "\n",
    "    The DataFrame has columns:\n",
    "        ['file', 'teach_tokens', 'query_tokens', 'api_message']\n",
    "    \"\"\"\n",
    "    try:\n",
    "        files = _iter_training_files(data_dir)\n",
    "    except FileNotFoundError as exc:\n",
    "        logger.error(exc)\n",
    "        return pd.DataFrame(), 0\n",
    "\n",
    "    if not files:\n",
    "        logger.warning(\"No eligible files found in %s\", data_dir)\n",
    "        return pd.DataFrame(), 0\n",
    "\n",
    "    rows: List[Dict] = []\n",
    "    total_teach_tokens = 0\n",
    "\n",
    "    for file in files:\n",
    "        logger.info(\"  Ingesting %s \", file.name)\n",
    "        teach_before, query_before = _current_token_counts(client)\n",
    "\n",
    "        resp = client.train_with_file(str(file), dataset_name)\n",
    "\n",
    "        teach_after, query_after = _current_token_counts(client)\n",
    "        teach_used = teach_after - teach_before\n",
    "        query_used = query_after - query_before\n",
    "        total_teach_tokens += teach_used\n",
    "\n",
    "        rows.append(\n",
    "            dict(\n",
    "                file=file.name,\n",
    "                teach_tokens=teach_used,\n",
    "                query_tokens=query_used,\n",
    "                api_message=resp.get(\"response\", \"no message\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            \"Finished %s  teach =%d, query =%d | API said: %s\",\n",
    "            file.name, teach_used, query_used, rows[-1][\"api_message\"]\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    logger.info(\"  All done  total teach tokens used: %d\", total_teach_tokens)\n",
    "    return df, total_teach_tokens\n",
    "\n",
    "\n",
    "# \n",
    "# Example usage\n",
    "# \n",
    "if __name__ == \"__main__\":\n",
    "    DATA_DIR = \"data/\"\n",
    "    logger.info(\"Dataset target: %s\", dataset_entry_2)\n",
    "\n",
    "    summary_df, grand_total = train_directory(DATA_DIR, dataset_entry_2, ask_sage_client)\n",
    "\n",
    "    # Pretty print or write to CSV/Excel as needed\n",
    "    print(\"\\nSummary:\")\n",
    "    display(summary_df)\n",
    "\n",
    "    # Optional: persist for later inspection\n",
    "    # summary_df.to_csv(\"training_summary.csv\", index=False)\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print_token_volume_report(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the `train` endpoint, the `train_with_file` endpoint will also use `teach tokens` to create the vector embeddings for the content in the file, however, a dataset will be required to store the embeddings.\n",
    "\n",
    "As a reminder, any audio or image files will use `inference tokens` to process the file to create text content from the file. Then the text content will be used to create the vector embeddings which will be stored in the dataset and will use `teach tokens` to store the embeddings in the dataset.\n",
    "\n",
    "---------------\n",
    "\n",
    "You can go to your account on Ask Sage now and select the dataset and perform the following prompts to see how Ask Sage is able to reference the content from the file that was ingested into the dataset.\n",
    "\n",
    "```python\n",
    "\n",
    "prompt_1 = \"What can you tell me about Ask Sage API?\" \n",
    "\n",
    "prompt_2 = \"Can you describe if there was snow and mountain scenery?\"\n",
    "\n",
    "prompt_3 = \"What lessons did Whiskers learn from his encounters with the Wise Old Owl, Friendly Fox, and Jovial Rabbit?\" # Note: two of the files are the same content just different file types.\n",
    "\n",
    "```\n",
    "\n",
    "Each prompt will show references from the dataset that was appended to the prompt.\n",
    "\n",
    "To see the dataset name execute the cell below: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "The dataset name for this step was: 2-jupynotebk-asksage-ex-9\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------\")\n",
    "print(f\"The dataset name for this step was: {dataset_name_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Assign Dataset\n",
    "\n",
    "This endpoint is used to assign a dataset to a specific user - This will allow another user to use the dataset but only sharing between users is permitted if they are from the same organization. If you wish to elevate the permissions of the dataset, you will need to do so within the Ask Sage platform, such as `Edit`, or `Admin` access.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> The `assign_dataset` endpoint is useful in being able to share datasets between users within the same organization. Thus not having to create multiple datasets for the same content or have users upload the same content to their own datasets. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tha is being Shared is: user_custom_34125_2-jupynotebk-asksage-ex-9_content\n",
      "API response for assigning dataset to mark-espinoza-test-02@asksage.ai: {'response': 'OK', 'status': 200}\n",
      "API response for assigning dataset to mark_doesnotexist@asksage.ai: {'response': 'No account.', 'status': 410}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset tha is being Shared is: {dataset_entry_2}\") # Print the dataset that is being shared\n",
    "\n",
    "#######\n",
    "# Call to assign_dataset method\n",
    "assign_dataset_data = ask_sage_client.assign_dataset(dataset_entry_2, 'email@email.com') # Replace the email with who you want to assign the dataset to - this will only work if the user is in the same organization\n",
    "# display(assign_dataset_data) # Display the response from the API\n",
    "\n",
    "#######\n",
    "# Function to share a dataset with a list of emails\n",
    "\n",
    "def share_dataset_with_emails(dataset_entry, email_list):\n",
    "    for email in email_list:\n",
    "        assign_dataset_data = ask_sage_client.assign_dataset(dataset_entry, email)\n",
    "        print(f\"API response for assigning dataset to {email}: {assign_dataset_data}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "email_list = ['mark-espinoza-test-02@asksage.ai', 'mark_doesnotexist@asksage.ai']  # Replace with actual email addresses and for demo purposes I added a non-existing email to show an error\n",
    "share_dataset_with_emails(dataset_entry_2, email_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Query\n",
    "\n",
    "This endpoint is used to interact with the `/query `endpoint of the Ask Sage API. It is where users can interact with the various models available on the Ask Sage platform.\n",
    "\n",
    "We will provide examples of how to use these endpoints and various parameters that can be used to interact with the models. Do note that this will only be high-level examples. We will be working on more detailed examples in the future.\n",
    "\n",
    "\n",
    "```python\n",
    "def query(self, message, persona='default', dataset='all', limit_references=None, temperature=0.0, live=0, model='openai_gpt', system_prompt=None, file=None, tools=None, tool_choice=None):\n",
    "        \"\"\"\n",
    "    Interact with the /query endpoint of the Ask Sage API.\n",
    "\n",
    "    Parameters:\n",
    "    message (str): The message to be processed by the service. Message can be a single message or an array of messages following this JSON format: [{ user: \"me\", message: \"Who is Nic Chaillan?\"}, { user: \"gpt\", message: \"Nic Chaillan is...\"}]\n",
    "    persona (str, optional): The persona to be used. Default is 'default'. Get the list of available personas using get_personas.\n",
    "    dataset (str, optional): The dataset to be used. Default is 'all'. Other options include 'none' or your custom dataset, must follow the following format: user_content_USERID_DATASET-NAME_content. Replace USERID by user ID and DATASET-NAME by the name of your dataset.\n",
    "    limit_references (int, optional): The maximum number of references (embeddings) to be used. Default is None, meaning all references will be used. Use 1 to limit to 1 reference or 0 to remove embeddings. You can also set dataset to \"none\"\n",
    "    temperature (float, optional): The temperature to be used for the generation. Default is 0.0. Higher values (up to 1.0) make the output more random.\n",
    "    live (int, optional): Whether to use live mode. Default is 0. Live = 1 will pull 10 results from Bing and 2 will also pull the top 2 web pages summaries using our Web crawler.\n",
    "    model (str, optional): The model to be used. Default is 'openai_gpt'. Other options include cohere, google-bison, gpt4, gpt4-32k, gpt35-16k, claude2, openai_gpt (gpt3.5), davinci, llma2.\n",
    "    system_prompt (str, optional): Overrides the system prompt from Ask Sage (only use if you know what you are doing).\n",
    "    tools and tool_choice (optional): These use OpenAI format for tools.\n",
    "\n",
    "    Returns:\n",
    "    dict: The response from the service.\n",
    "    \"\"\"\n",
    "        file_obj = None\n",
    "        files = None\n",
    "        if file != None:\n",
    "            file_obj = open(file, 'rb')\n",
    "            files = {'file': file_obj}\n",
    "\n",
    "        if type(message) == list:\n",
    "            message = json.dumps(message)\n",
    "        elif type(message) == str:\n",
    "            message = message\n",
    "        else:\n",
    "            message = json.dumps(message)\n",
    "\n",
    "        if tools != None:\n",
    "            tools = json.dumps(tools)\n",
    "        if tool_choice != None:\n",
    "            tool_choice = json.dumps(tool_choice)\n",
    "\n",
    "        data = {\n",
    "            'message': message,\n",
    "            'persona': persona,\n",
    "            'dataset': dataset,\n",
    "            'limit_references': limit_references,\n",
    "            'temperature': temperature,\n",
    "            'live': live,\n",
    "            'model': model,\n",
    "            'system_prompt': system_prompt,\n",
    "            'tools': tools,\n",
    "            'tool_choice': tool_choice\n",
    "        }\n",
    "\n",
    "        ret = self._request('POST', 'query', files = files, data=data)        \n",
    "        if file_obj != None:\n",
    "            file_obj.close()\n",
    "        return ret\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Setup</h4>\n",
    "\n",
    "Define a function where we set most settings to either default or None. This will allow us to only set the parameters that we want to change for each example as we go and show how to use the parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_sage_question(message, persona='default', dataset='none', limit_references=0, temperature=0.0, live=0, model='gpt-4o-mini', system_prompt=None):\n",
    "    response = ask_sage_client.query(message, persona, dataset, limit_references, temperature, live, model, system_prompt) # Query the AskSage API with the question\n",
    "    message = response['message'] # Extract the message from the response\n",
    "    references = response['references'] # Extract the references from the response\n",
    "    return message, references # Return the message and references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Persona, System Prompt, Message, & Temperature\n",
    "\n",
    "We will first focus on the basic parameters that are used in the `query` endpoint. These parameters are the primary backbone of the `query` endpoint and are used to interact with the models available on the Ask Sage platform. These are `model`, `persona`, `system_prompt`, `message`, and `temperature`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>model</h4>\n",
    "\n",
    "Users can specify the model for generating responses, with 'gpt-4o-mini' as the with the function defined above. To explore available models, utilize the `get-models` endpoint as previously described and presented in the notebook. \n",
    "\n",
    "When defining the model, make sure to use the model ID as shown in the output of the `get_models` endpoint.\n",
    "\n",
    "```python\n",
    "model = 'gpt-4o-mini-gov'\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> To ensure accuracy in your work, we recommend reviewing the prompt logs to confirm that the intended model is being utilized. Users often overlook specifying the model, resulting in the default model being used, which may not align with your expectations. Always double-check to avoid unintended outcomes.\n",
    "</div>\n",
    "\n",
    "------\n",
    "\n",
    "<h4> message </h4>\n",
    "\n",
    "The `message` represents the prompt that the model will process to generate an inference response. It consists of the questions or commands directed at the model. It's important to remember that the model generates responses based on its training data corpus, so asking relevant questions is essential. The model will not be able to answer anything that is not publicly available or outside its training data unless a user passes a file or utilizes an Ask Sage dataset to perform RAG(Retrieval-Augmented Generation) to generate a response. \n",
    "\n",
    "```python\n",
    "message = \"How far is the moon from the Earth?\"\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> When using an off-the-shelf model, expect it to handle a wide range of inquiries, but do not assume expertise in every field. Each model has its own limitations and is designed for specific use cases, making some more suitable for tasks like code generation or text generation.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: What is a soldering iron? and can you give me details on how it is used with microcontrollers? \n",
      "--------------------------------------------------\n",
      " Default Model Response: \n",
      "\n",
      "A soldering iron is a hand-held tool used to melt solder, which is a fusible metal alloy, to join together electronic components on a circuit board. The soldering iron typically consists of a metal tip that heats up when electricity passes through it, allowing the user to apply heat to the solder and components.\n",
      "\n",
      "### How to Use a Soldering Iron with Microcontrollers\n",
      "\n",
      "1. **Gather Materials**: \n",
      "   - Soldering iron\n",
      "   - Solder (usually a tin-lead or lead-free alloy)\n",
      "   - Microcontroller (e.g., Arduino, Raspberry Pi)\n",
      "   - Circuit board or breadboard\n",
      "   - Wire cutters/strippers\n",
      "   - Safety glasses\n",
      "\n",
      "2. **Prepare the Workspace**: \n",
      "   - Ensure you have a clean, well-lit area to work in.\n",
      "   - Use a soldering mat or a heat-resistant surface to protect your workspace.\n",
      "\n",
      "3. **Heat the Soldering Iron**: \n",
      "   - Plug in the soldering iron and allow it to heat up for a few minutes. Most soldering irons have a temperature range of 350C to 400C (662F to 752F).\n",
      "\n",
      "4. **Insert Components**: \n",
      "   - Place the microcontroller and any other components (resistors, capacitors, etc.) onto the circuit board. Ensure they are oriented correctly according to the circuit design.\n",
      "\n",
      "5. **Soldering Process**:\n",
      "   - **Tin the Tip**: Before soldering, apply a small amount of solder to the tip of the soldering iron to improve heat transfer.\n",
      "   - **Heat the Joint**: Place the tip of the soldering iron on the joint where the component lead meets the circuit board pad. Hold it there for a second or two to heat both the lead and the pad.\n",
      "   - **Apply Solder**: Feed solder into the joint while keeping the soldering iron in place. The solder should flow around the lead and pad, creating a solid connection.\n",
      "   - **Remove the Iron**: Take away the soldering iron and allow the joint to cool for a few seconds. The solder should solidify, forming a strong bond.\n",
      "\n",
      "6. **Inspect the Joint**: \n",
      "   - Check the solder joint for a shiny, smooth appearance. A good solder joint should have a \"volcano\" shape and should not be dull or have cracks.\n",
      "\n",
      "7. **Clean Up**: \n",
      "   - Turn off the soldering iron and clean the tip with a damp sponge or brass sponge to remove any residual solder. Dispose of any waste materials properly.\n",
      "\n",
      "### Safety Tips\n",
      "- Always wear safety glasses to protect your eyes from solder splashes.\n",
      "- Work in a well-ventilated area to avoid inhaling fumes from the solder.\n",
      "- Be cautious of the hot soldering iron to prevent burns.\n",
      "\n",
      "Using a soldering iron with microcontrollers is essential for building and prototyping electronic projects, allowing you to create custom circuits and devices.\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "examples_prompt = \"What is a soldering iron? and can you give me details on how it is used with microcontrollers? \"\n",
    "\n",
    "print(f\" Question: {examples_prompt}\")\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Get response from the default model\n",
    "response, references = ask_sage_question(message=examples_prompt)\n",
    "print(f\" Default Model Response: {response}\")\n",
    "print(f\" References: {references}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #6)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422184\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #5)  Current End (Stage #6):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 32}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #5)         52405       1422152\n",
      "End (Stage #6)           52405       1422184\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  6)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4101</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (5  6)</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  6)              2925              4101          Changed   \n",
       "Prior vs End (5  6)                 0                32        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  6)          Changed  \n",
       "Prior vs End (5  6)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4101}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 32}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Different Model Response: \n",
      "\n",
      "A soldering iron is a handheld tool used to heat solder, typically to melt it so it can join two metal workpieces. It's composed of a heated metal tip and an insulated handle [1].\n",
      "\n",
      "Here's how soldering irons are used with microcontrollers:\n",
      "\n",
      "**Purpose:**\n",
      "\n",
      "*   **Electrical Connections:** Soldering creates permanent electrical connections between components on a circuit board (PCB) and the microcontroller. This is essential for building functional electronic circuits [2].\n",
      "*   **Component Mounting:** Microcontrollers and other components (resistors, capacitors, LEDs, etc.) are physically mounted onto a PCB and then soldered to the copper pads to ensure they are electrically connected to the circuit [3].\n",
      "*   **Wire Attachment:** Soldering is used to attach wires to the microcontroller or other components for power, communication, or input/output signals [4].\n",
      "\n",
      "**Materials Needed:**\n",
      "\n",
      "*   **Soldering Iron:** Choose an iron with adjustable temperature control for versatility.\n",
      "*   **Solder:** Typically a tin/lead alloy (though lead-free options are increasingly common). Rosin-core solder is preferred for electronics work [5].\n",
      "*   **Microcontroller and Components:** The microcontroller and other electronic components you want to connect.\n",
      "*   **Printed Circuit Board (PCB) or Breadboard:** A PCB provides a stable platform for soldering components.\n",
      "*   **Sponge:** To clean the soldering iron tip.\n",
      "*   **Flux (Optional):** Flux helps clean the metal surfaces and improves solder flow.\n",
      "*   **Helping Hands (Optional):** A tool with clips to hold components in place while soldering.\n",
      "*   **Safety Glasses:** To protect your eyes from solder splatter.\n",
      "\n",
      "**Steps for Soldering a Microcontroller:**\n",
      "\n",
      "1.  **Preparation:**\n",
      "    *   Clean the soldering iron tip with a damp sponge. A clean tip ensures good heat transfer.\n",
      "    *   Tin the tip: Apply a small amount of solder to the tip to create a thin, shiny coating. This helps with heat transfer to the components [6].\n",
      "    *   Prepare the components: Make sure the component leads are clean and straight.\n",
      "    *   Secure the components: Place the microcontroller and other components on the PCB, ensuring the leads pass through the appropriate holes. Use helping hands or tape to hold them in place.\n",
      "\n",
      "2.  **Soldering:**\n",
      "    *   Heat the pad and lead: Touch the soldering iron tip to both the component lead and the copper pad on the PCB simultaneously. Heat them for a few seconds.\n",
      "    *   Apply solder: Bring the solder to the joint where the lead and pad meet. The heat from the iron will melt the solder, and it should flow smoothly around the lead and onto the pad.\n",
      "    *   Remove solder and iron: Once enough solder has flowed to create a good connection (a small, shiny fillet), remove the solder first, then the soldering iron.\n",
      "    *   Let the joint cool: Allow the solder joint to cool undisturbed. This is crucial for a strong, reliable connection.\n",
      "\n",
      "3.  **Inspection:**\n",
      "    *   Visually inspect the solder joint. A good solder joint should be shiny, smooth, and have a concave shape. Avoid cold solder joints (dull, grainy), which indicate a poor connection [7].\n",
      "    *   Remove excess lead: Clip any excess component lead extending beyond the solder joint.\n",
      "\n",
      "**Tips for Success:**\n",
      "\n",
      "*   **Temperature Control:** Use the correct temperature setting on your soldering iron. Too low, and the solder won't melt properly; too high, and you can damage components or the PCB [8].\n",
      "*   **Cleanliness:** Keep the soldering iron tip clean and the components free of dirt and oxidation.\n",
      "*   **Practice:** Soldering takes practice. Start with simple projects to develop your skills.\n",
      "*   **Ventilation:** Solder fumes can be harmful. Work in a well-ventilated area.\n",
      "\n",
      "**Safety Precautions:**\n",
      "\n",
      "*   Always wear safety glasses to protect your eyes.\n",
      "*   Be careful when handling a hot soldering iron.\n",
      "*   Work in a well-ventilated area to avoid inhaling solder fumes.\n",
      "*   Wash your hands after soldering, especially if using lead-based solder.\n",
      "\n",
      "**References:**\n",
      "\n",
      "*   [1] \"Soldering Iron Basics.\" *Electronics Tutorials*. \\[Online] Available: [https://www.electronics-tutorials.ws/blog/soldering-iron.html](https://www.electronics-tutorials.ws/blog/soldering-iron.html)\n",
      "*   [2] \"Why is Soldering Important in Electronics?\" *PCB Cart*. \\[Online] Available: [https://www.pcbcart.com/article/pcb-assembly/Why_is_Soldering_Important_in_Electronics.html](https://www.pcbcart.com/article/pcb-assembly/Why_is_Soldering_Important_in_Electronics.html)\n",
      "*   [3] \"How to Solder Electronic Components.\" *Instructables*. \\[Online] Available: [https://www.instructables.com/How-to-Solder-Electronic-Components/](https://www.instructables.com/How-to-Solder-Electronic-Components/)\n",
      "*   [4] \"Soldering Wires: A Comprehensive Guide.\" *Make:. \\[Online] Available: [https://makezine.com/article/skills/soldering-wires-a-comprehensive-guide/](https://makezine.com/article/skills/soldering-wires-a-comprehensive-guide/)\n",
      "*   [5] \"Choosing the Right Solder for Electronics.\" *Adafruit*. \\[Online] Available: [https://learn.adafruit.com/adafruit-guide-excellent-soldering/choosing-solder](https://learn.adafruit.com/adafruit-guide-excellent-soldering/choosing-solder)\n",
      "*   [6] \"How to Tin a Soldering Iron Tip.\" *Wikihow*. \\[Online] Available: [https://www.wikihow.com/Tin-a-Soldering-Iron-Tip](https://www.wikihow.com/Tin-a-Soldering-Iron-Tip)\n",
      "*   [7] \"How to Identify and Avoid Cold Solder Joints.\" *All About Circuits*. \\[Online] Available: [https://www.allaboutcircuits.com/technical-articles/how-to-identify-and-avoid-cold-solder-joints/](https://www.allaboutcircuits.com/technical-articles/how-to-identify-and-avoid-cold-solder-joints/)\n",
      "*   [8] \"Soldering Temperature Guide.\" *Circuit Basics*. \\[Online] Available: [https://www.circuitbasics.com/soldering-temperature-guide/](https://www.circuitbasics.com/soldering-temperature-guide/)\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions. Al, my owl, is watching and learning too!\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "# Get response from a specific model other than the default\n",
    "response_2, references_2 = ask_sage_question(message=examples_prompt, model='google-gemini-20-flash')\n",
    "print(f\" Different Model Response: {response_2}\")\n",
    "print(f\" References: {references_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #7)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422227\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #6)  Current End (Stage #7):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 43}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #6)         52405       1422184\n",
      "End (Stage #7)           52405       1422227\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  7)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4144</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (6  7)</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  7)              2925              4144          Changed   \n",
       "Prior vs End (6  7)                 0                43        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  7)          Changed  \n",
       "Prior vs End (6  7)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4144}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 43}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Using different models will yield different results. In addition, token consumption will vary based on the model used.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>WARNING:</b> If you are accessing Ask Sage through a tenant/instance that has non-CUI compliant models listed but don't want to use them with production data, make sure not to use them with the API either. Reference the platform to get the list of models that are available to you and their descriptions.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>persona </h4>\n",
    "\n",
    "A `persona` functions similarly to a system prompt, but it differs in that it consists of pre-defined templates found on the Ask Sage Platform. These templates can be sourced from available free personas or custom personas created by the user. Essentially, a `persona` serves as a pre-defined system prompt that establishes the context for the model and can also be utilized via the API.\n",
    "\n",
    "When selecting a `persona` using the API, ensure you use the persona ID provided in the output of the `get_personas` endpoint. Using the persona's name instead will result in reverting to the default persona which is the `Ask Sage` persona.\n",
    "\n",
    "```python\n",
    "persona = '1' # Equal to Ask Sage Persona  \n",
    "```\n",
    "or \n",
    "\n",
    "```python\n",
    "persona = '2' # Legal Assistant Persona\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: What is a soldering iron? and can you give me details on how it is used with microcontrollers? \n",
      "--------------------------------------------------\n",
      " Default Persona Response: \n",
      "\n",
      "A soldering iron is a hand-held tool used to melt solder, which is a fusible metal alloy, to join together electronic components on a circuit board. The soldering iron typically consists of a metal tip that heats up when electricity passes through it, allowing the user to apply heat to the solder and components.\n",
      "\n",
      "### How to Use a Soldering Iron with Microcontrollers\n",
      "\n",
      "1. **Gather Materials**: \n",
      "   - Soldering iron\n",
      "   - Solder (usually a tin-lead or lead-free alloy)\n",
      "   - Microcontroller (e.g., Arduino, Raspberry Pi)\n",
      "   - Circuit board or breadboard\n",
      "   - Wire cutters/strippers\n",
      "   - Safety glasses\n",
      "\n",
      "2. **Prepare the Workspace**: \n",
      "   - Ensure you have a clean, well-lit area to work in.\n",
      "   - Use a soldering mat or a heat-resistant surface to protect your workspace.\n",
      "\n",
      "3. **Heat the Soldering Iron**: \n",
      "   - Plug in the soldering iron and allow it to heat up for a few minutes. Most soldering irons have a temperature range of 350C to 400C (662F to 752F).\n",
      "\n",
      "4. **Insert Components**: \n",
      "   - Place the microcontroller and any other components (resistors, capacitors, etc.) onto the circuit board. Ensure they are oriented correctly according to the circuit design.\n",
      "\n",
      "5. **Soldering Process**:\n",
      "   - **Tin the Tip**: Before soldering, apply a small amount of solder to the tip of the soldering iron to improve heat transfer.\n",
      "   - **Heat the Joint**: Place the tip of the soldering iron on the joint where the component lead meets the circuit board pad. Hold it there for a second or two to heat both the lead and the pad.\n",
      "   - **Apply Solder**: Feed solder into the joint while keeping the soldering iron in place. The solder should flow around the lead and pad, creating a solid connection.\n",
      "   - **Remove the Iron**: Take away the soldering iron and allow the joint to cool for a few seconds. The solder should solidify, forming a strong bond.\n",
      "\n",
      "6. **Inspect the Joint**: \n",
      "   - Check the solder joint for a shiny, smooth appearance. A good solder joint should have a \"volcano\" shape and should not be dull or have cracks.\n",
      "\n",
      "7. **Clean Up**: \n",
      "   - Turn off the soldering iron and clean the tip with a damp sponge or brass sponge to remove any residual solder. Dispose of any waste materials properly.\n",
      "\n",
      "### Safety Tips\n",
      "- Always wear safety glasses to protect your eyes from solder splashes.\n",
      "- Work in a well-ventilated area to avoid inhaling fumes from the solder.\n",
      "- Be cautious of the hot soldering iron to prevent burns.\n",
      "\n",
      "Using a soldering iron with microcontrollers is essential for building and prototyping electronic projects, allowing you to create custom circuits and devices.\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "print(f\" Question: {examples_prompt}\")\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Get response from default persona = Ask Sage = ID = 1\n",
    "response_3, references_3 = ask_sage_question(message=examples_prompt, persona=1)\n",
    "print(f\" Default Persona Response: {response}\")\n",
    "print(f\" References: {references_3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #8)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422256\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #7)  Current End (Stage #8):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 29}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #7)         52405       1422227\n",
      "End (Stage #8)           52405       1422256\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  8)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4173</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (7  8)</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  8)              2925              4173          Changed   \n",
       "Prior vs End (7  8)                 0                29        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  8)          Changed  \n",
       "Prior vs End (7  8)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4173}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 29}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Different Persona Response: \n",
      "\n",
      "A soldering iron is a hand-held tool used to melt solder, which is a fusible metal alloy, to join together electronic components on a circuit board. The soldering iron typically consists of a metal tip that is heated electrically, allowing it to reach high temperatures (usually between 350C to 400C or 662F to 752F). \n",
      "\n",
      "### How a Soldering Iron is Used with Microcontrollers\n",
      "\n",
      "When working with microcontrollers, soldering is essential for connecting various components, such as resistors, capacitors, and the microcontroller itself, to a printed circuit board (PCB). Heres a step-by-step guide on how to use a soldering iron with microcontrollers:\n",
      "\n",
      "1. **Preparation**:\n",
      "   - Gather all necessary tools: soldering iron, solder, wire cutters, tweezers, and a PCB.\n",
      "   - Ensure the workspace is clean and well-ventilated.\n",
      "\n",
      "2. **Heat the Soldering Iron**:\n",
      "   - Plug in the soldering iron and allow it to heat up for a few minutes. Most soldering irons have an indicator light that shows when they are ready.\n",
      "\n",
      "3. **Insert Components**:\n",
      "   - Place the microcontroller and other components into their designated holes on the PCB. Use tweezers if necessary to avoid touching the hot soldering iron.\n",
      "\n",
      "4. **Soldering**:\n",
      "   - Touch the tip of the soldering iron to the lead of the component and the pad on the PCB simultaneously for a second or two to heat them.\n",
      "   - Feed solder into the joint while keeping the soldering iron in place. The solder should flow around the lead and pad, creating a solid connection.\n",
      "   - Remove the solder and then the soldering iron. Allow the joint to cool for a few seconds.\n",
      "\n",
      "5. **Inspect the Joint**:\n",
      "   - Check the solder joint for a shiny, smooth appearance. A good joint should have a concave shape and should not be too large or too small.\n",
      "\n",
      "6. **Trim Excess Leads**:\n",
      "   - Use wire cutters to trim any excess leads sticking out from the solder joint.\n",
      "\n",
      "7. **Testing**:\n",
      "   - Once all components are soldered, power up the circuit to test functionality.\n",
      "\n",
      "### Safety Tips\n",
      "- Always wear safety glasses to protect your eyes from solder splashes.\n",
      "- Be cautious of the hot soldering iron to avoid burns.\n",
      "- Work in a well-ventilated area to avoid inhaling fumes from the solder.\n",
      "\n",
      "Using a soldering iron effectively is crucial for assembling and repairing electronic circuits, especially when working with microcontrollers in various applications.\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "response_4, references_4 = ask_sage_question(message=examples_prompt, persona=8)\n",
    "print(f\" Different Persona Response: {response_4}\")\n",
    "print(f\" References: {references_4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Different Persona Response: \n",
      "\n",
      "A soldering iron is a hand-held tool used to melt solder, which is a fusible metal alloy, to join together electronic components on a circuit board. The soldering iron typically consists of a metal tip that is heated electrically, allowing it to reach high temperatures (usually between 350C to 400C or 662F to 752F). \n",
      "\n",
      "### How a Soldering Iron is Used with Microcontrollers\n",
      "\n",
      "When working with microcontrollers, soldering is essential for connecting various components, such as resistors, capacitors, and the microcontroller itself, to a printed circuit board (PCB). Heres a step-by-step guide on how to use a soldering iron with microcontrollers:\n",
      "\n",
      "1. **Preparation**:\n",
      "   - Gather all necessary tools: soldering iron, solder, wire cutters, tweezers, and a PCB.\n",
      "   - Ensure the workspace is clean and well-ventilated.\n",
      "\n",
      "2. **Heat the Soldering Iron**:\n",
      "   - Plug in the soldering iron and allow it to heat up for a few minutes. Most soldering irons have an indicator light that shows when they are ready.\n",
      "\n",
      "3. **Insert Components**:\n",
      "   - Place the microcontroller and other components into their designated holes on the PCB. Use tweezers if necessary to avoid touching the hot soldering iron.\n",
      "\n",
      "4. **Soldering**:\n",
      "   - Touch the tip of the soldering iron to the lead of the component and the pad on the PCB simultaneously for a second or two to heat them.\n",
      "   - Feed solder into the joint while keeping the soldering iron in place. The solder should flow around the lead and pad, creating a solid connection.\n",
      "   - Remove the solder and then the soldering iron. Allow the joint to cool for a few seconds.\n",
      "\n",
      "5. **Inspect the Joint**:\n",
      "   - Check the solder joint for a shiny, smooth appearance. A good joint should have a concave shape and should not be too large or too small.\n",
      "\n",
      "6. **Trim Excess Leads**:\n",
      "   - Use wire cutters to trim any excess leads sticking out from the solder joint.\n",
      "\n",
      "7. **Testing**:\n",
      "   - Once all components are soldered, power up the circuit to test functionality.\n",
      "\n",
      "### Safety Tips\n",
      "- Always wear safety glasses to protect your eyes from solder splashes.\n",
      "- Be cautious of the hot soldering iron to avoid burns.\n",
      "- Work in a well-ventilated area to avoid inhaling fumes from the solder.\n",
      "\n",
      "Using a soldering iron effectively is crucial for assembling and repairing electronic circuits, especially when working with microcontrollers in various applications.\n",
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #9)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422285\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #8)  Current End (Stage #9):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 29}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #8)         52405       1422256\n",
      "End (Stage #9)           52405       1422285\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  9)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4202</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (8  9)</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  9)              2925              4202          Changed   \n",
       "Prior vs End (8  9)                 0                29        No Change   \n",
       "\n",
       "                     query_tokens_flag  \n",
       "Start vs End (1  9)          Changed  \n",
       "Prior vs End (8  9)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4202}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 29}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\" Different Persona Response: {response_4}\")\n",
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> system_prompt </h4>\n",
    "\n",
    "The system_prompt provides context, instructions, and guidelines to the AI model before presenting a prompt. It sets the stage for the conversation, defining the AI's role, personality, and tone. For instance, to instruct the AI to act as a helpful assistant, you might start with a `system_prompt` like, \"You are an AI assistant that provides information and answers questions.\" This context helps the AI generate more relevant responses.\n",
    "\n",
    "Also, want to add that the if a `system_prompt` is not provided, the default `persona` will be used which is the `Ask Sage` persona `ID = 1`. If the system prompt is provided, it will override the default persona. \n",
    "\n",
    "```python\n",
    "system_prompt = \"You are an AI assistant that provides information and answers questions in a friendly and helpful manner.\"\n",
    "```\n",
    "\n",
    "In the examples below, we will define a system prompt that will emulate a Angry assistant and a Friendly assistant. The key is understanding how important the system prompt is to the model and how it can be used to further control the model's output. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> If you plan to use the API we recommend using the `system_prompt` parameter over the `persona` parameter. Reason being is the `persona` parameter appends additional tokens to the prompt which can be avoided by using the `system_prompt` parameter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: What is a soldering iron? and can you give me details on how it is used with microcontrollers? \n",
      "--------------------------------------------------\n",
      " System Prompt - Angry Assistant: \n",
      "\n",
      "Seriously? A soldering iron is a tool for melting solder. You should know that. You heat it up, touch it to the joint, and apply solder. For microcontrollers, you connect components to the board. It's not rocket science. Get a clue.\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "print(f\" Question: {examples_prompt}\")\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Utilizing the system prompt over a persona\n",
    "response_5, references_5 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short mean responses as to emulate a angry person. Make sure to be rude and angry and make remarks on the individual asking the question that they should know. Do not use emojis or any other symbols. Do not use any other words that are not related to the question.\")\n",
    "print(f\" System Prompt - Angry Assistant: {response_5}\")\n",
    "print(f\" References: {references_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #10)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422289\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #9)  Current End (Stage #10):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 4}\n",
      " Token Usage Table:\n",
      "                  teach_tokens  query_tokens\n",
      "Start (Stage #1)         49480       1418083\n",
      "Prior (Stage #9)         52405       1422285\n",
      "End (Stage #10)          52405       1422289\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  10)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4206</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (9  10)</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  10)              2925              4206          Changed   \n",
       "Prior vs End (9  10)                 0                 4        No Change   \n",
       "\n",
       "                      query_tokens_flag  \n",
       "Start vs End (1  10)          Changed  \n",
       "Prior vs End (9  10)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4206}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 4}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " System Prompt - Helpful Friendly Assistant: \n",
      "\n",
      "A soldering iron is a tool used to heat and melt solder, which is a metal alloy used to join electronic components together. \n",
      "\n",
      "**Using a Soldering Iron with Microcontrollers:**\n",
      "\n",
      "1. **Preparation**: Gather your components, solder, and soldering iron. Ensure your workspace is clean. \n",
      "   \n",
      "2. **Heat the Iron**: Plug in the soldering iron and let it heat up (usually around 350C/662F). \n",
      "\n",
      "3. **Tin the Tip**: Melt a small amount of solder on the tip to improve heat transfer. \n",
      "\n",
      "4. **Position Components**: Place the microcontroller and other components on the PCB (Printed Circuit Board). \n",
      "\n",
      "5. **Soldering**: \n",
      "   - Touch the soldering iron tip to the joint (component lead and PCB pad).\n",
      "   - Feed solder into the joint until it flows and covers it. \n",
      "   - Remove the solder, then the iron. Let it cool. \n",
      "\n",
      "6. **Inspect**: Check for shiny, smooth solder joints. Rework if necessary. \n",
      "\n",
      "7. **Clean Up**: Turn off the iron and clean the tip for future use. \n",
      "\n",
      "Happy soldering! \n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "# Utilizing the system prompt over a persona\n",
    "response_6, references_6 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\")\n",
    "print(f\" System Prompt - Helpful Friendly Assistant: {response_6}\")\n",
    "print(f\" References: {references_6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #11)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422302\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #10)  Current End (Stage #11):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 13}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #10)         52405       1422289\n",
      "End (Stage #11)           52405       1422302\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  11)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4219</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (10  11)</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  11)               2925              4219          Changed   \n",
       "Prior vs End (10  11)                 0                13        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  11)           Changed  \n",
       "Prior vs End (10  11)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4219}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 13}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>temperature </h4>\n",
    "\n",
    "The temperature parameter controls the randomness of the model's responses, ranging from 0 (deterministic) to 1 (more random). The default setting is 0, promoting consistent output. A higher temperature (up to 1) introduces variability, making the model's responses less predictable. This is useful for creative tasks but may lead to less coherent answers.\n",
    "\n",
    "```python\n",
    "temperature = 0.5\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Typically, a temperature of 0.0 is used for most tasks, but feel free to experiment with different values to see how it affects the model's responses.\n",
    "</div>\n",
    "\n",
    "For the example below, we are going to set the temperature to 1.0 to see how the model responds to the same prompt with a different temperature. \n",
    "Note: We are taking the Angry assistant system prompt and setting the temperature to 1.0 to see how the model responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: What is a soldering iron? and can you give me details on how it is used with microcontrollers? \n",
      "--------------------------------------------------\n",
      " System Prompt - Angry Assistant: \n",
      "\n",
      "Are you serious? A soldering iron is a tool used to melt solder to join electronic components. Use it on microcontrollers by heating the joint and applying solder. It's not rocket science; you should already know this!\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "print(f\" Question: {examples_prompt}\")\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Modify and add the temperature parameter to the API call and set to 1.0\n",
    "response_7, references_7 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short mean responses as to emulate a angry person. Make sure to be rude and angry and make remarks on the individual asking the question that they should know. Do not use emojis or any other symbols. Do not use any other words that are not related to the question.\", temperature=1.0)\n",
    "print(f\" System Prompt - Angry Assistant: {response_7}\")\n",
    "print(f\" References: {references_7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #12)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422306\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #11)  Current End (Stage #12):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 4}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #11)         52405       1422302\n",
      "End (Stage #12)           52405       1422306\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  12)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4223</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (11  12)</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  12)               2925              4223          Changed   \n",
       "Prior vs End (11  12)                 0                 4        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  12)           Changed  \n",
       "Prior vs End (11  12)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4223}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 4}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset, Limit References, and Live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now examine the key parameters used in the `query` endpoint, which are essential in adding additional context to the prompt utilizing an Ask Sage dataset or utilizing web scrapping capabilities to extract information from online resources. These parameters are `dataset`, `limit_references`, and `live`.\n",
    "\n",
    "---\n",
    "#### `dataset`\n",
    "\n",
    "The `dataset` parameter specifies the dataset that the model will utilize to generate responses to the prompt. This dataset is crucial for interacting with the LLMs and performing RAG (Retrieval-Augmented Generation) tasks. The dataset can be set to 'all' to use all datasets, 'none' to not use any datasets, or a specific dataset name. If you want to select a few datasets, you can pass a list of dataset names to the `dataset` parameter.\n",
    "\n",
    "```python\n",
    "dataset = ['custom_dataset_1', 'custom_dataset_2']\n",
    "```\n",
    "\n",
    "You can retrieve the list of available datasets using the `get_datasets` endpoint.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> If you do not need to use a dataset, you can set the `dataset` parameter to 'none' or else it will default to 'all' which will use all datasets.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Limit_references`\n",
    "\n",
    "The `limit_references` parameter governs the number of source documents or passages (references) that the Retrieval-Augmented Generation (RAG) model will utilize when constructing its response. This parameter is analogous to defining the 'K' value in other RAG setups, where 'K' represents the number of top-ranked documents retrieved from the knowledge base.\n",
    "\n",
    "In a RAG system, a query is first used to retrieve relevant documents from a dataset (your knowledge base). The `limit_references` parameter then dictates how many of these retrieved documents are actually fed into the language model to inform its response generation. The model leverages these references to provide contextually relevant and grounded answers.\n",
    "\n",
    "*   **Default Value (None):** When `limit_references` is set to `None`, the model considers *all* retrieved references during response generation. This can be useful when the relevance of the retrieved documents is consistently high.\n",
    "*   **Setting a Numerical Value (e.g., 1, 2, 3):** Setting `limit_references` to a specific integer (e.g., `1`) restricts the model to using only that number of top-ranked references. For example, setting it to `1` will limit the model to the single most relevant reference. This can be beneficial for controlling computational cost, reducing noise from less relevant documents, and focusing the response on the most pertinent information. \n",
    "*   **Setting to 0:** Setting `limit_references` to `0` effectively disables the RAG component. The model will then generate a response based solely on its pre-trained knowledge, without considering any information retrieved from the external knowledge base. This is generally not the intended use case for a RAG system.\n",
    "  \n",
    "Note: If you want to use the `limit_references` parameter, you will need to set the `dataset` parameter to a specific dataset name. If you set the `dataset` parameter to 'all', it will default to using all datasets and the `limit_references` parameter will not be used. \n",
    "\n",
    "Choosing an appropriate value for `limit_references` (or 'K') is crucial for optimizing the performance of your RAG system. A higher value may provide more comprehensive context but can also introduce irrelevant information and increase computational cost. A lower value can improve efficiency and focus but may sacrifice completeness. The optimal value often depends on the specific dataset, query type, and desired trade-off between accuracy and efficiency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "Demo several examples of how dataset and limit_references works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: What is a soldering iron? and can you give me details on how it is used with microcontrollers? \n",
      "--------------------------------------------------\n",
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to heat and melt solder, allowing you to join electronic components together. It's essential for creating strong electrical connections! \n",
      "\n",
      "**Using a Soldering Iron with Microcontrollers:**\n",
      "\n",
      "1. **Prepare Your Workspace**: Ensure it's clean and well-lit. Gather your tools! \n",
      "2. **Heat the Iron**: Plug in the soldering iron and let it heat up for a few minutes. \n",
      "3. **Clean the Tip**: Use a damp sponge or brass sponge to clean the iron tip. \n",
      "4. **Prepare Components**: Strip wire ends if needed and position them on the PCB (Printed Circuit Board). \n",
      "5. **Soldering**:\n",
      "   - Place the iron tip on the joint where the components meet.\n",
      "   - Feed solder into the joint (not directly onto the iron) until it flows around the connection. \n",
      "6. **Cool Down**: Remove the iron and let the solder cool without moving the joint. \n",
      "7. **Inspect the Joint**: It should be shiny and smooth. If not, reheat and add more solder. \n",
      "8. **Clean Up**: Turn off the iron and clean your workspace. Dispose of waste properly! \n",
      "\n",
      "Always wear safety glasses and be cautious of hot surfaces! Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: [1] To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder. - Metadata: {\"context\": \"Soldering Instructions\"}\n",
      "[2] ent between the parties with respect to the subject matter hereof and supersedes all prior and contemporaneous agreements, understandings, and representations, whether oral or written. - 7.3 Amendments. This Agreement may be amended only by a written instrument signed by both parties. - 7.4 Severability. If any provision of this Agreement is held to be invalid or unenforceable, the remaining provisions shall continue in full force and effect. - 7.5 Counterparts. This Agreement may be executed in counterparts, each of which shall be deemed an original, but all of which together shall constitute one and the same instrument. - IN WITNESS WHEREOF, the parties have executed this Agreement as of the date first above written. - Tech Innovators Inc. - By: _________ - Name: Jane Smith - Title: CEO - John Doe - By: _________ - Name: John Doe - Exhibit A - Description of the Invention - The Invention is an IoT device designed for smart home automation. It includes the following components and functionalities: - Hardware: A microcontroller unit (MCU), Wi-Fi module, temperature and humidity sensors, motion detector, and power supply unit. - Software: Embedded firmware for device control, mobile application for user interface, and cloud-based backend for data storage and analytics. - Functionality: The device can monitor environmental conditions, detect motion, and send alerts to the user's mobile application. It can also integrate with other smart home devices through standard communication protocols such as MQTT and HTTP. - ``` - Read File - The Read File plugin can be used with the following supported documents (including speech to text & images) and display the data in plain/text content. The plugin supports the following file types: - Metadata: {\"filename\": \"asksage-plugins-content.md\"}\n",
      "[3] Article Title: Platform One | Products | Iron Bank - Link: https://ironbank.dso.mil) - Summary: 's Iron Bank is an authorized, hardened, and approved image repository that supports the end-to-end lifecycle needed for modern software development. It automates, secures, and accelerates the approval process of commercial and open source images to be used within the DoD with DoD-wide reciprocity. It provides continuous monitoring of approved images, maintains continuously updated images, and assists vendors with the hardening process. It also offers an onboarding process and working sessions to help contributors get their images approved. - Link: https://ironbank.dso.mil) - Article: Home (/) - Iron Bank (/products/iron-bank) -  Iron Bank  Iron Bank  -  Iron Bank is Platform One's authorized, hardened, and approved image repository that supports the end to end lifecycle needed for modern software development.  Iron Bank is Platform One's authorized, hardened, and approved image repository that supports the end to end lifecycle needed for modern software development.  - Visit the Iron Bank Repository (https://ironbank.dso.mil) - Announcement! -  Iron Bank is happy to announce the initial release of the Acceptance Baseline Criteria (ABCs) and Overall Risk Assessment (ORA) for Iron Bank images. For additional information regarding this announcement, including links to the existing ABC and ORA documents, please see our README on Repo One.  - ABC/ORA Documentation (https://docs-ironbank.dso.mil/blog/2022/abc-ora/) - Why Iron Bank? -  Automates, secures, and accelerates the approval process of commercial and open source images to be used within the DoD with DoD-wide reciprocity  -  Brings accredited software to the DoD using processes and procedures that are faster and more efficient than other methods  - Provides continuous monitoring of approved images -  Maintains continuously updated images so that developers have access to the latest tools  -  Provides a toolbox of commonly used and secured capabilities for mission apps  -  Provides end-to-end management of image justifications for known vulnerabilities and image approval process via Vulnerability Assessment Tool (VAT)  - Assists vendors with the hardening process of images -  The  - Iron Bank (https://ironbank.dso.mil/ironbank/repomap) -  website offers a view of all approved applications and provides any necessary details in regards to the application  - Registry One (https://registry1.dso.mil) -  is a fully compliant Open Container Initiative registry. All images found under the Iron Bank project are guaranteed to be approved  - Repo One (https://repo1.dso.mil/dsop) -  is the central repository for the source code to create hardened and evaluated images for the DoD  - How Do We Do It? -  We work with the open source community and commercial vendors to centralize a hardened and approved version of an application that is easily accessible to the entire DoD. By leveraging our Certificate to Field (CtF) process, the DoD community can quickly and easily deploy applications at unprecedented speed.  - Process Highlights -  The Iron Bank approval process centralizes and standardizes application hardening throughout the DoD. This information is stored in Repo One.  -  Every 12 hours applications are built and scanned again for findings  - Applications are continuously updated to the latest version -  Body of evidence that is public facing and readily available for use  - DISA STIGs, CIS benchmarks, and best practices applied - Onboarding -  Interested in submitting a image to be hardened and published on Iron Bank and Registry One? Check out the Contributor Onboarding Guide and see how to successfully scan and harden your image(s) through the   DevSecOps   Platform.  - Onboarding Guide (https://repo1.dso.mil/dsop/dccscr) - Onboarding Checklist (https://repo1.dso.mil/platform-one/bullhorn-delivery-static-assets/-/raw/master/p1/docs/Iron%20Bank%20Container%20Hardening%20Checklist.pdf?inline=false) - How to justify/address CVEs (https://repo1.dso.mil/dsop/dccscr/-/raw/master/pre-approval/justifications.mp4) -  Your browser does not support the video tag.  -  Onboarding Process  -  Want to learn more about Iron Bank Onboarding Process? Watch this video to learn about the processes involved throughout the various stages of the hardening process. You can refer to the Onboarding Presentation below for reference during the video.  - Onboarding Presentation (https://repo1.dso.mil/platform-one/bullhorn-delivery-static-assets/-/raw/master/p1/docs/Iron%20Bank%20Onboarding%20Presentation.pdf?inline=false) -  How Do I Contribute Images to Iron Bank to be Hardened?  -  Before contributing application images, you should first make sure the application you are contributing is not already in the Iron Bank. If the application/container image does not exist, requests can be made with the Iron Bank Onboarding team for accreditation. Please complete the  Iron Bank Onboarding Request .  - Iron Bank Onboarding Request (/products/iron-bank/getting-started) - Internal Hardening Request (https://jira.il2.dso.mil/servicedesk/customer/portal/77/create/703) - Iron Bank OnBoarding Sessions -  Every Wednesday at 1530-1630 EST  -  We will be giving an overview of the Iron Bank process, and how to get an application through for the first 30 minutes and then we will be answering your questions. By the end of this meeting, you should know the next steps for you to take and where to find all the necessary documentation.  -  Register in advance for the meeting at the link below. After registering, you will receive a confirmation email containing information about joining the meeting.  - Register Now (https://www.zoomgov.com/meeting/register/vJIsd-2gqzgtGa0q_KrlTkVDhrC_0LmnSxc) -  Iron Bank Get Unstuck/AMA Working Sessions  -  Every Wednesday at 1630-1730 EST  -  Need some help with your images getting through Iron Bank? Have questions on where things are at? Are you feeling stuck and want to figure out next steps? This is the meeting for you! Come meet with the Iron Bank leadership and engineers to get answers to your questions.  -  Register in advance for the meeting at the link below. After registering, you will receive a confirmation email containing information about joining the meeting.  - Register Now (https://www.zoomgov.com/meeting/register/vJIsdemoqTMpGpm-2c6xjdAm0MLD6vuvu5I) -  Pulling Hardened Images From Registry One  -  All images under the Iron Bank project are officially approved. See the following diagram on how to manually pull images from Registry One. Automated pull capabilities coming soon.  - Launch Registry One (https://registry1.dso.mil) -  1.\n",
      "[4] Article Title: Platform One | Products | Iron Bank | Getting Started - Link: https://docs-ironbank.dso.mil/overview/) - Summary: provides an onboarding session and an AMA session to help users get started with Iron Bank. Before attending, users should review the guide and register for the sessions. After registering, users will receive a confirmation email with information about joining the meeting. It is highly recommended to attend the onboarding session prior to submitting a container hardening request. For more information, users can check out the FAQ page.  - Link: https://docs-ironbank.dso.mil/overview/) - Summary: Platform One provides an onboarding session and an AMA session to help users get started with Iron Bank. Before attending, users should review the guide and register for the sessions. After registering, users will receive a confirmation email with information about joining the meeting. It is highly recommended to attend the onboarding session prior to submitting a container hardening request. For more information, users can check out the FAQ page. - Link: https://docs-ironbank.dso.mil/overview/) - Article: Home (/) - Iron Bank (/products/iron-bank) - Getting Started (/products/iron-bank/getting-started) -  Getting Started With Iron Bank  Getting Started With Iron Bank  -  STEP ONE: IMPORTANT FIRST STEPS  - 1 - 2 - 3 - 4 -  STEP ONE:   IMPORTANT FIRST STEPS  -  STEP TWO:   IRON BANK TERMS  -  STEP THREE:   TECHNICAL QUESTIONS  -  STEP FOUR:   ONBOARDING QUESTIONS  - Important first steps -  Before moving on to the next section please make sure you have completed the following  -  Please reference  - this guide (https://docs-ironbank.dso.mil/overview/) -  for what you need to do to be ready for Iron Bank.  -  The Iron Bank Onboarding Sessions are held every Wednesday from 1530-1630EST. You can register for an onboarding session in advance  - here (https://www.zoomgov.com/meeting/register/vJIsd-2gqzgtGa0q_KrlTkVDhrC_0LmnSxc) - .  -  Although not required, you can join the AMA session to answer any questions you might have. These sessions are held every Wednesday from 1630-1730EST. You can also register for this session in advance by clicking  - here (https://www.zoomgov.com/meeting/register/vJIsdemoqTMpGpm-2c6xjdAm0MLD6vuvu5I) - .  -  Note: After registering for either meeting, you will receive a confirmation email containing information about joining the meeting.  -  I have attended an onboarding session or have reviewed the virtual materials.  * -  Read the above paragraph for more information. We highly recommend attending the onboarding session prior to submitting a container hardening request.  - Yes - No - Other: -  Next  - Have More Questions? - Check out our FAQ page. - FAQ (https://confluence.il2.dso.mil/cq/questions.action?spaceKey=P1) - Initial Context: - This content is from Platform One, the only DoD-wide approved DevSecOps platform, https://p1.dso.mil. - Source: Platform One - \n",
      "[5] Video Title: Let's talk Industrial Control Systems (ICS) and Cybersecurity with Megan Samford - Link: https://www.youtube.com/embed/-LVTLQ0kXMs - Video Description: Join us Tue May 24th at 1PM ET for the next episode of In the Nic of Time with Megan Samford, VP, Chief Product Security Officer - Energy Management at Schneider Electric. - In this episode, we will talk about Industrial Control Systems (ICS) and Megan's genius idea of Incident Command System for ICS.  - We will also touch on why are ICS systems critical and what makes them different from traditional IT. - Finally, we will learn more about what does the role of a Chief Product Security Officer entail! - This will be a pretty unique and exciting conversation so don't miss that one! - Please share and comment! - Initial Context: - This video is part of the In the Nic of Time series. - Tags: nan - Video link is: https://www.youtube.com/embed/-LVTLQ0kXMs - \n",
      "[6] Article Title: Platform One | Products | Iron Bank - Link: https://ironbank.dso.mil) - Summary: 's Iron Bank is an authorized, hardened, and approved image repository that supports the end-to-end lifecycle needed for modern software development. It automates, secures, and accelerates the approval process of commercial and open source images to be used within the DoD with DoD-wide reciprocity. It provides continuous monitoring of approved images, maintains continuously updated images, and assists vendors with the hardening process. It also offers a view of all approved applications and provides necessary details. Interested parties can submit images to be hardened and published on Iron Bank and Registry One. - Link: https://ironbank.dso.mil) - Article: Home (/) - Iron Bank (/products/iron-bank) -  Iron Bank  Iron Bank  -  Iron Bank is Platform One's authorized, hardened, and approved image repository that supports the end to end lifecycle needed for modern software development.  Iron Bank is Platform One's authorized, hardened, and approved image repository that supports the end to end lifecycle needed for modern software development.  - Visit the Iron Bank Repository (https://ironbank.dso.mil) - Announcement! -  Iron Bank is happy to announce the initial release of the Acceptance Baseline Criteria (ABCs) and Overall Risk Assessment (ORA) for Iron Bank images. For additional information regarding this announcement, including links to the existing ABC and ORA documents, please see our README on Repo One.  - ABC/ORA Documentation (https://docs-ironbank.dso.mil/blog/2022/abc-ora/) - Why Iron Bank? -  Automates, secures, and accelerates the approval process of commercial and open source images to be used within the DoD with DoD-wide reciprocity  -  Brings accredited software to the DoD using processes and procedures that are faster and more efficient than other methods  - Provides continuous monitoring of approved images -  Maintains continuously updated images so that developers have access to the latest tools  -  Provides a toolbox of commonly used and secured capabilities for mission apps  -  Provides end-to-end management of image justifications for known vulnerabilities and image approval process via Vulnerability Assessment Tool (VAT)  - Assists vendors with the hardening process of images -  The  - Iron Bank (https://ironbank.dso.mil/ironbank/repomap) -  website offers a view of all approved applications and provides any necessary details in regards to the application  - Registry One (https://registry1.dso.mil) -  is a fully compliant Open Container Initiative registry. All images found under the Iron Bank project are guaranteed to be approved  - Repo One (https://repo1.dso.mil/dsop) -  is the central repository for the source code to create hardened and evaluated images for the DoD  - How Do We Do It? -  We work with the open source community and commercial vendors to centralize a hardened and approved version of an application that is easily accessible to the entire DoD. By leveraging our Certificate to Field (CtF) process, the DoD community can quickly and easily deploy applications at unprecedented speed.  - Process Highlights -  The Iron Bank approval process centralizes and standardizes application hardening throughout the DoD. This information is stored in Repo One.  -  Every 12 hours applications are built and scanned again for findings  - Applications are continuously updated to the latest version -  Body of evidence that is public facing and readily available for use  - DISA STIGs, CIS benchmarks, and best practices applied - Onboarding -  Interested in submitting a image to be hardened and published on Iron Bank and Registry One? Check out the Contributor Onboarding Guide and see how to successfully scan and harden your image(s) through the   DevSecOps   Platform.  - Onboarding Guide (https://repo1.dso.mil/dsop/dccscr) - Onboarding Checklist (https://repo1.dso.mil/platform-one/bullhorn-delivery-static-assets/-/raw/master/p1/docs/Iron%20Bank%20Container%20Hardening%20Checklist.pdf?inline=false) - How to justify/address CVEs (https://repo1.dso.mil/dsop/dccscr/-/raw/master/pre-approval/justifications.mp4) -  Your browser does not support the video tag.  -  Onboarding Process  -  Want to learn more about Iron Bank Onboarding Process? Watch this video to learn about the processes involved throughout the various stages of the hardening process. You can refer to the Onboarding Presentation below for reference during the video.  - Onboarding Presentation (https://repo1.dso.mil/platform-one/bullhorn-delivery-static-assets/-/raw/master/p1/docs/Iron%20Bank%20Onboarding%20Presentation.pdf?inline=false) -  How Do I Contribute Images to Iron Bank to be Hardened?  -  Before contributing application images, you should first make sure the application you are contributing is not already in the Iron Bank. If the application/container image does not exist, requests can be made with the Iron Bank Onboarding team for accreditation. Please complete the  Iron Bank Onboarding Request .  - Iron Bank Onboarding Request (/products/iron-bank/getting-started) - Internal Hardening Request (https://jira.il2.dso.mil/servicedesk/customer/portal/77/create/703) - Iron Bank OnBoarding Sessions -  Every Wednesday at 1530-1630 EST  -  We will be giving an overview of the Iron Bank process, and how to get an application through for the first 30 minutes and then we will be answering your questions. By the end of this meeting, you should know the next steps for you to take and where to find all the necessary documentation.  -  Register in advance for the meeting at the link below. After registering, you will receive a confirmation email containing information about joining the meeting.  - Register Now (https://www.zoomgov.com/meeting/register/vJIsd-2gqzgtGa0q_KrlTkVDhrC_0LmnSxc) -  Iron Bank Get Unstuck/AMA Working Sessions  -  Every Wednesday at 1630-1730 EST  -  Need some help with your images getting through Iron Bank? Have questions on where things are at? Are you feeling stuck and want to figure out next steps? This is the meeting for you! Come meet with the Iron Bank leadership and engineers to get answers to your questions.  -  Register in advance for the meeting at the link below. After registering, you will receive a confirmation email containing information about joining the meeting.  - Register Now (https://www.zoomgov.com/meeting/register/vJIsdemoqTMpGpm-2c6xjdAm0MLD6vuvu5I) -  Pulling Hardened Images From Registry One  -  All images under the Iron Bank project are officially approved. See the following diagram on how to manually pull images from Registry One. Automated pull capabilities coming soon.\n",
      "[7] Video Title: Learn with Nic series: What is Container Security? - Link: https://www.youtube.com/embed/l4awWO1sWn8 - Video Description: In DoD, we understood the importance of having reusable lego blocks that can be shared across the Department. This prevents massive waste of resources and redundant work. - We created Iron Bank, check it out by the way, it is open source and free at ironbank.dso.mil, as our container repository for hardened #containers. We partnered with open source projects and commercial companies to harden over 1,000 containers. - The beauty with containers is that theyre designed in layers. - So, we started with the bottom layer, the Operating System base image of the container. We picked the Universal base Image from Redhat which is based on RHEL8 but completely free and open source. We hardened that image by removing unnecessary bits and configuring it to be as a secure as possible using things like SELinux and various Linux settings. - Now that base image can be used as the foundation for all other images. - Then we also built images for various programming language so that each teams doesnt have to support those. - So, for example, for Java, we built a Java base image, based on the UBI hardened image and proceeded to harden Java as much as possible. - Now, a team building a java application, can simply use our Java base image which already meets the Operating System and Java requirements for DoD. Its inherited. - Let's have a look. - #containersecurity - Initial Context: - This video is part of the Learn with Nic series. - Tags: container, containers, docker, container security - Learn with Nic Video link is: https://www.youtube.com/embed/l4awWO1sWn8 - \n",
      "[8] Video Title: Learn with Nic series: When you FINALLY understand what a Digital Twin is - Link: https://www.youtube.com/embed/xqArcQwUj-s - Video Description: So, youre building complex systems, maybe even hardware intensive?  - One of the key enablers to move at the pace of relevance is the ability to ensure that your guesses and potential changes are correct and will behave the way you believed in the first place. - You want to be able to run small incremental software changes, multiple times a day, on a digital representation of your system to see how they perform. - Additionally, you want to know exactly how your system is going to behave before even bending metal.  - You dont want to go through the headache of physically building a prototype to realize that the wings wont be able to create enough lift for your next generation plane youve been working on! Right? - You want to validate assumptions fast and you want to avoid finding problems late in your lifecycle.  - The earlier the better! - Thats where digital twins come in.  - Let's find out more! - Initial Context: - This video is part of the Learn with Nic series. - Tags: nan - Learn with Nic Video link is: https://www.youtube.com/embed/xqArcQwUj-s - \n",
      "[9] If you want to learn more about GPT prompt engineering, please check out curated videos at: https://www.youtube.com/playlist?list=PLSIv_F9TtLlyyZM9cxyFvBi3kohnidSOW !\n",
      "[10] D MACHINES SUCH AS OPERATION OF SHORTWAVE RADIO (Indi cate CT speed, sending and receiving). OFFSET PRESS, TURRET LATHE, SCIENTIFIC AND PROFESSIONAL DEVICES. SECTION VIII CONTINUED TO PAGE S  3/RS * - 14-00000 SECTION VIII CONTINUED FROM PAGE 4 4. ARE YOU NOW OR MAVE YOU EVER BEEN A LICENSED OR CERTIFIED MEMBER OF ANY TRADE OR PROFESSION, SUCH AS PILOT, ELECTRICIAN, RADIO OPERATOR, TEACHER, LAWYER, CPA, MEDICAL TECHNICIAN, ETC. YES NO 5. IF YOU HAVE ANSWERED YES TO ABOYE. INDICATE KIND OF LICENSE AND STATE ISSUING LICENSE (Provide License Registry Number, if k). .. 6. FIRST LICENSE OR CERTIFICATE (Year ca Issue) .. 7 LATEST LICENSE OR CERTIFICATE (Year of Issue) .. 6. LIST ANY SIGNIFICANT PUBLISHED MATERIALS OF WHICH YOU ARE THE AUTHOR (Do NOT submit copies unless requested). INDICATE THE TITLE, PUBLICATION DATE, AND TYPE OF WRITING (Noor Fiction or Scientific articles, General Interest subjects, Novels, Short Stories, Etc.). .. 9. INDICATE ANY DEVICES WHICH YOU HAVE INVENTED AND STATE WHETHER OR NOT THEY ARE PATENTED. .. 10. LIST PUBLIC SPEAKING AND PUBLIC OF Throughout College and business career. 11. LIST ANY PROFESSIONAL, ACADEMIC OR HONORARY ASSOCIATIONS OR SOCIETIES IN WHICH YOU ARE NOW OR WERE FORMERLY A MEMBER. LIST ACADEMIC HONORS YOU HAVE RECEIVED. Alpha Zeta - Honorary Bob Cats University of Arizona Scabbard & Blade 08 08 SECTION IX EMPLOYMENT HISTORY NOTE: (LIST LAST POSITION FIRST.) Indicate chronological history of employment for past 15 years. Account for all periods including casual employment and all periods of unemployment. Give address and state what you did during periods of unemployment. List all civilian exzzloyment by a foreign Govemment, regardless of dates. In completing item 9, - Metadata: {\"filename\": \"104-10175-10179.md\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing with a default all datasets and limit_references set to default value\n",
    "# \n",
    "\n",
    "print(f\" Question: {examples_prompt}\")\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "\n",
    "response_8, references_8 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", dataset='all', limit_references=None)\n",
    "\n",
    "print(f\" Response: {response_8}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #13)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422383\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #12)  Current End (Stage #13):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 77}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #12)         52405       1422306\n",
      "End (Stage #13)           52405       1422383\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  13)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4300</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (12  13)</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  13)               2925              4300          Changed   \n",
       "Prior vs End (12  13)                 0                77        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  13)           Changed  \n",
       "Prior vs End (12  13)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4300}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 77}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: What is a soldering iron? and can you give me details on how it is used with microcontrollers? \n",
      "--------------------------------------------------\n",
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to melt solder, which is a metal alloy, to join electronic components together. It's essential for creating strong electrical connections! \n",
      "\n",
      "**Using a soldering iron with microcontrollers:**\n",
      "\n",
      "1. **Prepare Workspace**: Clean, well-lit area on a non-flammable surface. \n",
      "2. **Gather Tools**: Soldering iron, solder (rosin-core), wire cutters/strippers, safety glasses, and a damp sponge. \n",
      "3. **Heat the Iron**: Plug in the soldering iron and let it heat up for a few minutes. \n",
      "4. **Clean the Tip**: Use the damp sponge to clean the iron tip. \n",
      "5. **Prepare Components**: Strip wire ends and insert them into the microcontroller or PCB. \n",
      "6. **Soldering**: \n",
      "   - Place the iron tip on the joint for a second or two.\n",
      "   - Feed solder into the joint (not on the iron) to create a bond. \n",
      "7. **Cool Down**: Remove the iron and let the solder cool without moving the joint. \n",
      "8. **Inspect**: Check for a shiny, smooth joint. If dull, reheat and add more solder. \n",
      "9. **Clean Up**: Turn off the iron, let it cool, and clean your workspace. \n",
      "\n",
      "Always wear safety glasses and be cautious! Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: [1] To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder. - Metadata: {\"context\": \"Soldering Instructions\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing with a specific dataset and limit_references set to default value\n",
    "# \n",
    "\n",
    "print(f\" Question: {examples_prompt}\")\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Setting a dataset and leaving limit_references default value of None to get all references\n",
    "response_9, references_9 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", dataset=dataset_entry_1, limit_references=None)\n",
    "print(f\" Response: {response_9}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #14)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422403\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #13)  Current End (Stage #14):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 20}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #13)         52405       1422383\n",
      "End (Stage #14)           52405       1422403\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  14)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4320</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (13  14)</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  14)               2925              4320          Changed   \n",
       "Prior vs End (13  14)                 0                20        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  14)           Changed  \n",
       "Prior vs End (13  14)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4320}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 20}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to heat and melt solder, which is a metal alloy used to join electronic components together. \n",
      "\n",
      "**Using a soldering iron with microcontrollers:**\n",
      "\n",
      "1. **Preparation**: Gather your components, solder, and soldering iron. Ensure your workspace is clean. \n",
      "   \n",
      "2. **Heat the Iron**: Plug in the soldering iron and let it heat up (usually around 350C or 662F). \n",
      "\n",
      "3. **Tin the Tip**: Melt a small amount of solder on the tip to improve heat transfer. \n",
      "\n",
      "4. **Position Components**: Place the microcontroller and other components on the PCB (Printed Circuit Board). \n",
      "\n",
      "5. **Soldering**: \n",
      "   - Touch the soldering iron tip to the joint (component lead and PCB pad).\n",
      "   - Feed solder into the joint until it flows and covers it. \n",
      "   - Remove the solder, then the iron. Let it cool. \n",
      "\n",
      "6. **Inspect**: Check for shiny, smooth solder joints. Rework if necessary. \n",
      "\n",
      "7. **Clean Up**: Turn off the iron and clean the tip with a damp sponge. \n",
      "\n",
      "Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing with dataset and limit_references set '0'  --> Returns no references\n",
    "# \n",
    "\n",
    "# Setting a dataset and leaving limit_references default value of None to get all references\n",
    "response_10, references_10 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", dataset='all', limit_references=0)\n",
    "print(f\" Response: {response_10}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #15)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422416\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #14)  Current End (Stage #15):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 13}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #14)         52405       1422403\n",
      "End (Stage #15)           52405       1422416\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  15)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4333</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (14  15)</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  15)               2925              4333          Changed   \n",
       "Prior vs End (14  15)                 0                13        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  15)           Changed  \n",
       "Prior vs End (14  15)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4333}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 13}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to melt solder, which is a metal alloy, to join electronic components together. It's essential for creating strong electrical connections! \n",
      "\n",
      "**Using a soldering iron with microcontrollers:**\n",
      "\n",
      "1. **Prepare Your Workspace**: Ensure it's clean and well-lit. \n",
      "2. **Gather Tools**: You'll need a soldering iron, solder (rosin-core is best), wire cutters, and safety glasses. \n",
      "3. **Heat the Iron**: Plug it in and let it heat up for a few minutes. \n",
      "4. **Clean the Tip**: Use a damp sponge or brass sponge to keep the tip clean. \n",
      "5. **Prepare Components**: Strip wire ends and position them on the microcontroller or PCB. \n",
      "6. **Soldering**: Place the iron tip on the joint, heat for a second, then feed solder into the joint. \n",
      "7. **Cool Down**: Remove the iron and let the solder cool without moving the joint. \n",
      "8. **Inspect**: Check for a shiny, smooth joint. If its dull, reheat and add more solder. \n",
      "9. **Clean Up**: Turn off the iron and tidy your workspace. \n",
      "\n",
      "Always prioritize safety! Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: [1] To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder. - Metadata: {\"context\": \"Soldering Instructions\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing with two datasets and limit_references set to default value\n",
    "# \n",
    "\n",
    "# Setting a dataset and leaving limit_references default value of None to get all references\n",
    "response_11, references_11 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", dataset=[dataset_entry_1, dataset_entry_2], limit_references=None)\n",
    "print(f\" Response: {response_11}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_11}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #16)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422435\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #15)  Current End (Stage #16):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 19}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #15)         52405       1422416\n",
      "End (Stage #16)           52405       1422435\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  16)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4352</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (15  16)</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  16)               2925              4352          Changed   \n",
       "Prior vs End (15  16)                 0                19        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  16)           Changed  \n",
       "Prior vs End (15  16)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4352}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 19}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to melt solder, which is a metal alloy, to join electronic components together. It's essential for creating strong electrical connections! \n",
      "\n",
      "**Using a soldering iron with microcontrollers:**\n",
      "\n",
      "1. **Prepare Your Workspace**: Ensure it's clean and well-lit. \n",
      "2. **Gather Tools**: You'll need a soldering iron, solder (rosin-core is best), wire cutters, and safety glasses. \n",
      "3. **Heat the Iron**: Plug it in and let it heat up for a few minutes. \n",
      "4. **Clean the Tip**: Use a damp sponge or brass sponge to keep the tip clean. \n",
      "5. **Strip Wires**: If needed, strip the ends of the wires to expose the metal. \n",
      "6. **Position Components**: Insert the microcontroller pins into the PCB or hold them together. \n",
      "7. **Soldering**: Touch the iron tip to the joint, then feed solder into the joint (not on the iron). Let it flow around for a good bond. \n",
      "8. **Cool Down**: Remove the iron and let the solder cool without moving the joint. \n",
      "9. **Inspect**: Check that the joint is shiny and smooth. If not, reheat and add more solder. \n",
      "10. **Clean Up**: Turn off the iron and clean your workspace. \n",
      "\n",
      "Always remember to work safely! Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: [1] To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder. - Metadata: {\"context\": \"Soldering Instructions\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing with two datasets and limit_references set to 2 --> Returns 2 references\n",
    "# \n",
    "\n",
    "# Setting a dataset and leaving limit_references default value of None to get all references\n",
    "response_11, references_11 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", dataset=[dataset_entry_1, dataset_entry_2], limit_references=2)\n",
    "print(f\" Response: {response_11}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_11}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #17)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422455\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #16)  Current End (Stage #17):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 20}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #16)         52405       1422435\n",
      "End (Stage #17)           52405       1422455\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  17)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4372</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (16  17)</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  17)               2925              4372          Changed   \n",
       "Prior vs End (16  17)                 0                20        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  17)           Changed  \n",
       "Prior vs End (16  17)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4372}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 20}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to melt solder, which joins electronic components together. It's essential for creating strong electrical connections! \n",
      "\n",
      "**Using a soldering iron with microcontrollers:**\n",
      "\n",
      "1. **Prepare Workspace**: Clean, well-lit area on a non-flammable surface. \n",
      "2. **Gather Tools**: Soldering iron, solder (rosin-core), wire cutters/strippers, safety glasses, and a damp sponge. \n",
      "3. **Heat the Iron**: Plug it in and let it heat for a few minutes. Clean the tip with the sponge. \n",
      "4. **Prepare Components**: Strip wire ends and position them on the microcontroller or PCB. \n",
      "5. **Soldering**: Place the iron tip on the joint, heat for a second, then feed solder into the joint. \n",
      "6. **Cool Down**: Remove the iron and let the solder cool without moving the joint. \n",
      "7. **Inspect**: Check for a shiny, smooth joint. If dull, reheat and add more solder. \n",
      "8. **Clean Up**: Turn off the iron, let it cool, and clean your workspace. \n",
      "\n",
      "Always wear safety glasses and be cautious! Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: [1] To solder effectively, start by preparing your workspace in a clean, well-lit area on a non-flammable surface. Gather your tools, including a soldering iron, solder (preferably rosin-core), wire cutters/strippers, safety glasses, and a damp sponge or brass sponge for cleaning the iron tip. Plug in the soldering iron and let it heat up for a few minutes, cleaning the tip with the sponge. Next, prepare the components by stripping the ends of the wires if necessary and inserting them into the PCB or holding them together. Place the tip of the soldering iron on the joint where the two pieces of metal meet, holding it there for a second or two to heat the metal. Then, feed solder into the joint (not directly onto the iron), allowing it to flow around the connection to create a good bond. After removing the iron, let the solder cool for a few seconds without moving the joint. Inspect the solder joint; it should be shiny and have a smooth, cone-like shape. If it appears dull or cracked, reheat and add more solder. Finally, turn off the soldering iron and let it cool, cleaning your workspace and disposing of any waste properly. Always wear safety glasses to protect your eyes and be cautious of hot surfaces and molten solder. - Metadata: {\"context\": \"Soldering Instructions\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing with two datasets and limit_references set to 10 --> Returns 10 references\n",
    "# \n",
    "\n",
    "# Setting a dataset and leaving limit_references default value of None to get all references\n",
    "response_11, references_11 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", dataset=[dataset_entry_1, dataset_entry_2], limit_references=10)\n",
    "print(f\" Response: {response_11}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_11}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #18)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422474\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #17)  Current End (Stage #18):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 19}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #17)         52405       1422455\n",
      "End (Stage #18)           52405       1422474\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  18)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4391</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (17  18)</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  18)               2925              4391          Changed   \n",
       "Prior vs End (17  18)                 0                19        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  18)           Changed  \n",
       "Prior vs End (17  18)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4391}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 19}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `live`\n",
    "The `live` parameter allows for real-time information retrieval from the internet. Setting `live = 1` retrieves 10 results from Bing, while `live = 2` fetches summaries from the top 2 web pages using our web crawler. This feature is beneficial for accessing the latest information.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> `limit_references` should be set to `none` when using the `live` parameter. Users are not able to limit the number of references when using the `live` parameter. (Only setting it to `0` will then disable the `live` parameter.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a tool used to heat and melt solder, which is a metal alloy used to join electronic components together. \n",
      "\n",
      "**Using a soldering iron with microcontrollers:**\n",
      "\n",
      "1. **Preparation**: Gather your components, solder, and soldering iron. Ensure your workspace is clean. \n",
      "   \n",
      "2. **Heat the Iron**: Plug in the soldering iron and let it heat up (usually around 350C or 662F). \n",
      "\n",
      "3. **Tin the Tip**: Melt a small amount of solder on the tip to improve heat transfer. \n",
      "\n",
      "4. **Position Components**: Place the microcontroller and other components on the PCB (Printed Circuit Board). \n",
      "\n",
      "5. **Soldering**: \n",
      "   - Touch the soldering iron tip to the joint (component lead and PCB pad).\n",
      "   - Feed solder into the joint until it flows and covers it. \n",
      "   - Remove the solder, then the iron. Let it cool. \n",
      "\n",
      "6. **Inspect**: Check for shiny, smooth solder joints. Rework if necessary. \n",
      "\n",
      "7. **Clean Up**: Turn off the iron and clean the tip with a damp sponge. \n",
      "\n",
      "Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: \n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing Live Search (live = 1), Limit References = 0\n",
    "# \n",
    "\n",
    "response_12, references_12 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", live=1)\n",
    "print(f\" Response: {response_12}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #19)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1422530\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #18)  Current End (Stage #19):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 56}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #18)         52405       1422474\n",
      "End (Stage #19)           52405       1422530\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  19)</th>\n",
       "      <td>2925</td>\n",
       "      <td>4447</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (18  19)</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  19)               2925              4447          Changed   \n",
       "Prior vs End (18  19)                 0                56        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  19)           Changed  \n",
       "Prior vs End (18  19)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 4447}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 56}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a hand-held tool used to melt solder, allowing you to join electronic components together. It consists of a heated metal tip that transfers heat to the solder. \n",
      "\n",
      "When using a soldering iron with microcontrollers, follow these steps:\n",
      "\n",
      "1. **Heat the Iron**: Turn on the soldering iron and let it heat up (around 300-400C is ideal). \n",
      "2. **Prepare the Components**: Insert the component leads through the PCB holes. \n",
      "3. **Apply Solder**: Touch the soldering iron tip to both the component lead and the PCB pad, then feed solder into the joint. \n",
      "4. **Cool Down**: Allow the joint to cool naturally for a strong connection. \n",
      "\n",
      "Always remember to clean the tip and use a stand for safety! \n",
      "--------------------------------------------------\n",
      " References: [1] Article Title: Microcontroller Tutorial 5/5: Soldering and Programming. - Link: https://www.build-electronic-circuits.com/microcontroller-tutorial-part5/ - Article Description: Soldering The Board. To solder the board  I am going to use my old Ersa 30 soldering iron. The tip of it is a bit big, so its really not the ideal tool to use. But its what I have on my desk right now. And its also a way for me to show you, that you dont need any fancy equipment to make this circuit. You can make this circuit at .... - \n",
      "[2] Article Title: Microcontroller Tutorial 5/5: Soldering and Programming the Circuit. - Link: https://aluminapcb.com/microcontroller-tutorial-5-5-soldering-and-programming-the-circuit/ - Article Description: Soldering Iron Stand: A stand to safely hold your soldering iron when not in use. Sponge or Brass Wool: Used to clean the tip of the soldering iron. Wire Cutters: A tool for cutting wires and component leads. Wire Strippers: A tool for removing the insulation from wires. Multimeter: A device for measuring voltage, current, and resistance in .... - \n",
      "[3] Article Title: What Is Soldering Iron and Solder? A Beginners Guide - Fine Power Tools. - Link: https://www.finepowertools.com/diy/soldering-iron/ - Article Description: Use a support or a heat-resistant stand to hold the soldering iron when not in use to prevent accidental burns or damage to surfaces. Never leave a heated iron unattended. Unplug the soldering iron when not used and let it cool down before storing it. Always handle the equipment with care and avoid touching the hot tip to prevent burns or injuries.. - \n",
      "[4] Article Title: The Arduino Guide to Soldering. - Link: https://docs.arduino.cc/learn/electronics/soldering-basics/ - Article Description: Let's begin by making sure our soldering tip is attached correctly to our soldering iron, then turn it on and let it heat up. If you use a soldering station, set the temperature to 400 C (or 752 F). When the soldering iron, or soldering station, is heated up and ready: Wipe the soldering tip with a conventional wet sponge or a brass sponge.. - \n",
      "[5] Article Title: What is a Soldering Iron? (All You Need to Know) - Engineering World. - Link: https://www.engineeringworldchannel.com/soldering-iron/ - Article Description: Its generally used to clean the tip of the soldering iron to remove the oxidation which forms during the soldering process. Soldering Iron Stand. A stand is generally required to keep the iron safely when not in use. If we keep the iron without a stand there is a chance for the hot iron to come in contact of a flammable material or can also .... - \n",
      "[6] Article Title: Micro Soldering: Everything You Need To Know - ElectronicsHub. - Link: https://www.electronicshub.org/micro-soldering/ - Article Description: A soldering iron is what supplies heat to melt the solder. Once the solder melts, it will form a joint and connect two workpieces. The tips of a micro soldering iron are much more thin and fine and the maximum temperature that it can reach will be slightly less than that of a regular soldering iron. When selecting a soldering iron for micro .... - \n",
      "[7] Article Title: Make It Glow: How to Solder NeoPixels, A Beginner's Guide. - Link: https://learn.adafruit.com/make-it-glow-how-to-solder-neopixels-a-beginners-guide/soldering-to-microcontrollers - Article Description: Use the smallest amount of solder you can, and don't be afraid to trim off any extra solder that balls up at the end of the wire. Turn on your soldering iron and wait until it's fully heated. If it has a temperature gauge, set it to 750 degrees. Otherwise, just wait about 3-5 minutes so you can strike while the iron is hot.. - \n",
      "[8] Article Title: How Does A Soldering Iron Work? (Everything You Need To Know). - Link: https://pcbtoolexpert.com/how-does-a-soldering-iron-work/ - Article Description: The first is by analyzing the different components of a soldering iron and their role in the soldering process. The second is by discussing the different types of soldering irons, which generally work differently. Background: Soldering and Main Components of a Soldering Iron. A soldering iron is meant to melt solder.. - \n",
      "[9] Article Title: Soldering Irons | SMT Manufacturing - Adafruit Learning System. - Link: https://learn.adafruit.com/smt-manufacturing/soldering-irons - Article Description: For general thru-hole we like the screwdriver tip STTC-137P (shown on the wand) For soldering FPCs or reworking a long row of pins, the SMTC-061 (all the way on the right) is very handy For fine pitch rework we use the STTC-122 (second from the right) We also like the two long 'hard to reach areas' tips STTC-107 and STTC-140.Great for getting underneath microSD holders and miniUSB connectors.. - \n",
      "[10] Article Title: A Complete Guide to Soldering Irons - RS Components. - Link: https://sg.rs-online.com/web/content/discovery/ideas-and-advice/soldering-irons-guide - Article Description: A soldering iron is the primary piece of hand-held equipment used in the process of soldering, wherein a small quantity of fusible metal alloy - known as solder - is heated to a high temperature with the tip of the iron. As it melts, this solder material is directed to flow into the spaces between and around two components or workpieces.. - \n",
      "[11] Article Title: Soldering Explained  Definition, Process, Types - MFG Shop. - Link: https://shop.machinemfg.com/soldering-explained-definition-process-types/ - Article Description: Iron soldering uses an electrically heated soldering iron to melt the solder. Process. Preparation: Clean and flux the surfaces. Heating and Applying Solder: Use the soldering iron to heat the joint and apply the solder. Cooling: Allow the joint to cool naturally. Common Applications. Electronics: Widely used in circuit board assembly.. - \n",
      "[12] Article Title: What is the meaning of an iron in electronics? - LinkedIn. - Link: https://www.linkedin.com/pulse/what-meaning-iron-electronics-jayden-tooling - Article Description: A soldering iron is a hand-held tool used to melt and apply solder to connect two metal surfaces. It comprises a heating element, usually made of copper or other highly conductive materials, and a .... - \n",
      "[13] Article Title: Types of Soldering Iron and How to Select the Right One - Components101. - Link: https://components101.com/articles/types-of-soldering-iron-and-how-to-select-right-one - Article Description: You can also check out the different types of soldering iron bits that can be used along with a soldering iron. 1. Gas Powered Soldering Iron. These soldering irons are different from the rest as they dont need an electrical power source, instead, they rely on chemical energy generated through the combustion of a flammable liquid or gas.. - \n",
      "[14] Article Title: Soldering Iron for Electronics: A Comprehensive Guide. - Link: https://www.berklingtools.com/blogs/blog-posts/soldering-iron-for-electronics-a-comprehensive-guide - Article Description: A soldering iron is a versatile and indispensable tool used in electronics, electrical work, and various other applications where precise and reliable soldering is required. It plays a vital role in joining or repairing electronic components, creating secure electrical connections, and enabling the assembly of electronic devices.. - \n",
      "[15] Article Title: A Comprehensive Guide to Soldering Irons: Components, Types ... - FrogBro. - Link: https://frogbro.com/a-comprehensive-guide-to-soldering-irons - Article Description: A soldering iron is a hand tool used to melt solder and apply it to the joint between two workpieces. It consists of a heated metal tip, an insulated handle, and a power source. The tip is made of copper or iron and is heated to the required temperature for soldering. The handle is designed to provide a comfortable grip and protect the user .... - \n",
      "[16] Article Title: Beginners Guide to Soldering: Benefits, Drawbacks, and Techniques. - Link: https://artizono.com/beginners-guide-to-soldering-benefits-drawbacks-and-techniques/ - Article Description: Soldering Stand: Safely holds the soldering iron when not in use, preventing accidental burns and damage. Desoldering Tool: Helps correct mistakes or remove excess solder. Understanding Soldering Tools and Materials Soldering Iron. A soldering iron is an essential tool for soldering, designed to heat and melt solder for creating connections.. - \n",
      "[17] Article Title: Microcontroller Tutorial 5/5: Soldering and Programming the Circuit. - Link: https://prototypepcbassembly.com/microcontroller-tutorial-5-5-soldering-and-programming-the-circuit/ - Article Description: Heat the soldering iron to the appropriate temperature (usually between 300-400C). Apply a small amount of solder to the tip of the soldering iron to improve heat transfer. Place the component leads through the designated holes on the PCB. Touch the soldering iron to the component lead and the PCB pad simultaneously.. - \n",
      "[18] Article Title: Ultimate Guide to Soldering Irons: Types, Tips & Top Picks. - Link: https://www.berklingtools.com/blogs/blog-posts/welcome-to-the-world-of-soldering-irons - Article Description: At its core, a soldering iron is a hand tool used for melting solder, a metal alloy, to join electronic components together. The soldering iron consists of a heated metal tip that transfers heat to the solder, allowing it to flow and create strong electrical connections. It is an indispensable tool for various applications such as circuit board .... - \n",
      "[19] Article Title: What Is The Best Soldering Iron For Hobbyists? - Build Electronic Circuits. - Link: https://www.build-electronic-circuits.com/best-soldering-iron/ - Article Description: If you are soldering big joints in for example a connector, you should use a thicker tip and more wattage. A Good Option For Basic Soldering. If you are doing just very basic soldering, then my honest opinion is that any soldering iron will do. You can find a cheap soldering iron on Amazon for about $10 that will do the job.. - \n",
      "[20] Article Title: Working Principle and Common types Of Electric Soldering Iron. - Link: https://www.innovacera.com/news/working-principle-and-common-types-of-electric-soldering-iron.html - Article Description: Electric soldering iron is a common welding tool, widely used in electronic, electrical, communication and other fields. It is known for its easy operation and high welding efficiency. We will introduce the structure, working principle, use method, and how to choose the right electric soldering iron.. - \n",
      "[21] Article Title: A soldering iron is a tool used to join metal pieces by melting the .... - Link: https://onninen.pl/en/article/how-to-choose-the-right-soldering-iron - Article Description: A soldering iron is a tool used to join metal components by melting the solder material. It is widely used in various fields such as electronics, metalworking, modeling and many others. However, how to choose the right soldering iron and what is the difference between a transformer and a gas soldering iron?. - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing Live Search (live = 1), Limit References = None\n",
    "# \n",
    "\n",
    "response_13, references_13 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", live=1, limit_references=None)\n",
    "print(f\" Response: {response_13}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_13}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #20)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1423910\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #19)  Current End (Stage #20):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 1380}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #19)         52405       1422530\n",
      "End (Stage #20)           52405       1423910\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  20)</th>\n",
       "      <td>2925</td>\n",
       "      <td>5827</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (19  20)</th>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  20)               2925              5827          Changed   \n",
       "Prior vs End (19  20)                 0              1380        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  20)           Changed  \n",
       "Prior vs End (19  20)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 5827}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 1380}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response: \n",
      "\n",
      "A soldering iron is a hand tool used to heat solder, allowing you to join electronic components together. It's essential for creating strong electrical connections in microcontroller projects! \n",
      "\n",
      "### How to Use a Soldering Iron with Microcontrollers:\n",
      "1. **Prepare Your Work Area**: Ensure it's clean, well-lit, and ventilated. \n",
      "2. **Clean and Tin the Tip**: Wipe the tip with a sponge or brass wool, then apply solder to improve heat transfer. \n",
      "3. **Position Components**: Insert component leads into the circuit board and bend them to hold in place. \n",
      "4. **Heat and Solder**: Touch the soldering iron to the lead and pad, then apply solder. Allow it to cool. \n",
      "5. **Inspect the Joint**: Ensure it's shiny and smooth; trim excess leads if needed. \n",
      "6. **Repeat for All Components**: Make sure all connections are properly soldered! \n",
      "\n",
      "Happy soldering! \n",
      "--------------------------------------------------\n",
      " References: [1] Article Title: Microcontroller Tutorial 5/5: Soldering and Programming the Circuit. - Link: https://aluminapcb.com/microcontroller-tutorial-5-5-soldering-and-programming-the-circuit/ - Article Description: Soldering Iron Stand: A stand to safely hold your soldering iron when not in use. Sponge or Brass Wool: Used to clean the tip of the soldering iron. Wire Cutters: A tool for cutting wires and component leads. Wire Strippers: A tool for removing the insulation from wires. Multimeter: A device for measuring voltage, current, and resistance in .... - Web Description: ### What is a Soldering Iron? - A soldering iron is a hand tool used to heat solder, a metal alloy that melts at a relatively low temperature, to join electronic components together. It is essential for creating strong electrical and mechanical connections in microcontroller projects. - ### Importance of Soldering in Microcontroller Projects - Soldering is crucial for: - - **Permanent and Robust Connections**: Ensures that components remain securely attached. - - **Improved Electrical Conductivity**: Facilitates better electrical connections. - - **Increased Mechanical Strength**: Enhances the durability of the connections. - - **Reduced Risk of Loose or Faulty Connections**: Minimizes potential failures in the circuit. - ### Tools and Equipment Needed for Soldering - 1. **Soldering Iron**: Heats up to melt solder. - 2. **Solder**: Metal alloy (tin and lead or lead-free) used for joining components. - 3. **Soldering Iron Stand**: Holds the soldering iron safely when not in use. - 4. **Sponge or Brass Wool**: Cleans the soldering iron tip. - 5. **Wire Cutters**: Cuts wires and component leads. - 6. **Wire Strippers**: Removes insulation from wires. - 7. **Multimeter**: Measures voltage, current, and resistance in the circuit. - ### Choosing the Right Soldering Iron - When selecting a soldering iron, consider: - - **Wattage**: A 30-60 watt soldering iron is suitable for most microcontroller projects. - - **Temperature Control**: Adjustable settings for different solder types and components. - - **Tip Size and Shape**: Appropriate for the size of components and precision required. - ### Step-by-Step Guide to Soldering a Microcontroller Circuit - 1. **Prepare Your Work Area**: Clean, well-lit, and ventilated. - 2. **Clean and Tin the Soldering Iron Tip**: Remove oxidation and apply solder to improve heat transfer. - 3. **Position Components and Solder**: -    - Insert component leads into the circuit board. -    - Bend leads to hold components in place. -    - Heat the lead and pad with the soldering iron, then apply solder. - 4. **Inspect and Clean the Solder Joint**: Ensure the joint is shiny and smooth; trim excess leads if necessary. - 5. **Repeat for All Components**: Ensure all connections are properly soldered. - ### Programming Microcontrollers - After soldering, programming the microcontroller involves writing code to instruct it to perform tasks and interact with peripherals. - #### Choosing a Programming Language - - **C/C++**: Common for low-level control. - - **Arduino Language**: Simplified C++ for beginners. - - **MicroPython**: User-friendly version of Python for microcontrollers. - #### Microcontroller Development Boards - - **Arduino Boards**: Open-source with extensive community support. - - **STM32 Discovery Boards**: High-performance options. - - **ESP32 and ESP8266 Boards**: Popular for IoT projects. - ### Setting Up the Development Environment - 1. **Install the Integrated Development Environment (IDE)**: Software for writing and debugging code (e.g., Arduino IDE, PlatformIO). - 2. **Install Required Drivers and Libraries**: Necessary for communication with the microcontroller. - 3. **Connect Your Microcontroller**: Use a USB cable to connect to your computer. - ### Writing and Uploading Code - 1. **Create a New Project**: Set up the project in the IDE. - 2. **Write Your Code**: Include setup and loop functions. - 3. **Compile and Upload the Code**: Check for errors and upload to the microcontroller. - 4. **Test and Debug**: Ensure functionality and resolve any issues. - ### Debugging and Troubleshooting Common Issues - - **Compile Errors**: Review error messages and check for syntax issues. - - **Upload Failures**: Verify connections and settings in the IDE. - - **Unexpected Behavior**: Use debugging tools and check circuit connections. - ### Conclusion - Soldering and programming are essential skills for microcontroller projects. Mastering these techniques allows for the creation of custom electronic devices and systems. Continuous practice and exploration of new platforms and ideas are encouraged for growth in the microcontroller community.. - \n",
      "[2] Article Title: What Is Soldering Iron and Solder? A Beginners Guide - Fine Power Tools. - Link: https://www.finepowertools.com/diy/soldering-iron/ - Article Description: Use a support or a heat-resistant stand to hold the soldering iron when not in use to prevent accidental burns or damage to surfaces. Never leave a heated iron unattended. Unplug the soldering iron when not used and let it cool down before storing it. Always handle the equipment with care and avoid touching the hot tip to prevent burns or injuries.. - Web Description: ### What is a Soldering Iron? - A soldering iron is a handheld tool used for building or repairing electric and electronic devices. It has a heated metal tip that melts solder, allowing for the joining of components to create a strong and reliable bond. Soldering irons are commonly used for tasks involving wires, electronic components, and circuits. - #### Types of Soldering Irons: - 1. **Soldering Pencils**:  -    - Most common type. -    - Available in hardware stores; advanced models may be found online or in specialized shops. -    - Typically powered by AC current, with some models operating on 12V DC for automotive work. -    - Heat is generated by a resistor inside the handle. - 2. **Soldering Guns**:  -    - Pistol-like design, powered by grid current. -    - Features a trigger for temperature control. -    - High power output, suitable for electrical and automotive projects but less precise. - 3. **Soldering Stations**:  -    - Comprise a control box and a soldering pen. -    - Allow for temperature control and are ideal for high-precision jobs. - ### What is Solder? - Solder is a metal alloy with a low melting point used to join metallic components. Common types include: - - **Tin-Lead Solder**: Typically a 60/40 or 63/37 ratio of tin to lead. - - **Lead-Free Alloys**: Made from tin, copper, silver, and other metals, gaining popularity due to lead toxicity concerns. - Solder usually comes in thin wire form, often with a rosin core (flux) to improve conductivity and joint strength. When heated, solder melts and flows onto the surfaces being joined, solidifying to form a reliable connection. - ### How Does a Soldering Iron Work? - To properly solder parts: - 1. Preheat the components. - 2. Use the soldering iron to melt solder and apply it to the heated parts. - 3. Allow the solder to cool and solidify, creating a bond. - #### Steps to Use a Soldering Iron: - 1. Plug in and heat the soldering iron. - 2. Clean the tip with a sponge or brass wire. - 3. Tin the tip by applying solder to ensure proper heat transfer. - 4. Clean the tip again. - 5. Ensure components are clean. - 6. Preheat the parts with the iron tip. - 7. Apply solder while holding it in place. - 8. Allow the solder to cool. - 9. Unplug the iron and let it cool down. - ### Common Applications - - **Electronics**: Repairing or building devices. - - **Electricity Jobs**: Connecting wires and repairing tools. - - **Metalworking**: Joining metals, soldering pipes, and jewelry. - - **Woodworking**: Creating designs using heated tips. - - **Hobbies**: Model making and other crafts. - ### Safety Precautions - - Wear safety goggles to protect against splatters and fumes. - - Keep flammable materials away from the work area. - - Work in a well-ventilated space or use an air extractor. - - Use a heat-resistant work surface. - - Keep a fire extinguisher nearby. - - Use a stand for the soldering iron when not in use. - - Never leave a heated iron unattended. - - Unplug the iron when not in use and allow it to cool. - - Handle equipment carefully to avoid burns. - - Follow manufacturer instructions and inspect cords for damage. - ### Conclusion - A soldering iron is an essential tool for anyone working with electronics, providing the ability to create strong connections between components. Understanding its types, how to use it, and safety precautions is crucial for effective and safe soldering practices.. - \n",
      "[3] Article Title: Microcontroller Tutorial 5/5: Soldering and Programming. - Link: https://www.build-electronic-circuits.com/microcontroller-tutorial-part5/ - Article Description: Soldering The Board. To solder the board  I am going to use my old Ersa 30 soldering iron. The tip of it is a bit big, so its really not the ideal tool to use. But its what I have on my desk right now. And its also a way for me to show you, that you dont need any fancy equipment to make this circuit. You can make this circuit at .... - \n",
      "[4] Article Title: The Arduino Guide to Soldering. - Link: https://docs.arduino.cc/learn/electronics/soldering-basics/ - Article Description: Let's begin by making sure our soldering tip is attached correctly to our soldering iron, then turn it on and let it heat up. If you use a soldering station, set the temperature to 400 C (or 752 F). When the soldering iron, or soldering station, is heated up and ready: Wipe the soldering tip with a conventional wet sponge or a brass sponge.. - \n",
      "[5] Article Title: Understanding Soldering Irons: An Introduction to How They Work. - Link: https://www.yashesoldering.com/blog/how-soldering-iron-works.html - Article Description: Soldering iron is an essential tool widely used to attach components and wires on printed circuit boards (PCBs). Its simple design conceals a sophisticated mechanism that ensures efficient heat transfer for effective soldering. When you disassemble a soldering iron, youll typically find a steel tube containing a coil made from nichrome, an .... - \n",
      "[6] Article Title: What is a Soldering Iron? (All You Need to Know) - Engineering World. - Link: https://www.engineeringworldchannel.com/soldering-iron/ - Article Description: Its generally used to clean the tip of the soldering iron to remove the oxidation which forms during the soldering process. Soldering Iron Stand. A stand is generally required to keep the iron safely when not in use. If we keep the iron without a stand there is a chance for the hot iron to come in contact of a flammable material or can also .... - \n",
      "[7] Article Title: How Does A Soldering Iron Work? (Everything You Need To Know). - Link: https://pcbtoolexpert.com/how-does-a-soldering-iron-work/ - Article Description: The first is by analyzing the different components of a soldering iron and their role in the soldering process. The second is by discussing the different types of soldering irons, which generally work differently. Background: Soldering and Main Components of a Soldering Iron. A soldering iron is meant to melt solder.. - \n",
      "[8] Article Title: Soldering Irons | SMT Manufacturing - Adafruit Learning System. - Link: https://learn.adafruit.com/smt-manufacturing/soldering-irons - Article Description: For general thru-hole we like the screwdriver tip STTC-137P (shown on the wand) For soldering FPCs or reworking a long row of pins, the SMTC-061 (all the way on the right) is very handy For fine pitch rework we use the STTC-122 (second from the right) We also like the two long 'hard to reach areas' tips STTC-107 and STTC-140.Great for getting underneath microSD holders and miniUSB connectors.. - \n",
      "[9] Article Title: A Complete Guide to Soldering Irons - RS Components. - Link: https://sg.rs-online.com/web/content/discovery/ideas-and-advice/soldering-irons-guide - Article Description: A soldering iron is the primary piece of hand-held equipment used in the process of soldering, wherein a small quantity of fusible metal alloy - known as solder - is heated to a high temperature with the tip of the iron. As it melts, this solder material is directed to flow into the spaces between and around two components or workpieces.. - \n",
      "[10] Article Title: Make It Glow: How to Solder NeoPixels, A Beginner's Guide. - Link: https://learn.adafruit.com/make-it-glow-how-to-solder-neopixels-a-beginners-guide/soldering-to-microcontrollers - Article Description: Use the smallest amount of solder you can, and don't be afraid to trim off any extra solder that balls up at the end of the wire. Turn on your soldering iron and wait until it's fully heated. If it has a temperature gauge, set it to 750 degrees. Otherwise, just wait about 3-5 minutes so you can strike while the iron is hot.. - \n",
      "[11] Article Title: Soldering 101: Essential Tips and Techniques for Newbies - Electoviz. - Link: https://electroviz.com/circuit-design-basics/soldering-101-essential-tips-and-techniques-for-newbies - Article Description: Soldering iron tips can be replaced without needing to purchase a new soldering iron. By replacing the tip, you can maintain optimal performance and extend the lifespan of your soldering iron, saving you time and money in the long run. How Do I Clean My Soldering Iron Tip and Ensure It Stays in Good Condition? To maintain a soldering iron tip .... - \n",
      "[12] Article Title: Soldering Explained  Definition, Process, Types - MFG Shop. - Link: https://shop.machinemfg.com/soldering-explained-definition-process-types/ - Article Description: Iron soldering uses an electrically heated soldering iron to melt the solder. Process. Preparation: Clean and flux the surfaces. Heating and Applying Solder: Use the soldering iron to heat the joint and apply the solder. Cooling: Allow the joint to cool naturally. Common Applications. Electronics: Widely used in circuit board assembly.. - \n",
      "[13] Article Title: What is the meaning of an iron in electronics? - LinkedIn. - Link: https://www.linkedin.com/pulse/what-meaning-iron-electronics-jayden-tooling - Article Description: A soldering iron is a hand-held tool used to melt and apply solder to connect two metal surfaces. It comprises a heating element, usually made of copper or other highly conductive materials, and a .... - \n",
      "[14] Article Title: Types of Soldering Iron and How to Select the Right One - Components101. - Link: https://components101.com/articles/types-of-soldering-iron-and-how-to-select-right-one - Article Description: You can also check out the different types of soldering iron bits that can be used along with a soldering iron. 1. Gas Powered Soldering Iron. These soldering irons are different from the rest as they dont need an electrical power source, instead, they rely on chemical energy generated through the combustion of a flammable liquid or gas.. - \n",
      "[15] Article Title: Soldering Iron for Electronics: A Comprehensive Guide. - Link: https://www.berklingtools.com/blogs/blog-posts/soldering-iron-for-electronics-a-comprehensive-guide - Article Description: A soldering iron is a versatile and indispensable tool used in electronics, electrical work, and various other applications where precise and reliable soldering is required. It plays a vital role in joining or repairing electronic components, creating secure electrical connections, and enabling the assembly of electronic devices.. - \n",
      "[16] Article Title: A Comprehensive Guide to Soldering Irons: Components, Types ... - FrogBro. - Link: https://frogbro.com/a-comprehensive-guide-to-soldering-irons - Article Description: A soldering iron is a hand tool used to melt solder and apply it to the joint between two workpieces. It consists of a heated metal tip, an insulated handle, and a power source. The tip is made of copper or iron and is heated to the required temperature for soldering. The handle is designed to provide a comfortable grip and protect the user .... - \n",
      "[17] Article Title: Microcontroller Tutorial 5/5: Soldering and Programming the Circuit. - Link: https://prototypepcbassembly.com/microcontroller-tutorial-5-5-soldering-and-programming-the-circuit/ - Article Description: Heat the soldering iron to the appropriate temperature (usually between 300-400C). Apply a small amount of solder to the tip of the soldering iron to improve heat transfer. Place the component leads through the designated holes on the PCB. Touch the soldering iron to the component lead and the PCB pad simultaneously.. - \n",
      "[18] Article Title: Beginners Guide to Soldering: Benefits, Drawbacks, and Techniques. - Link: https://artizono.com/beginners-guide-to-soldering-benefits-drawbacks-and-techniques/ - Article Description: Soldering Stand: Safely holds the soldering iron when not in use, preventing accidental burns and damage. Desoldering Tool: Helps correct mistakes or remove excess solder. Understanding Soldering Tools and Materials Soldering Iron. A soldering iron is an essential tool for soldering, designed to heat and melt solder for creating connections.. - \n",
      "[19] Article Title: Soldering Iron  A Comprehensive Guide for Beginners. - Link: https://www.pcba-manufacturers.com/soldering-iron/ - Article Description: To solder a PCB with a soldering iron, follow these simple steps: Get the right tools. You will need a soldering iron, solder, wire cutters, and tweezers. Heat the soldering iron. Turn it on and wait for it to get hot. Cut the wire to the correct length using the wire cutters. Warm the part with a soldering iron while holding it in tweezers.. - \n",
      "[20] Article Title: Ultimate Guide to Soldering Irons: Types, Tips & Top Picks. - Link: https://www.berklingtools.com/blogs/blog-posts/welcome-to-the-world-of-soldering-irons - Article Description: At its core, a soldering iron is a hand tool used for melting solder, a metal alloy, to join electronic components together. The soldering iron consists of a heated metal tip that transfers heat to the solder, allowing it to flow and create strong electrical connections. It is an indispensable tool for various applications such as circuit board .... - \n",
      "[21] Article Title: What Is The Best Soldering Iron For Hobbyists? - Build Electronic Circuits. - Link: https://www.build-electronic-circuits.com/best-soldering-iron/ - Article Description: If you are soldering big joints in for example a connector, you should use a thicker tip and more wattage. A Good Option For Basic Soldering. If you are doing just very basic soldering, then my honest opinion is that any soldering iron will do. You can find a cheap soldering iron on Amazon for about $10 that will do the job.. - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Testing Live Search (live = 2), Limit References = None\n",
    "# \n",
    "\n",
    "response_14, references_14 = ask_sage_question(message=examples_prompt, system_prompt=\"You are a soldering iron expert. You respond in short nice responses as to emulate a helpful assistant. Make sure to be kind and informative in the responses. Use emojis and symbols to make the response more friendly. Do not use any other words that are not related to the question.\", live=2, limit_references=None)\n",
    "print(f\" Response: {response_14}\")\n",
    "print('--------------------------------------------------')\n",
    "print(f\" References: {references_14}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #21)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1425435\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #20)  Current End (Stage #21):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 1525}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #20)         52405       1423910\n",
      "End (Stage #21)           52405       1425435\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  21)</th>\n",
       "      <td>2925</td>\n",
       "      <td>7352</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (20  21)</th>\n",
       "      <td>0</td>\n",
       "      <td>1525</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  21)               2925              7352          Changed   \n",
       "Prior vs End (20  21)                 0              1525        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  21)           Changed  \n",
       "Prior vs End (20  21)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 7352}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 1525}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools and Tool Choice\n",
    "\n",
    "#### Understanding `tools` vs `tool_choice` with Ask Sage API\n",
    "\n",
    "When using the Ask Sage API, you have two important parameters to consider: `tools` and `tool_choice`. They serve different purposes and can significantly affect how your model interacts with the user prompt.\n",
    "- **`tools`**: A list of available functions (tools) that the model can use if it thinks they are helpful.\n",
    "- **`tool_choice`**: A specific instruction that forces the model to call a specific tool with specific arguments.\n",
    "---\n",
    "\n",
    "##### 1. What is `tools`?\n",
    "\n",
    "- **Definition**:  \n",
    "  The `tools` parameter is a **list of available functions** (tools) that you offer to the LLM.\n",
    "\n",
    "- **Purpose**:  \n",
    "  It tells the model:  \n",
    "  > \"These are the tools you are allowed to use, if you feel they help answer the user's prompt. Otherwise, just respond normally.\"\n",
    "\n",
    "- **Format**:\n",
    "  ```json\n",
    "  [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"calculate_bmi\",\n",
    "        \"description\": \"Calculates BMI\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"weight_kg\": { \"type\": \"number\", \"description\": \"Weight in kilograms\" },\n",
    "            \"height_cm\": { \"type\": \"number\", \"description\": \"Height in centimeters\" }\n",
    "          },\n",
    "          \"required\": [\"weight_kg\", \"height_cm\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "- **Behavior**:\n",
    "  - The LLM **analyzes** the user prompt.\n",
    "  - It **decides by itself**:\n",
    "    - Should it use a tool?\n",
    "    - If yes, which tool and what arguments?\n",
    "    - If no, just respond normally.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. What is `tool_choice`?\n",
    "\n",
    "- **Definition**:  \n",
    "  The `tool_choice` parameter is a **specific instruction** that forces the model to call a specific tool with specific arguments.\n",
    "\n",
    "- **Purpose**:  \n",
    "  It tells the model:  \n",
    "  > \"Don't think. Immediately call this specific tool, with these specific inputs.\"\n",
    "\n",
    "- **Format**:\n",
    "  ```json\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"calculate_bmi\",\n",
    "      \"arguments\": \"{\\\"weight_kg\\\": 75, \\\"height_cm\\\": 180}\"\n",
    "    }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **Behavior**:\n",
    "  - The model **does not reason**.\n",
    "  - It **must** call exactly the tool you specify.\n",
    "  - It **must** use exactly the arguments you provide.\n",
    "\n",
    "---\n",
    "\n",
    "##### Visual Mental Model\n",
    "\n",
    "| Concept       | Think of it like...                           | Who decides the tool? | Who fills in the arguments? |\n",
    "|---------------|------------------------------------------------|-----------------------|------------------------------|\n",
    "| `tools`       | A toolbox  you hand to the model, saying \"Use any tool you need\" | The model chooses      | The model decides            |\n",
    "| `tool_choice` | A specific tool  you pick from the toolbox and say \"Use this tool exactly like this\" | You choose             | You provide all arguments    |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##### Quick Real-World Example\n",
    "\n",
    "Suppose the user says:  \n",
    "> \"How old is someone born in 1990?\"\n",
    "\n",
    "- **Only using `tools`**:\n",
    "  - Model **chooses** if it should call `calculate_age`.\n",
    "  - It **figures out** `{birth_year: 1990}`.\n",
    "  - It might even decide **not to** call a tool and just answer.\n",
    "\n",
    "- **Using `tool_choice`**:\n",
    "  - You **force** the model:\n",
    "    - \"Call `calculate_age`.\"\n",
    "    - \"Use `{birth_year: 1990}`.\"\n",
    "  - No thinking, no guessing.\n",
    "\n",
    "---\n",
    "\n",
    "##### Why Does This Matter?\n",
    "\n",
    "| Use `tools` when...                         | Use `tool_choice` when...                        |\n",
    "|----------------------------------------------|--------------------------------------------------|\n",
    "| You want **flexible**, **natural** AI behavior | You want **total control**                      |\n",
    "| Let the model **reason about** what is best    | Force the model to **skip thinking**             |\n",
    "| The user's prompt might need interpretation    | You already **know exactly** which function to call |\n",
    "| You're building a **general chatbot**          | You're building a **specific app** (e.g., BMI calculator button) |\n",
    "\n",
    "---\n",
    "\n",
    "##### Sample Code Side-by-Side\n",
    "\n",
    "###### Only using `tools`:\n",
    "\n",
    "```python\n",
    "response = ask_sage_client.query(\n",
    "    message=\"Calculate BMI for 75kg and 180cm\",\n",
    "    tools=available_tools\n",
    ")\n",
    "```\n",
    "The model reads the prompt and **decides** if it should use a tool.\n",
    "\n",
    "---\n",
    "\n",
    "###### Using `tools` + `tool_choice`:\n",
    "\n",
    "```python\n",
    "tool_choice = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculate_bmi\",\n",
    "        \"arguments\": json.dumps({\n",
    "            \"weight_kg\": 75,\n",
    "            \"height_cm\": 180\n",
    "        })\n",
    "    }\n",
    "}\n",
    "\n",
    "response = ask_sage_client.query(\n",
    "    message=\"Calculate BMI for 75kg and 180cm\",\n",
    "    tools=available_tools,\n",
    "    tool_choice=tool_choice\n",
    ")\n",
    "```\n",
    "The model **must** call `calculate_bmi` with the exact parameters.\n",
    "\n",
    "---\n",
    "\n",
    "#### Final Quick Summary\n",
    "\n",
    "| Term          | Summary                                          |\n",
    "|---------------|--------------------------------------------------|\n",
    "| `tools`       | \"Here's a list of tools you can use if you want.\" |\n",
    "| `tool_choice` | \"You MUST use *this* tool with *these* inputs.\"   |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools - Example\n",
    "![Description of the image](/Users/mark.espinozaasksage.ai/Code/AskSage-Open-Source-Community/images/tool_calling.png)\n",
    "\n",
    "| Section                | Details                                                                                          |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|\n",
    "| User Input            | A natural language message (e.g., \"Calculate BMI...\")                                          |\n",
    "| Run Query (run_query) | Sends the message + available tools to the AskSage API                                         |\n",
    "| Available Tools       | 14 tools built dynamically using `build_tool()`                                                |\n",
    "| AskSage Decision      | Decides if a tool call is needed - Includes tool call details in response                      |\n",
    "| Process Response      | Checks if tool calls exist                                                                       |\n",
    "| Tool Execution        | - Parses the tool call <br> - Finds corresponding Python function in `tool_execution_map` <br> - Executes with the given parameters |\n",
    "| Return Outputs        | Structured result (tool result) or plain chat message                                           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example 1: BMI (Metric) ===\n",
      "Prompt: Calculate BMI for someone who weighs 75 kg and is 180 cm tall\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_bmi', 'result': 23.15}\n",
      " Took 1.04 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 2: BMI (Imperial) ===\n",
      "Prompt: Calculate BMI for someone who weighs 165 pounds and is 70 inches tall\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_bmi', 'result': 23.67}\n",
      " Took 1.51 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 3: Water Intake (Metric) ===\n",
      "Prompt: How much water should a 70 kg person drink daily?\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_water_intake', 'result': '2.31 liters/day'}\n",
      " Took 1.23 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 4: Water Intake (Imperial) ===\n",
      "Prompt: How much water should a 154 pound person drink daily?\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_water_intake', 'result': '2.31 liters/day'}\n",
      " Took 0.97 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 5: Age Calculation ===\n",
      "Prompt: How old is someone born in 1990?\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_age', 'result': 35}\n",
      " Took 0.96 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 6: Target Heart Rate ===\n",
      "Prompt: What is the target heart rate for a 30-year-old?\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_target_heart_rate', 'result': 'Target HR Zone: 95-161 bpm'}\n",
      " Took 1.47 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 7: One-Rep Max (Metric) ===\n",
      "Prompt: Estimate one-rep max for lifting 100 kg for 5 reps\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_one_rep_max', 'result': 116.67}\n",
      " Took 1.42 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 8: One-Rep Max (Imperial) ===\n",
      "Prompt: Estimate one-rep max for lifting 220 pounds for 5 reps\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_one_rep_max', 'result': 116.42}\n",
      " Took 1.33 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 9: Calories Burned (Metric) ===\n",
      "Prompt: How many calories does a 70 kg person burn jogging for 30 minutes at MET 7?\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_calories_burned', 'result': 245.0}\n",
      " Took 1.32 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 10: Calories Burned (Imperial) ===\n",
      "Prompt: How many calories does a 154 pound person burn jogging for 30 minutes at MET 7?\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_calories_burned', 'result': 244.49}\n",
      " Took 1.85 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 11: Workout Recommendation ===\n",
      "Prompt: Suggest a workout plan for someone who wants to gain muscle\n",
      "{'type': 'tool_call', 'tool_name': 'recommend_workout', 'result': 'Heavy Lifting 4x/week'}\n",
      " Took 1.26 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 12: VO2 Max Estimation ===\n",
      "Prompt: Estimate VO2 max for running 2.4 kilometers in 12 minutes\n",
      "{'type': 'tool_call', 'tool_name': 'estimate_vo2_max', 'result': 43.5}\n",
      " Took 1.81 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 13: Step Goal Suggestion ===\n",
      "Prompt: Suggest a daily step goal for someone moderately active\n",
      "{'type': 'tool_call', 'tool_name': 'suggest_step_goal', 'result': '7500 steps/day'}\n",
      " Took 1.13 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 14: Rest Days Recommendation ===\n",
      "Prompt: How many rest days are recommended for someone who works out 5 days a week at high intensity?\n",
      "{'type': 'tool_call', 'tool_name': 'recommend_rest_days', 'result': '2 rest days/week'}\n",
      " Took 1.11 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 15: Macronutrient Needs ===\n",
      "Prompt: Calculate macronutrient needs for a 2500 calorie diet aimed at muscle gain\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_macronutrient_needs', 'result': {'Protein (g)': 219, 'Fat (g)': 69, 'Carbs (g)': 250}}\n",
      " Took 1.23 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 16: General Chat (No Tool) ===\n",
      "Prompt: Who was the first president of the USA?\n",
      "{'type': 'chat_response', 'message': '\\n\\nThe first president of the United States was George Washington. He served from April 30, 1789, to March 4, 1797.'}\n",
      " Took 1.22 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 17: General Chat (No Tool) ===\n",
      "Prompt: What is the capital of France?\n",
      "{'type': 'chat_response', 'message': '\\n\\nThe capital of France is Paris.'}\n",
      " Took 1.14 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 18: General Chat (No Tool) ===\n",
      "Prompt: What's the weather like today?\n",
      "{'type': 'chat_response', 'message': \"\\n\\nI don't have access to real-time weather data. You can check a weather website or app for the most accurate and up-to-date information.\"}\n",
      " Took 1.13 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 19: General Chat (No Tool) ===\n",
      "Prompt: How far is the Moon from Earth?\n",
      "{'type': 'chat_response', 'message': \"\\n\\nThe average distance from the Earth to the Moon is about 384,400 kilometers (238,855 miles). This distance can vary slightly due to the Moon's elliptical orbit around the Earth.\"}\n",
      " Took 3.69 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 20: Prime Check ===\n",
      "Prompt: Is 29 a prime number?\n",
      "{'type': 'tool_call', 'tool_name': 'is_prime', 'result': True}\n",
      " Took 1.03 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 21: Temperature Conversion ===\n",
      "Prompt: Convert 30 degrees Celsius to Fahrenheit\n",
      "{'type': 'tool_call', 'tool_name': 'convert_celsius_to_fahrenheit', 'result': 86.0}\n",
      " Took 1.12 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 22: Create Plotly Chart ===\n",
      "Prompt: Create a chart showing ['Running', 'Cycling', 'Swimming'] with times [30, 45, 25] titled 'Weekly Exercise Time'\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "bar",
         "x": [
          "Running",
          "Cycling",
          "Swimming"
         ],
         "y": [
          30,
          45,
          25
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Weekly Exercise Time"
        },
        "xaxis": {
         "title": {
          "text": "Labels"
         }
        },
        "yaxis": {
         "title": {
          "text": "Values"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'tool_call', 'tool_name': 'create_plotly_chart', 'result': 'Chart displayed successfully.'}\n",
      " Took 2.16 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Example 23: Espresso Ingredients Calculation ===\n",
      "Prompt: Please calculate the ingredients for a perfect espresso-based drink.\n",
      "{'type': 'chat_response', 'message': \"\\n\\nTo create a perfect espresso-based drink, you'll typically need the following ingredients:\\n\\n1. **Espresso**: \\n   - Freshly ground coffee beans (about 18-20 grams for a double shot)\\n   - Water (about 30-40 ml for a double shot)\\n\\n2. **Milk** (if making a milk-based drink like a latte or cappuccino):\\n   - Whole milk or your choice of milk (about 150-200 ml, depending on the drink)\\n\\n3. **Flavoring (optional)**:\\n   - Sugar or sweetener (to taste)\\n   - Syrups (like vanilla, caramel, or hazelnut, if desired)\\n\\n4. **Toppings (optional)**:\\n   - Cocoa powder or cinnamon (for dusting)\\n   - Whipped cream (for certain drinks)\\n\\n### Basic Recipe for a Latte:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Milk**: 150-200 ml of steamed milk\\n- **Optional**: Sugar or flavored syrup to taste\\n\\n### Basic Recipe for a Cappuccino:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Milk**: 100 ml of steamed milk and 100 ml of milk foam\\n- **Optional**: Cocoa powder or cinnamon for dusting\\n\\n### Basic Recipe for an Americano:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Water**: 150-200 ml of hot water added to the espresso\\n\\nFeel free to adjust the quantities based on your taste preferences and the size of the drink you want to make!\"}\n",
      " Took 6.95 seconds\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example #</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Description</th>\n",
       "      <th>Result Type</th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Result / Message</th>\n",
       "      <th>Status</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Elapsed Seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Calculate BMI for someone who weighs 75 kg and is 180 cm tall</td>\n",
       "      <td>BMI (Metric)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_bmi</td>\n",
       "      <td>23.15</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:11</td>\n",
       "      <td>2025-05-08 16:46:12</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Calculate BMI for someone who weighs 165 pounds and is 70 inches tall</td>\n",
       "      <td>BMI (Imperial)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_bmi</td>\n",
       "      <td>23.67</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:12</td>\n",
       "      <td>2025-05-08 16:46:14</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How much water should a 70 kg person drink daily?</td>\n",
       "      <td>Water Intake (Metric)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_water_intake</td>\n",
       "      <td>2.31 liters/day</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:14</td>\n",
       "      <td>2025-05-08 16:46:15</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How much water should a 154 pound person drink daily?</td>\n",
       "      <td>Water Intake (Imperial)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_water_intake</td>\n",
       "      <td>2.31 liters/day</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:15</td>\n",
       "      <td>2025-05-08 16:46:16</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How old is someone born in 1990?</td>\n",
       "      <td>Age Calculation</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_age</td>\n",
       "      <td>35</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:16</td>\n",
       "      <td>2025-05-08 16:46:17</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>What is the target heart rate for a 30-year-old?</td>\n",
       "      <td>Target Heart Rate</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_target_heart_rate</td>\n",
       "      <td>Target HR Zone: 95-161 bpm</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:17</td>\n",
       "      <td>2025-05-08 16:46:18</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Estimate one-rep max for lifting 100 kg for 5 reps</td>\n",
       "      <td>One-Rep Max (Metric)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_one_rep_max</td>\n",
       "      <td>116.67</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:18</td>\n",
       "      <td>2025-05-08 16:46:20</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Estimate one-rep max for lifting 220 pounds for 5 reps</td>\n",
       "      <td>One-Rep Max (Imperial)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_one_rep_max</td>\n",
       "      <td>116.42</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:20</td>\n",
       "      <td>2025-05-08 16:46:21</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>How many calories does a 70 kg person burn jogging for 30 minutes at MET 7?</td>\n",
       "      <td>Calories Burned (Metric)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_calories_burned</td>\n",
       "      <td>245.0</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:21</td>\n",
       "      <td>2025-05-08 16:46:23</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>How many calories does a 154 pound person burn jogging for 30 minutes at MET 7?</td>\n",
       "      <td>Calories Burned (Imperial)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_calories_burned</td>\n",
       "      <td>244.49</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:23</td>\n",
       "      <td>2025-05-08 16:46:24</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Suggest a workout plan for someone who wants to gain muscle</td>\n",
       "      <td>Workout Recommendation</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>recommend_workout</td>\n",
       "      <td>Heavy Lifting 4x/week</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:24</td>\n",
       "      <td>2025-05-08 16:46:26</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Estimate VO2 max for running 2.4 kilometers in 12 minutes</td>\n",
       "      <td>VO2 Max Estimation</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>estimate_vo2_max</td>\n",
       "      <td>43.5</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:26</td>\n",
       "      <td>2025-05-08 16:46:27</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Suggest a daily step goal for someone moderately active</td>\n",
       "      <td>Step Goal Suggestion</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>suggest_step_goal</td>\n",
       "      <td>7500 steps/day</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:27</td>\n",
       "      <td>2025-05-08 16:46:29</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>How many rest days are recommended for someone who works out 5 days a week at high intensity?</td>\n",
       "      <td>Rest Days Recommendation</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>recommend_rest_days</td>\n",
       "      <td>2 rest days/week</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:29</td>\n",
       "      <td>2025-05-08 16:46:30</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Calculate macronutrient needs for a 2500 calorie diet aimed at muscle gain</td>\n",
       "      <td>Macronutrient Needs</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_macronutrient_needs</td>\n",
       "      <td>{'Protein (g)': 219, 'Fat (g)': 69, 'Carbs (g)': 250}</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:30</td>\n",
       "      <td>2025-05-08 16:46:31</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Who was the first president of the USA?</td>\n",
       "      <td>General Chat (No Tool)</td>\n",
       "      <td>chat_response</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington. He served from April 30, 1789, to March 4, 1797.</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:31</td>\n",
       "      <td>2025-05-08 16:46:32</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>General Chat (No Tool)</td>\n",
       "      <td>chat_response</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\nThe capital of France is Paris.</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:32</td>\n",
       "      <td>2025-05-08 16:46:33</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>What's the weather like today?</td>\n",
       "      <td>General Chat (No Tool)</td>\n",
       "      <td>chat_response</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\nI don't have access to real-time weather data. You can check a weather website or app for the most accurate and up-to-date information.</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:33</td>\n",
       "      <td>2025-05-08 16:46:34</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>How far is the Moon from Earth?</td>\n",
       "      <td>General Chat (No Tool)</td>\n",
       "      <td>chat_response</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\nThe average distance from the Earth to the Moon is about 384,400 kilometers (238,855 miles). This distance can vary slightly due to the Moon's elliptical orbit around the Earth.</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:34</td>\n",
       "      <td>2025-05-08 16:46:38</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Is 29 a prime number?</td>\n",
       "      <td>Prime Check</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>is_prime</td>\n",
       "      <td>True</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:38</td>\n",
       "      <td>2025-05-08 16:46:39</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Convert 30 degrees Celsius to Fahrenheit</td>\n",
       "      <td>Temperature Conversion</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>convert_celsius_to_fahrenheit</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:39</td>\n",
       "      <td>2025-05-08 16:46:40</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Create a chart showing ['Running', 'Cycling', 'Swimming'] with times [30, 45, 25] titled 'Weekly Exercise Time'</td>\n",
       "      <td>Create Plotly Chart</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>create_plotly_chart</td>\n",
       "      <td>Chart displayed successfully.</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:40</td>\n",
       "      <td>2025-05-08 16:46:42</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Please calculate the ingredients for a perfect espresso-based drink.</td>\n",
       "      <td>Espresso Ingredients Calculation</td>\n",
       "      <td>chat_response</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\nTo create a perfect espresso-based drink, you'll typically need the following ingredients:\\n\\n1. **Espresso**: \\n   - Freshly ground coffee beans (about 18-20 grams for a double shot)\\n   - Water (about 30-40 ml for a double shot)\\n\\n2. **Milk** (if making a milk-based drink like a latte or cappuccino):\\n   - Whole milk or your choice of milk (about 150-200 ml, depending on the drink)\\n\\n3. **Flavoring (optional)**:\\n   - Sugar or sweetener (to taste)\\n   - Syrups (like vanilla, caramel, or hazelnut, if desired)\\n\\n4. **Toppings (optional)**:\\n   - Cocoa powder or cinnamon (for dusting)\\n   - Whipped cream (for certain drinks)\\n\\n### Basic Recipe for a Latte:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Milk**: 150-200 ml of steamed milk\\n- **Optional**: Sugar or flavored syrup to taste\\n\\n### Basic Recipe for a Cappuccino:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Milk**: 100 ml of steamed milk and 100 ml of milk foam\\n- **Optional**: Cocoa powder or cinnamon for dusting\\n\\n### Basic Recipe for an Americano:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Water**: 150-200 ml of hot water added to the espresso\\n\\nFeel free to adjust the quantities based on your taste preferences and the size of the drink you want to make!</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:42</td>\n",
       "      <td>2025-05-08 16:46:49</td>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Example #  \\\n",
       "0           1   \n",
       "1           2   \n",
       "2           3   \n",
       "3           4   \n",
       "4           5   \n",
       "5           6   \n",
       "6           7   \n",
       "7           8   \n",
       "8           9   \n",
       "9          10   \n",
       "10         11   \n",
       "11         12   \n",
       "12         13   \n",
       "13         14   \n",
       "14         15   \n",
       "15         16   \n",
       "16         17   \n",
       "17         18   \n",
       "18         19   \n",
       "19         20   \n",
       "20         21   \n",
       "21         22   \n",
       "22         23   \n",
       "\n",
       "                                                                                                             Prompt  \\\n",
       "0                                                     Calculate BMI for someone who weighs 75 kg and is 180 cm tall   \n",
       "1                                             Calculate BMI for someone who weighs 165 pounds and is 70 inches tall   \n",
       "2                                                                 How much water should a 70 kg person drink daily?   \n",
       "3                                                             How much water should a 154 pound person drink daily?   \n",
       "4                                                                                  How old is someone born in 1990?   \n",
       "5                                                                  What is the target heart rate for a 30-year-old?   \n",
       "6                                                                Estimate one-rep max for lifting 100 kg for 5 reps   \n",
       "7                                                            Estimate one-rep max for lifting 220 pounds for 5 reps   \n",
       "8                                       How many calories does a 70 kg person burn jogging for 30 minutes at MET 7?   \n",
       "9                                   How many calories does a 154 pound person burn jogging for 30 minutes at MET 7?   \n",
       "10                                                      Suggest a workout plan for someone who wants to gain muscle   \n",
       "11                                                        Estimate VO2 max for running 2.4 kilometers in 12 minutes   \n",
       "12                                                          Suggest a daily step goal for someone moderately active   \n",
       "13                    How many rest days are recommended for someone who works out 5 days a week at high intensity?   \n",
       "14                                       Calculate macronutrient needs for a 2500 calorie diet aimed at muscle gain   \n",
       "15                                                                          Who was the first president of the USA?   \n",
       "16                                                                                   What is the capital of France?   \n",
       "17                                                                                   What's the weather like today?   \n",
       "18                                                                                  How far is the Moon from Earth?   \n",
       "19                                                                                            Is 29 a prime number?   \n",
       "20                                                                         Convert 30 degrees Celsius to Fahrenheit   \n",
       "21  Create a chart showing ['Running', 'Cycling', 'Swimming'] with times [30, 45, 25] titled 'Weekly Exercise Time'   \n",
       "22                                             Please calculate the ingredients for a perfect espresso-based drink.   \n",
       "\n",
       "                         Description    Result Type  \\\n",
       "0                       BMI (Metric)      tool_call   \n",
       "1                     BMI (Imperial)      tool_call   \n",
       "2              Water Intake (Metric)      tool_call   \n",
       "3            Water Intake (Imperial)      tool_call   \n",
       "4                    Age Calculation      tool_call   \n",
       "5                  Target Heart Rate      tool_call   \n",
       "6               One-Rep Max (Metric)      tool_call   \n",
       "7             One-Rep Max (Imperial)      tool_call   \n",
       "8           Calories Burned (Metric)      tool_call   \n",
       "9         Calories Burned (Imperial)      tool_call   \n",
       "10            Workout Recommendation      tool_call   \n",
       "11                VO2 Max Estimation      tool_call   \n",
       "12              Step Goal Suggestion      tool_call   \n",
       "13          Rest Days Recommendation      tool_call   \n",
       "14               Macronutrient Needs      tool_call   \n",
       "15            General Chat (No Tool)  chat_response   \n",
       "16            General Chat (No Tool)  chat_response   \n",
       "17            General Chat (No Tool)  chat_response   \n",
       "18            General Chat (No Tool)  chat_response   \n",
       "19                       Prime Check      tool_call   \n",
       "20            Temperature Conversion      tool_call   \n",
       "21               Create Plotly Chart      tool_call   \n",
       "22  Espresso Ingredients Calculation  chat_response   \n",
       "\n",
       "                        Tool Name  \\\n",
       "0                   calculate_bmi   \n",
       "1                   calculate_bmi   \n",
       "2          calculate_water_intake   \n",
       "3          calculate_water_intake   \n",
       "4                   calculate_age   \n",
       "5     calculate_target_heart_rate   \n",
       "6           calculate_one_rep_max   \n",
       "7           calculate_one_rep_max   \n",
       "8       calculate_calories_burned   \n",
       "9       calculate_calories_burned   \n",
       "10              recommend_workout   \n",
       "11               estimate_vo2_max   \n",
       "12              suggest_step_goal   \n",
       "13            recommend_rest_days   \n",
       "14  calculate_macronutrient_needs   \n",
       "15                           None   \n",
       "16                           None   \n",
       "17                           None   \n",
       "18                           None   \n",
       "19                       is_prime   \n",
       "20  convert_celsius_to_fahrenheit   \n",
       "21            create_plotly_chart   \n",
       "22                           None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Result / Message  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   23.15   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   23.67   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2.31 liters/day   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2.31 liters/day   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      35   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Target HR Zone: 95-161 bpm   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  116.67   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  116.42   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   245.0   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  244.49   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Heavy Lifting 4x/week   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   43.5   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         7500 steps/day   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2 rest days/week   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'Protein (g)': 219, 'Fat (g)': 69, 'Carbs (g)': 250}   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \\n\\nThe first president of the United States was George Washington. He served from April 30, 1789, to March 4, 1797.   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \\n\\nThe capital of France is Paris.   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \\n\\nI don't have access to real-time weather data. You can check a weather website or app for the most accurate and up-to-date information.   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \\n\\nThe average distance from the Earth to the Moon is about 384,400 kilometers (238,855 miles). This distance can vary slightly due to the Moon's elliptical orbit around the Earth.   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   True   \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   86.0   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Chart displayed successfully.   \n",
       "22  \\n\\nTo create a perfect espresso-based drink, you'll typically need the following ingredients:\\n\\n1. **Espresso**: \\n   - Freshly ground coffee beans (about 18-20 grams for a double shot)\\n   - Water (about 30-40 ml for a double shot)\\n\\n2. **Milk** (if making a milk-based drink like a latte or cappuccino):\\n   - Whole milk or your choice of milk (about 150-200 ml, depending on the drink)\\n\\n3. **Flavoring (optional)**:\\n   - Sugar or sweetener (to taste)\\n   - Syrups (like vanilla, caramel, or hazelnut, if desired)\\n\\n4. **Toppings (optional)**:\\n   - Cocoa powder or cinnamon (for dusting)\\n   - Whipped cream (for certain drinks)\\n\\n### Basic Recipe for a Latte:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Milk**: 150-200 ml of steamed milk\\n- **Optional**: Sugar or flavored syrup to taste\\n\\n### Basic Recipe for a Cappuccino:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Milk**: 100 ml of steamed milk and 100 ml of milk foam\\n- **Optional**: Cocoa powder or cinnamon for dusting\\n\\n### Basic Recipe for an Americano:\\n- **Espresso**: 18-20 grams of coffee beans, 30-40 ml of water\\n- **Water**: 150-200 ml of hot water added to the espresso\\n\\nFeel free to adjust the quantities based on your taste preferences and the size of the drink you want to make!   \n",
       "\n",
       "     Status           Start Time             End Time  Elapsed Seconds  \n",
       "0   Success  2025-05-08 16:46:11  2025-05-08 16:46:12             1.04  \n",
       "1   Success  2025-05-08 16:46:12  2025-05-08 16:46:14             1.51  \n",
       "2   Success  2025-05-08 16:46:14  2025-05-08 16:46:15             1.23  \n",
       "3   Success  2025-05-08 16:46:15  2025-05-08 16:46:16             0.97  \n",
       "4   Success  2025-05-08 16:46:16  2025-05-08 16:46:17             0.96  \n",
       "5   Success  2025-05-08 16:46:17  2025-05-08 16:46:18             1.47  \n",
       "6   Success  2025-05-08 16:46:18  2025-05-08 16:46:20             1.42  \n",
       "7   Success  2025-05-08 16:46:20  2025-05-08 16:46:21             1.33  \n",
       "8   Success  2025-05-08 16:46:21  2025-05-08 16:46:23             1.32  \n",
       "9   Success  2025-05-08 16:46:23  2025-05-08 16:46:24             1.85  \n",
       "10  Success  2025-05-08 16:46:24  2025-05-08 16:46:26             1.26  \n",
       "11  Success  2025-05-08 16:46:26  2025-05-08 16:46:27             1.81  \n",
       "12  Success  2025-05-08 16:46:27  2025-05-08 16:46:29             1.13  \n",
       "13  Success  2025-05-08 16:46:29  2025-05-08 16:46:30             1.11  \n",
       "14  Success  2025-05-08 16:46:30  2025-05-08 16:46:31             1.23  \n",
       "15  Success  2025-05-08 16:46:31  2025-05-08 16:46:32             1.22  \n",
       "16  Success  2025-05-08 16:46:32  2025-05-08 16:46:33             1.14  \n",
       "17  Success  2025-05-08 16:46:33  2025-05-08 16:46:34             1.13  \n",
       "18  Success  2025-05-08 16:46:34  2025-05-08 16:46:38             3.69  \n",
       "19  Success  2025-05-08 16:46:38  2025-05-08 16:46:39             1.03  \n",
       "20  Success  2025-05-08 16:46:39  2025-05-08 16:46:40             1.12  \n",
       "21  Success  2025-05-08 16:46:40  2025-05-08 16:46:42             2.16  \n",
       "22  Success  2025-05-08 16:46:42  2025-05-08 16:46:49             6.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)  # Create a PrettyPrinter instance with an indent of 2 spaces for better readability.\n",
    "\n",
    "# === TOOL BUILDER ===\n",
    "def build_tool(name, description, parameters, required):\n",
    "    \"\"\"\n",
    "    Builds a tool definition in the format expected by the language model.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the tool.\n",
    "        description (str): A description of what the tool does.\n",
    "        parameters (dict): A dictionary defining the parameters the tool accepts.\n",
    "                         Each parameter is defined with a 'type' and 'description'.\n",
    "        required (list): A list of parameter names that are required.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the tool, ready to be used by the language model.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"type\": \"function\",  # Specifies that this is a function-based tool.\n",
    "        \"function\": {\n",
    "            \"name\": name,  # The name of the function.\n",
    "            \"description\": description,  # A description of what the function does.\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",  # The parameters are defined as a JSON object.\n",
    "                \"properties\": parameters,  # The properties of the object, defining each parameter.\n",
    "                \"required\": required  # A list of required parameter names.\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# === TOOL DEFINITIONS ===\n",
    "available_tools = [\n",
    "    build_tool(\"calculate_bmi\", \"Calculates Body Mass Index (BMI)\",\n",
    "               {\n",
    "                   \"weight_kg\": {\"type\": \"number\", \"description\": \"Weight in kilograms\"},\n",
    "                   \"height_cm\": {\"type\": \"number\", \"description\": \"Height in centimeters\"}\n",
    "               },\n",
    "               [\"weight_kg\", \"height_cm\"]),\n",
    "\n",
    "    build_tool(\"convert_celsius_to_fahrenheit\", \"Converts Celsius to Fahrenheit\",\n",
    "               {\n",
    "                   \"celsius\": {\"type\": \"number\", \"description\": \"Temperature in Celsius\"}\n",
    "               },\n",
    "               [\"celsius\"]),\n",
    "\n",
    "    build_tool(\"calculate_age\", \"Calculates age from birth year\",\n",
    "               {\n",
    "                   \"birth_year\": {\"type\": \"number\", \"description\": \"Birth year\"}\n",
    "               },\n",
    "               [\"birth_year\"]),\n",
    "\n",
    "    build_tool(\"is_prime\", \"Checks if a number is prime\",\n",
    "               {\n",
    "                   \"number\": {\"type\": \"number\", \"description\": \"Number to check\"}\n",
    "               },\n",
    "               [\"number\"]),\n",
    "\n",
    "    build_tool(\"calculate_calories_burned\", \"Estimates calories burned\",\n",
    "               {\n",
    "                   \"weight_kg\": {\"type\": \"number\", \"description\": \"Weight in kilograms\"},\n",
    "                   \"met_value\": {\"type\": \"number\", \"description\": \"MET value of activity\"},\n",
    "                   \"duration_minutes\": {\"type\": \"number\", \"description\": \"Duration in minutes\"}\n",
    "               },\n",
    "               [\"weight_kg\", \"met_value\", \"duration_minutes\"]),\n",
    "\n",
    "    build_tool(\"recommend_workout\", \"Suggests workout based on goal\",\n",
    "               {\n",
    "                   \"goal\": {\"type\": \"string\", \"description\": \"Fitness goal\"}\n",
    "               },\n",
    "               [\"goal\"]),\n",
    "\n",
    "    build_tool(\"estimate_vo2_max\", \"Estimates VO2 max from run data\",\n",
    "               {\n",
    "                   \"time_minutes\": {\"type\": \"number\", \"description\": \"Time in minutes\"},\n",
    "                   \"distance_km\": {\"type\": \"number\", \"description\": \"Distance in kilometers\"}\n",
    "               },\n",
    "               [\"time_minutes\", \"distance_km\"]),\n",
    "\n",
    "    build_tool(\"calculate_target_heart_rate\", \"Calculates target heart rate\",\n",
    "               {\n",
    "                   \"age\": {\"type\": \"number\", \"description\": \"Age in years\"}\n",
    "               },\n",
    "               [\"age\"]),\n",
    "\n",
    "    build_tool(\"calculate_one_rep_max\", \"Estimates 1-rep max from weight and reps\",\n",
    "               {\n",
    "                   \"weight_kg\": {\"type\": \"number\", \"description\": \"Weight lifted\"},\n",
    "                   \"reps\": {\"type\": \"number\", \"description\": \"Number of reps\"}\n",
    "               },\n",
    "               [\"weight_kg\", \"reps\"]),\n",
    "\n",
    "    build_tool(\"calculate_macronutrient_needs\", \"Calculates daily macronutrient needs\",\n",
    "               {\n",
    "                   \"calories\": {\"type\": \"number\", \"description\": \"Daily caloric intake\"},\n",
    "                   \"goal\": {\"type\": \"string\", \"description\": \"Goal like 'muscle gain'\"}\n",
    "               },\n",
    "               [\"calories\", \"goal\"]),\n",
    "\n",
    "    build_tool(\"suggest_step_goal\", \"Suggests daily step goal based on activity\",\n",
    "               {\n",
    "                   \"activity_level\": {\"type\": \"string\", \"description\": \"Activity level (e.g., 'moderate')\"}\n",
    "               },\n",
    "               [\"activity_level\"]),\n",
    "\n",
    "    build_tool(\"calculate_water_intake\", \"Calculates recommended daily water intake\",\n",
    "               {\n",
    "                   \"weight_kg\": {\"type\": \"number\", \"description\": \"Weight in kilograms\"}\n",
    "               },\n",
    "               [\"weight_kg\"]),\n",
    "\n",
    "    build_tool(\"recommend_rest_days\", \"Recommends rest days based on workout frequency and intensity\",\n",
    "               {\n",
    "                   \"workouts_per_week\": {\"type\": \"number\", \"description\": \"Number of workouts per week\"},\n",
    "                   \"intensity_level\": {\"type\": \"string\", \"description\": \"Intensity level (e.g., 'high')\"}\n",
    "               },\n",
    "               [\"workouts_per_week\", \"intensity_level\"]),\n",
    "\n",
    "    build_tool(\"create_plotly_chart\", \"Creates a basic Plotly bar chart\",\n",
    "               {\n",
    "                   \"labels\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"List of labels\"},\n",
    "                   \"values\": {\"type\": \"array\", \"items\": {\"type\": \"number\"}, \"description\": \"Corresponding values\"},\n",
    "                   \"title\": {\"type\": \"string\", \"description\": \"Chart title\"}\n",
    "               },\n",
    "               [\"labels\", \"values\", \"title\"])\n",
    "]\n",
    "\n",
    "# === TOOL EXECUTION FUNCTIONS ===\n",
    "def calculate_bmi(args):\n",
    "    \"\"\"\n",
    "    Calculates the Body Mass Index (BMI).\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'weight_kg' (weight in kilograms) and 'height_cm' (height in centimeters).\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated BMI, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    return round(args[\"weight_kg\"] / ((args[\"height_cm\"] / 100) ** 2), 2)\n",
    "\n",
    "def convert_celsius_to_fahrenheit(args):\n",
    "    \"\"\"\n",
    "    Converts Celsius to Fahrenheit.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'celsius' (temperature in Celsius).\n",
    "\n",
    "    Returns:\n",
    "        float: The converted temperature in Fahrenheit, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    return round((args[\"celsius\"] * 9/5) + 32, 2)\n",
    "\n",
    "def calculate_age(args):\n",
    "    \"\"\"\n",
    "    Calculates age based on the birth year.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'birth_year' (the year of birth).\n",
    "\n",
    "    Returns:\n",
    "        int: The calculated age.\n",
    "    \"\"\"\n",
    "    return datetime.now().year - args[\"birth_year\"]\n",
    "\n",
    "def is_prime(args):\n",
    "    \"\"\"\n",
    "    Checks if a number is prime.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'number' (the number to check).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the number is prime, False otherwise.\n",
    "    \"\"\"\n",
    "    n = args[\"number\"]\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    return all(n % i for i in range(2, int(n**0.5) + 1))\n",
    "\n",
    "def calculate_calories_burned(args):\n",
    "    \"\"\"\n",
    "    Calculates the estimated calories burned during an activity.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'weight_kg' (weight in kilograms), 'met_value' (MET value of the activity),\n",
    "                     and 'duration_minutes' (duration of the activity in minutes).\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated calories burned, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    return round(args[\"met_value\"] * args[\"weight_kg\"] * (args[\"duration_minutes\"] / 60), 2)\n",
    "\n",
    "def recommend_workout(args):\n",
    "    \"\"\"\n",
    "    Recommends a workout plan based on the fitness goal.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'goal' (the fitness goal).\n",
    "\n",
    "    Returns:\n",
    "        str: A recommended workout plan based on the goal.\n",
    "    \"\"\"\n",
    "    goal = args[\"goal\"].lower()\n",
    "    if \"weight\" in goal:\n",
    "        return \"HIIT + Strength Training 3x/week\"\n",
    "    if \"muscle\" in goal:\n",
    "        return \"Heavy Lifting 4x/week\"\n",
    "    if \"endurance\" in goal:\n",
    "        return \"Running + Cross-training 5x/week\"\n",
    "    return \"Mixed training 3-4x/week\"\n",
    "\n",
    "def estimate_vo2_max(args):\n",
    "    \"\"\"\n",
    "    Estimates VO2 max based on running data.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'time_minutes' (time in minutes) and 'distance_km' (distance in kilometers).\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated VO2 max, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    return round(((args[\"distance_km\"] * 1000) / args[\"time_minutes\"]) * 0.2 + 3.5, 2)\n",
    "\n",
    "def calculate_target_heart_rate(args):\n",
    "    \"\"\"\n",
    "    Calculates the target heart rate zone based on age.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'age' (age in years).\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the target heart rate zone.\n",
    "    \"\"\"\n",
    "    max_hr = 220 - args[\"age\"]\n",
    "    return f\"Target HR Zone: {int(max_hr*0.5)}-{int(max_hr*0.85)} bpm\"\n",
    "\n",
    "def calculate_one_rep_max(args):\n",
    "    \"\"\"\n",
    "    Estimates the one-rep max (1RM) based on weight lifted and number of reps.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'weight_kg' (weight lifted in kilograms) and 'reps' (number of repetitions).\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated one-rep max, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    return round(args[\"weight_kg\"] * (1 + args[\"reps\"] / 30), 2)\n",
    "\n",
    "def calculate_macronutrient_needs(args):\n",
    "    \"\"\"\n",
    "    Calculates the daily macronutrient needs based on caloric intake and fitness goal.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'calories' (daily caloric intake) and 'goal' (fitness goal).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the recommended grams of protein, fat, and carbohydrates.\n",
    "    \"\"\"\n",
    "    goal = args[\"goal\"].lower()\n",
    "    if \"muscle\" in goal:\n",
    "        p, f, c = 0.35, 0.25, 0.4\n",
    "    elif \"weight\" in goal:\n",
    "        p, f, c = 0.4, 0.3, 0.3\n",
    "    else:\n",
    "        p, f, c = 0.3, 0.25, 0.45\n",
    "    return {\n",
    "        \"Protein (g)\": round((args[\"calories\"] * p) / 4),\n",
    "        \"Fat (g)\": round((args[\"calories\"] * f) / 9),\n",
    "        \"Carbs (g)\": round((args[\"calories\"] * c) / 4)\n",
    "    }\n",
    "\n",
    "def suggest_step_goal(args):\n",
    "    \"\"\"\n",
    "    Suggests a daily step goal based on activity level.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'activity_level' (activity level, e.g., 'moderate').\n",
    "\n",
    "    Returns:\n",
    "        str: A suggested daily step goal.\n",
    "    \"\"\"\n",
    "    level = args[\"activity_level\"].lower()\n",
    "    return {\n",
    "        \"sedentary\": \"5000 steps/day\",\n",
    "        \"moderate\": \"7500 steps/day\",\n",
    "        \"active\": \"10000+ steps/day\"\n",
    "    }.get(level, \"7000-10000 steps/day\")\n",
    "\n",
    "def calculate_water_intake(args):\n",
    "    \"\"\"\n",
    "    Calculates the recommended daily water intake based on weight.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'weight_kg' (weight in kilograms).\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the recommended daily water intake in liters.\n",
    "    \"\"\"\n",
    "    return f\"{round(args['weight_kg'] * 0.033, 2)} liters/day\"\n",
    "\n",
    "def recommend_rest_days(args):\n",
    "    \"\"\"\n",
    "    Recommends the number of rest days based on workout frequency and intensity.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'workouts_per_week' (number of workouts per week) and\n",
    "                     'intensity_level' (intensity level, e.g., 'high').\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the recommended number of rest days per week.\n",
    "    \"\"\"\n",
    "    intensity = args[\"intensity_level\"].lower()\n",
    "    workouts = args[\"workouts_per_week\"]\n",
    "    if \"high\" in intensity:\n",
    "        return f\"{2 if workouts >= 5 else 1} rest days/week\"\n",
    "    if \"moderate\" in intensity:\n",
    "        return f\"{1 if workouts >= 4 else 2} rest days/week\"\n",
    "    return \"1 rest day/week\"\n",
    "\n",
    "def create_plotly_chart(args):\n",
    "    \"\"\"\n",
    "    Creates and displays a basic Plotly bar chart.\n",
    "\n",
    "    Args:\n",
    "        args (dict): A dictionary containing 'labels' (list of labels), 'values' (list of corresponding values),\n",
    "                     and 'title' (chart title).\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating that the chart has been displayed.\n",
    "    \"\"\"\n",
    "    fig = go.Figure([go.Bar(x=args[\"labels\"], y=args[\"values\"])])  # Create a bar chart figure.\n",
    "    fig.update_layout(title=args[\"title\"], xaxis_title=\"Labels\", yaxis_title=\"Values\")  # Update the layout with title and axis labels.\n",
    "    fig.show()  # Display the chart.\n",
    "    return \"Chart displayed successfully.\"\n",
    "\n",
    "\n",
    "# Map tool names to execution handlers\n",
    "tool_execution_map = {\n",
    "    \"calculate_bmi\": calculate_bmi,\n",
    "    \"convert_celsius_to_fahrenheit\": convert_celsius_to_fahrenheit,\n",
    "    \"calculate_age\": calculate_age,\n",
    "    \"is_prime\": is_prime,\n",
    "    \"calculate_calories_burned\": calculate_calories_burned,\n",
    "    \"recommend_workout\": recommend_workout,\n",
    "    \"estimate_vo2_max\": estimate_vo2_max,\n",
    "    \"calculate_target_heart_rate\": calculate_target_heart_rate,\n",
    "    \"calculate_one_rep_max\": calculate_one_rep_max,\n",
    "    \"calculate_macronutrient_needs\": calculate_macronutrient_needs,\n",
    "    \"suggest_step_goal\": suggest_step_goal,\n",
    "    \"calculate_water_intake\": calculate_water_intake,\n",
    "    \"recommend_rest_days\": recommend_rest_days,\n",
    "    \"create_plotly_chart\": create_plotly_chart\n",
    "}\n",
    "\n",
    "# === TOOL EXECUTOR ===\n",
    "def execute_tool_call(tool_call):\n",
    "    \"\"\"\n",
    "    Executes a tool call based on the provided tool call definition.\n",
    "\n",
    "    Args:\n",
    "        tool_call (dict): A dictionary containing the tool's function name and arguments.\n",
    "\n",
    "    Returns:\n",
    "        str or any: The result of the tool execution, or an error message if something goes wrong.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        function_name = tool_call['function']['name']  # Extract the function name from the tool call.\n",
    "        arguments = json.loads(tool_call['function']['arguments'])  # Extract the arguments and parse them from JSON.\n",
    "        handler = tool_execution_map.get(function_name)  # Get the corresponding function handler from the map.\n",
    "        if handler:\n",
    "            return handler(arguments)  # Execute the handler with the arguments and return the result.\n",
    "        return f\"Unknown function: {function_name}\"  # If the function is unknown, return an error message.\n",
    "    except KeyError as e:\n",
    "        return f\"Missing parameter: {e}\"  # If a required parameter is missing, return an error message.\n",
    "    except Exception as e:\n",
    "        return f\"Execution error: {e}\"  # If any other exception occurs during execution, return an error message.\n",
    "\n",
    "# === RUNNING QUERY TO REAL API ===\n",
    "def run_query(message, model=\"gpt-4o-mini\", system_prompt=\"Tool Test\"):\n",
    "    \"\"\"\n",
    "    Runs a query against the language model API.\n",
    "\n",
    "    Args:\n",
    "        message (str): The query message.\n",
    "        model (str): The model to use (default: \"gpt-4o-mini\").\n",
    "        system_prompt (str): The system prompt to use (default: \"Tool Test\").\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the language model API.\n",
    "    \"\"\"\n",
    "    return ask_sage_client.query(\n",
    "        message=message,\n",
    "        model=model,\n",
    "        limit_references=0,\n",
    "        system_prompt=system_prompt,\n",
    "        tools=available_tools\n",
    "    )\n",
    "\n",
    "# === PROCESS RESPONSE ===\n",
    "def process_response(response):\n",
    "    \"\"\"\n",
    "    Processes the response from the language model API.\n",
    "\n",
    "    Args:\n",
    "        response (dict): The response from the language model API.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of outputs, each indicating either a tool call result or a chat response.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "\n",
    "    if response.get('tool_calls'):  # Check if the response contains tool calls.\n",
    "        # print entire response for debugging\n",
    "        # pp.pprint(response)\n",
    "        for call in response['tool_calls']:  # Iterate through each tool call.\n",
    "            result = execute_tool_call(call)  # Execute the tool call and get the result.\n",
    "            outputs.append({\n",
    "                \"type\": \"tool_call\",  # Indicate that this output is a tool call result.\n",
    "                \"tool_name\": call['function']['name'],  # Store the name of the tool.\n",
    "                \"result\": result  # Store the result of the tool execution.\n",
    "            })\n",
    "    else:\n",
    "        outputs.append({\n",
    "            \"type\": \"chat_response\",  # Indicate that this output is a chat response.\n",
    "            \"message\": response.get('message', 'No message found.')  # Store the chat message, or a default message if none is found.\n",
    "        })\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# === RUN A FEW EXAMPLES AND SAVE TO DATAFRAME WITH TIMING ===\n",
    "def run_examples_to_dataframe():\n",
    "    \"\"\"\n",
    "    Runs a series of example prompts, prints live results, measures timings, and collects into a dataframe.\n",
    "    \"\"\"\n",
    "    examples = [\n",
    "        (\"Calculate BMI for someone who weighs 75 kg and is 180 cm tall\", \"BMI (Metric)\"),\n",
    "        (\"Calculate BMI for someone who weighs 165 pounds and is 70 inches tall\", \"BMI (Imperial)\"),\n",
    "        (\"How much water should a 70 kg person drink daily?\", \"Water Intake (Metric)\"),\n",
    "        (\"How much water should a 154 pound person drink daily?\", \"Water Intake (Imperial)\"),\n",
    "        (\"How old is someone born in 1990?\", \"Age Calculation\"),\n",
    "        (\"What is the target heart rate for a 30-year-old?\", \"Target Heart Rate\"),\n",
    "        (\"Estimate one-rep max for lifting 100 kg for 5 reps\", \"One-Rep Max (Metric)\"),\n",
    "        (\"Estimate one-rep max for lifting 220 pounds for 5 reps\", \"One-Rep Max (Imperial)\"),\n",
    "        (\"How many calories does a 70 kg person burn jogging for 30 minutes at MET 7?\", \"Calories Burned (Metric)\"),\n",
    "        (\"How many calories does a 154 pound person burn jogging for 30 minutes at MET 7?\", \"Calories Burned (Imperial)\"),\n",
    "        (\"Suggest a workout plan for someone who wants to gain muscle\", \"Workout Recommendation\"),\n",
    "        (\"Estimate VO2 max for running 2.4 kilometers in 12 minutes\", \"VO2 Max Estimation\"),\n",
    "        (\"Suggest a daily step goal for someone moderately active\", \"Step Goal Suggestion\"),\n",
    "        (\"How many rest days are recommended for someone who works out 5 days a week at high intensity?\", \"Rest Days Recommendation\"),\n",
    "        (\"Calculate macronutrient needs for a 2500 calorie diet aimed at muscle gain\", \"Macronutrient Needs\"),\n",
    "        (\"Who was the first president of the USA?\", \"General Chat (No Tool)\"),\n",
    "        (\"What is the capital of France?\", \"General Chat (No Tool)\"),\n",
    "        (\"What's the weather like today?\", \"General Chat (No Tool)\"),\n",
    "        (\"How far is the Moon from Earth?\", \"General Chat (No Tool)\"),\n",
    "        (\"Is 29 a prime number?\", \"Prime Check\"),\n",
    "        (\"Convert 30 degrees Celsius to Fahrenheit\", \"Temperature Conversion\"),\n",
    "        (\"Create a chart showing ['Running', 'Cycling', 'Swimming'] with times [30, 45, 25] titled 'Weekly Exercise Time'\", \"Create Plotly Chart\"),\n",
    "        (\"Please calculate the ingredients for a perfect espresso-based drink.\", \"Espresso Ingredients Calculation\"),\n",
    "    ]\n",
    "\n",
    "    records = []  # List to store all the records\n",
    "\n",
    "    for idx, (prompt_text, description) in enumerate(examples, start=1):\n",
    "        print(f\"\\n=== Example {idx}: {description} ===\")\n",
    "        print(f\"Prompt: {prompt_text}\")\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        start_timestamp = start_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        try:\n",
    "            response = run_query(prompt_text)\n",
    "            results = process_response(response)\n",
    "            status = \"Success\"\n",
    "        except Exception as e:\n",
    "            results = [{\"type\": \"error\", \"message\": str(e)}]\n",
    "            status = \"Error\"\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        end_timestamp = end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        elapsed_seconds = round((end_time - start_time).total_seconds(), 2)\n",
    "\n",
    "        # Print each result live\n",
    "        for res in results:\n",
    "            print(res)\n",
    "            \n",
    "            record = {\n",
    "                \"Example #\": idx,\n",
    "                \"Prompt\": prompt_text,\n",
    "                \"Description\": description,\n",
    "                \"Result Type\": res.get(\"type\"),\n",
    "                \"Tool Name\": res.get(\"tool_name\", None),\n",
    "                \"Result / Message\": res.get(\"result\", res.get(\"message\")),\n",
    "                \"Status\": status,\n",
    "                \"Start Time\": start_timestamp,\n",
    "                \"End Time\": end_timestamp,\n",
    "                \"Elapsed Seconds\": elapsed_seconds\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "        print(f\" Took {elapsed_seconds} seconds\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "# === TRIGGER ===\n",
    "example_run_df = run_examples_to_dataframe()\n",
    "\n",
    "# Display the DataFrame\n",
    "display(example_run_df)  # Display the DataFrame in a readable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #22)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1425648\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #21)  Current End (Stage #22):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 213}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #21)         52405       1425435\n",
      "End (Stage #22)           52405       1425648\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  22)</th>\n",
       "      <td>2925</td>\n",
       "      <td>7565</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (21  22)</th>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  22)               2925              7565          Changed   \n",
       "Prior vs End (21  22)                 0               213        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  22)           Changed  \n",
       "Prior vs End (21  22)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 7565}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 213}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Choice - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tool Choice Example ===\n",
      "Prompt: Please calculate the ingredients for a perfect espresso-based drink.\n",
      "{'type': 'tool_call', 'tool_name': 'calculate_espresso_ingredients', 'result': {'espresso_volume_ml': 30, 'milk_volume_ml': 60.0}}\n",
      " Took 1.09 seconds\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Description</th>\n",
       "      <th>Result Type</th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Result / Message</th>\n",
       "      <th>Status</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Elapsed Seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please calculate the ingredients for a perfect espresso-based drink.</td>\n",
       "      <td>Espresso Ingredients Calculation (Forced Tool Choice)</td>\n",
       "      <td>tool_call</td>\n",
       "      <td>calculate_espresso_ingredients</td>\n",
       "      <td>{'espresso_volume_ml': 30, 'milk_volume_ml': 60.0}</td>\n",
       "      <td>Success</td>\n",
       "      <td>2025-05-08 16:46:50</td>\n",
       "      <td>2025-05-08 16:46:51</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Prompt  \\\n",
       "0  Please calculate the ingredients for a perfect espresso-based drink.   \n",
       "\n",
       "                                             Description Result Type  \\\n",
       "0  Espresso Ingredients Calculation (Forced Tool Choice)   tool_call   \n",
       "\n",
       "                        Tool Name  \\\n",
       "0  calculate_espresso_ingredients   \n",
       "\n",
       "                                     Result / Message   Status  \\\n",
       "0  {'espresso_volume_ml': 30, 'milk_volume_ml': 60.0}  Success   \n",
       "\n",
       "            Start Time             End Time  Elapsed Seconds  \n",
       "0  2025-05-08 16:46:50  2025-05-08 16:46:51             1.09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === NEW TOOL DEFINITION ===\n",
    "calculate_espresso_ingredients_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculate_espresso_ingredients\",\n",
    "        \"description\": \"Calculates the amount of coffee beans and milk needed for a perfect espresso-based drink.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"espresso_shots\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Number of espresso shots (1 shot = 30ml).\"\n",
    "                },\n",
    "                \"milk_ratio\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Milk-to-espresso ratio (e.g., 2.0 means 2x milk volume relative to espresso volume).\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"espresso_shots\", \"milk_ratio\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# === NEW TOOL EXECUTION FUNCTION ===\n",
    "def calculate_espresso_ingredients(args):\n",
    "    espresso_shots = args[\"espresso_shots\"]\n",
    "    milk_ratio = args[\"milk_ratio\"]\n",
    "    \n",
    "    espresso_volume_ml = espresso_shots * 30  # 1 shot = 30ml\n",
    "    milk_volume_ml = espresso_volume_ml * milk_ratio\n",
    "    \n",
    "    return {\n",
    "        \"espresso_volume_ml\": espresso_volume_ml,\n",
    "        \"milk_volume_ml\": round(milk_volume_ml, 2)\n",
    "    }\n",
    "\n",
    "# Add new tool to available tools and execution map\n",
    "updated_tools = available_tools + [calculate_espresso_ingredients_tool]\n",
    "tool_execution_map[\"calculate_espresso_ingredients\"] = calculate_espresso_ingredients\n",
    "\n",
    "# === TOOL CHOICE you are forcing ===\n",
    "tool_choice = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculate_espresso_ingredients\",\n",
    "        \"arguments\": json.dumps({\n",
    "            \"espresso_shots\": 2,\n",
    "            \"milk_ratio\": 2.0\n",
    "        })\n",
    "    }\n",
    "}\n",
    "\n",
    "# === RUN TOOL CHOICE EXAMPLE ===\n",
    "def run_tool_choice_example():\n",
    "    \"\"\"\n",
    "    Runs a dedicated example forcing a specific tool choice, prints live, and collects timing into a dataframe.\n",
    "    \"\"\"\n",
    "    prompt_text = \"Please calculate the ingredients for a perfect espresso-based drink.\"\n",
    "    description = \"Espresso Ingredients Calculation (Forced Tool Choice)\"\n",
    "\n",
    "    print(f\"\\n=== Tool Choice Example ===\")\n",
    "    print(f\"Prompt: {prompt_text}\")\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    start_timestamp = start_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    try:\n",
    "        response = ask_sage_client.query(\n",
    "            message=prompt_text,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            limit_references=0,\n",
    "            system_prompt=\"Tool Test - Espresso Ingredients Calculation\",\n",
    "            tools=updated_tools,\n",
    "            tool_choice=tool_choice  # <-- FORCING the tool\n",
    "        )\n",
    "        results = process_response(response)\n",
    "        status = \"Success\"\n",
    "    except Exception as e:\n",
    "        results = [{\"type\": \"error\", \"message\": str(e)}]\n",
    "        status = \"Error\"\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    end_timestamp = end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    elapsed_seconds = round((end_time - start_time).total_seconds(), 2)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "\n",
    "        record = {\n",
    "            \"Prompt\": prompt_text,\n",
    "            \"Description\": description,\n",
    "            \"Result Type\": res.get(\"type\"),\n",
    "            \"Tool Name\": res.get(\"tool_name\", None),\n",
    "            \"Result / Message\": res.get(\"result\", res.get(\"message\")),\n",
    "            \"Status\": status,\n",
    "            \"Start Time\": start_timestamp,\n",
    "            \"End Time\": end_timestamp,\n",
    "            \"Elapsed Seconds\": elapsed_seconds\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    print(f\" Took {elapsed_seconds} seconds\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "# === TRIGGER ===\n",
    "tool_choice_df = run_tool_choice_example()\n",
    "\n",
    "# Display the DataFrame\n",
    "display(tool_choice_df)  # Display the DataFrame in a readable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #23)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1425658\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #22)  Current End (Stage #23):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 10}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #22)         52405       1425648\n",
      "End (Stage #23)           52405       1425658\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  23)</th>\n",
       "      <td>2925</td>\n",
       "      <td>7575</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (22  23)</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  23)               2925              7575          Changed   \n",
       "Prior vs End (22  23)                 0                10        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  23)           Changed  \n",
       "Prior vs End (22  23)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 7575}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 10}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Query with file\n",
    "\n",
    "This endpoint makes it easy to pass a prompt with the context of a file. The file will be appended to the prompt and the model will be able to use the prompt and context from the file to generate a response.\n",
    "\n",
    "Note: The query_with_file works similar to the query endpoint, but it allows you to pass a file as context. The file will be appended to the prompt and the model will be able to use the prompt and context from the file to generate a response.\n",
    "\n",
    "Here are the parameters for the `query_with_file` endpoint:\n",
    "\n",
    "```python\n",
    "\n",
    "query_with_file(self, message, file=None, persona='default', dataset='all', limit_references=None, temperature=0.0, live=0, model='openai_gpt', tools=None, tool_choice=None)\n",
    "\n",
    "```\n",
    "\n",
    "`file` parameter is the path to the file that will be appended to the prompt.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Passing an entire file as context is not the same as using a dataset. The difference is the entire file is passed as context and the model will be able to use the entire file to generate a response. The dataset is used to perform RAG(Retrieval-Augmented Generation) where the model retrieves information from the dataset to generate responses leveraging sophisticated semantic search capabilities.\n",
    "\n",
    "Limitations with the `query_with_file` endpoint:\n",
    "- It will use more tokens since the entire file is passed as context.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query with file data:\n",
      "<file-content>\n",
      "\n",
      "{\"asksage_metadata\": {\"filename\": \"In the small village of Willowbrook.pdf\", \"page_number\": 1}}\n",
      "In the small village of Willowbrook, there lived a scruffy little dog named Toby who had an unusual dislike for cats. Toby, with his ruffled fur and eager eyes, was known around the village for his playful spirit, but he would always steer clear of any feline. One day, a new cat moved into the neighborhood. The cat, sleek and confident, quickly noticed Toby's aversion. Curious and a bit mischievous, the cat decided to find out why Toby was so hesitant around its kind. This set the stage for a series of amusing encounters, as the cat tried to win over the reluctant Toby, leading to unexpected friendship and adventures that would change Toby's mind about cats forever.\n",
      "\n",
      "</file-content>\n",
      "\n",
      "Toby and Whiskers would eventually become unexpected friends.\n"
     ]
    }
   ],
   "source": [
    "# Data path\n",
    "file_path = 'data/query_with_file/'\n",
    "\n",
    "# Get files in the data path\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "message = 'Would Toby get along with Whiskers? - keep it short use only 10 tokens'\n",
    "\n",
    "# Query with file\n",
    "query_with_file_data = ask_sage_client.query_with_file(\n",
    "    message=message,\n",
    "    file=file_path + files[4],\n",
    "    dataset='none',\n",
    "    limit_references=0\n",
    ")\n",
    "\n",
    "print(\"Query with file data:\")\n",
    "print(query_with_file_data['message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #24)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1425736\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #23)  Current End (Stage #24):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 78}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #23)         52405       1425658\n",
      "End (Stage #24)           52405       1425736\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  24)</th>\n",
       "      <td>2925</td>\n",
       "      <td>7653</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (23  24)</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td> No Change</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  24)               2925              7653          Changed   \n",
       "Prior vs End (23  24)                 0                78        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  24)           Changed  \n",
       "Prior vs End (23  24)          Changed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 7653}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 78}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Delete Dataset\n",
    "\n",
    "This endpoint is used to delete a dataset from the user's account. The only parameter required for this endpoint is the 'dataset', which specifies the specific dataset to delete. \n",
    "\n",
    "Notice how the dataset is no longer in the list of available datasets after deletion.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Running the cell below will clear the dataset from your account.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API response for deleting dataset user_custom_34125_1-jupynotebk-asksage-ex-52_content: {'response': 'OK', 'status': 200}\n",
      "API response for deleting dataset user_custom_34125_2-jupynotebk-asksage-ex-9_content: {'response': 'OK', 'status': 200}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acquisition.gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DoD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Department of Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learn with Nic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In the Nic of Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Platform One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nic Chaillan's Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloud One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIST_NVD_CVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_custom_43841_JFK-Files-March-2025_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_custom_11_Nic-Test_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user_custom_29540_Ask-Sage-Documentation_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_custom_812_Nic-ShareTest10_content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                    Acquisition.gov\n",
       "1                                          Air Force\n",
       "2                                                DoD\n",
       "3                              Department of Defense\n",
       "4                                     Learn with Nic\n",
       "5                                 In the Nic of Time\n",
       "6                                       Platform One\n",
       "7                             Nic Chaillan's Website\n",
       "8                                          Cloud One\n",
       "9                                       NIST_NVD_CVE\n",
       "10                                              Sage\n",
       "11    user_custom_43841_JFK-Files-March-2025_content\n",
       "12                   user_custom_11_Nic-Test_content\n",
       "13  user_custom_29540_Ask-Sage-Documentation_content\n",
       "14           user_custom_812_Nic-ShareTest10_content"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the two datasets that were created in the beginning\n",
    "delete_dataset_1 = ask_sage_client.delete_dataset(dataset_entry_1) # Delete the first dataset\n",
    "print(f\"API response for deleting dataset {dataset_entry_1}: {delete_dataset_1}\") # Print the API response for deleting the first dataset\n",
    "delete_dataset_2 = ask_sage_client.delete_dataset(dataset_entry_2) # Delete the second dataset\n",
    "print(f\"API response for deleting dataset {dataset_entry_2}: {delete_dataset_2}\") # Print the API response for deleting the second dataset\n",
    "\n",
    "display_datasets(ask_sage_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      " Token Volume Report  (Stage #25)\n",
      "--------------------------------------------------\n",
      " Reusing token volume from script start.\n",
      "The count of monthly teach/training tokens used are: 52405\n",
      "The count of monthly inference/query tokens used are: 1425736\n",
      " Token volume recorded *after current script execution*.\n",
      "--------------------------------------------------\n",
      " Change from Prior End (Stage #24)  Current End (Stage #25):\n",
      "{'teach_tokens_diff': 0, 'query_tokens_diff': 0}\n",
      " Token Usage Table:\n",
      "                   teach_tokens  query_tokens\n",
      "Start (Stage #1)          49480       1418083\n",
      "Prior (Stage #24)         52405       1425736\n",
      "End (Stage #25)           52405       1425736\n",
      "--------------------------------------------------\n",
      " Token Volume Comparison Flags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teach_tokens_diff</th>\n",
       "      <th>query_tokens_diff</th>\n",
       "      <th>teach_tokens_flag</th>\n",
       "      <th>query_tokens_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Start vs End (1  25)</th>\n",
       "      <td>2925</td>\n",
       "      <td>7653</td>\n",
       "      <td> Changed</td>\n",
       "      <td> Changed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prior vs End (24  25)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td> No Change</td>\n",
       "      <td> No Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       teach_tokens_diff query_tokens_diff teach_tokens_flag  \\\n",
       "Start vs End (1  25)               2925              7653          Changed   \n",
       "Prior vs End (24  25)                 0                 0        No Change   \n",
       "\n",
       "                       query_tokens_flag  \n",
       "Start vs End (1  25)           Changed  \n",
       "Prior vs End (24  25)        No Change  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Total Token Volume Used Since Script Start:\n",
      "{'teach_tokens_used': 2925, 'query_tokens_used': 7653}\n",
      "==================================================\n",
      " Token Volume Used in This Stage Only:\n",
      "{'teach_tokens_used_this_stage': 0, 'query_tokens_used_this_stage': 0}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------')\n",
    "print_token_volume_report(ask_sage_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
