
# Vocabulary for AI and ML

Welcome to this comprehensive vocabulary resource for Artificial Intelligence (AI) and Machine Learning (ML). This document is designed to assist learners and professionals in understanding and effectively communicating the diverse terminology used in AI and ML. Each term is not only listed but is accompanied by concise definitions, making this a practical guide for everyday use.

Whether you're new to the field or looking to polish your technical language, this document will serve as your go-to reference.

## Table of Contents
- [Vocabulary for AI and ML](#vocabulary-for-ai-and-ml)
  - [Table of Contents](#table-of-contents)
  - [Basic Concepts](#basic-concepts)
  - [AI and Machine Learning Concepts](#ai-and-machine-learning-concepts)
  - [Machine Learning Models and Techniques](#machine-learning-models-and-techniques)
  - [Data Handling and Processing](#data-handling-and-processing)
  - [Validation and Error Analysis](#validation-and-error-analysis)
  - [Feedback](#feedback)

## Basic Concepts
- **Variable** - A symbol used to represent an unknown value in mathematical expressions and algorithms.
- **Dependent Variable (Target/Label)** - The outcome variable that the model predicts, influenced by the independent variables.
- **Independent Variable (Feature/Attribute)** - The input variables that are presumed to influence the dependent variable. (Make up a Feature Set represented as vectors or arrays)
- **Discrete Variable/Data** - Data that is counted, often integers, and can only take distinct values.
- **Continuous Variable/Data** - Data that can take any value within a range, often measured and including decimals.

## AI and Machine Learning Concepts
- **Generative AI** - AI systems that can generate new content, such as text or images, that are similar to human-generated ones.
- **Large Language Model** - AI models that process and generate text based on large datasets of human language.
- **Multi-Modal** - AI that can process and interpret multiple types of data inputs like text, audio, and visual.
- **Training Data** - The dataset used to train a machine learning model.
- **Testing Data** - Data used to evaluate the performance and generalizability of a trained model.
- **Observed Data vs. Predicted Data** - Comparison between data collected/observed and data predicted by a model.
- **Overfitting** - A modeling error which occurs when a function is too closely fit to a limited set of data points.
- **Bias-Variance Tradeoff** - The tradeoff between making the model flexible enough to accurately model the target function but not so flexible that it picks up noise in the data.
- **Next Word Prediction** - The process of predicting the next word in a sequence, given the words that precede it.
- **Human-Like Intelligence** - AI that mimics human cognitive functions such as learning and problem-solving.
- **Rule-Based System** - An AI system that uses a set of predetermined rules to make decisions or solve problems.
- **Genetic Algorithm** - An optimization algorithm based on the principles of genetic inheritance and natural selection.
- **Expert System** - A computer system that emulates the decision-making ability of a human expert.
- **Fuzzy Logic** - A form of many-valued logic where the truth values of variables may be any real number between 0 and 1.
- **Symbolic Reasoning** - AI that manipulates symbols and strings to emulate human reasoning.
- **Feature Engineering** - The process of using domain knowledge to select, modify, or create new features from raw data to increase the predictive power of machine learning algorithms.
- **Machine Translation** - The application of computers to translate text or speech from one language to another.
- **Sentiment Analysis** - The use of natural language processing to systematically identify, extract, quantify, and study affective states and subjective information.
- **Text Summarization** - The process of distilling the most important information from a source text.
- **Knowledge Retrieval** - The process of finding knowledge in large datasets.
- **Domain Specific Sub-Model** - A model tailored to address specific needs within a defined domain.
- **Pretraining** - The training of a model on a large dataset before it is fine-tuned on a specific task.
- **Fine-Tuning** - The process of tweaking a pre-trained model on a specific dataset to improve its performance on that dataset.
- **Modeling Performance** - Evaluating how effectively a model predicts or classifies data.
- **Foundational Model** - A pre-trained model that provides a starting point for building more specialized models.
- **Fine-Tuned Model** - A foundational model that has been fine-tuned for specific tasks.
- **Text Completion** - Generating text that completes a given piece of text using a language model.
- **Few-Shot Learning** - Training a model with a very small amount of labeled data.
- **Unlabelled Text Copora** - Collections of written texts that have not been annotated with labels.
- **Zero-shot Learning** - The ability of a model to correctly make predictions for tasks it has never explicitly been trained on.

## Machine Learning Models and Techniques
- **Decision Tree** - A model that uses a tree-like model of decisions and their possible consequences.
- **Deep Learning** - A subset of machine learning that uses neural networks with three or more layers.
- **Convolutional Neural Network** - A class of deep neural networks, most commonly applied to analyzing visual imagery.
- **Logistic Regression** - A statistical model that in its basic form uses a logistic function to model a binary dependent variable.
- **Naive Bayes** - A simple probabilistic classifier based on applying Bayes' theorem with strong (naive) independence assumptions between the features.
- **Classification Trees** - Decision trees that classify instances by sorting them based on feature values.
- **Regression Trees** - Decision trees that predict continuous values.
- **Support Vector Machines** - A set of supervised learning methods used for classification, regression and outliers detection.
- **Neural Networks** - Networks of neurons either artificial or natural that are used to model complex patterns and prediction problems.
- **Hidden Layers** - Layers in a neural network that are not directly connected to the input or output layers.
- **Transformers** - Models that handle sequences of data, such as natural language, for tasks such as translation and text summarization.
- **Natural Language Processing** - The branch of AI that gives computers the ability to understand text and spoken words in much the way human beings can.
- **BERT (Bidirectional Encoder Representations from Transformers)** - A transformer-based machine learning technique for natural language processing pre-training.
- **GPT (Generative Pre-trained Transformer)** - An autoregressive language model that uses deep learning to produce human-like text.
- **Model Parameters** - Variables in a model that are tuned during training, such as the weights in a neural network.
- **Supervised Learning** - A type of machine learning where the model is trained on labeled data.
- **Unsupervised Learning** - A type of machine learning where the model is trained on unlabeled data.

## Data Handling and Processing
- **Embeddings** - A way of representing data by mapping it to vectors of real numbers.
- **Encode** - To convert data into a form that can be easily and correctly processed by different systems.
- **Decoder** - A process that converts the encoded data back into the original format or a format that is useful for subsequent processes.
- **Vector(s)** - An array or a list of numbers that store data points in a machine learning model.
- **Self-Attention Mechanism** - Part of a neural network that allows it to focus on different parts of the input sequence when producing a particular output.
- **RESTful Interface** - An architectural style for an application program interface (API) that uses HTTP requests to access and use data.
- **API (Application Programming Interface)** - A set of rules and tools for building software and applications.
- **JSON Format** - A lightweight data-interchange format that is easy for humans to read and write.
- **Rate Limiting** - A technique used in computer networks to control the rate of traffic sent or received by a network interface.
- **Error Handling** - The process of responding to and recovering from error conditions in a program.
- **Tokenization** - Splitting a text into individual terms or symbols, which are used as inputs for further processing.
- **Authentication** - The process of verifying the identity of a user or process.
- **Versioning** - The management of changes to documents, computer programs, large websites, and other collections of information.
- **Data Ingestion** - The process of obtaining and importing data for immediate use or storage in a database.
- **Vector Embedding** - A representation of data where similar data points are co-located in a lower-dimensional space.
- **Prompt Engineering** - The process of designing and optimizing the prompts used to interact with AI models.
- **Fine-Tuning** - The process of tweaking a pre-trained model on a specific dataset to improve its performance on that dataset.
- **Data Leakage** - The unintentional sharing of information between the training and testing datasets.

## Validation and Error Analysis
- **Cross Validation** - A technique for assessing how the results of a statistical analysis will generalize to an independent data set. Folded into k-folds, typically 5 or 10.
- Leave-One-Out Cross Validation - A technique for assessing how the results of a statistical analysis will generalize to an independent data set by leaving out one data point at a time.
- **Error** - The difference between the predicted value by the model and the actual value.
- **Regression** - A type of predictive modeling technique which investigates the relationship between a dependent (target) and independent variable (s) (predictor).
- **Classification** - The process of predicting the class of given data points.

## Feedback
To help improve this document, please provide feedback or suggest terms. 

Thank you for using this resource! ðŸŒŸ
